"use strict";(self.webpackChunkmcp_ai=self.webpackChunkmcp_ai||[]).push([[3518],{4369:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/skills/what-is-agent-skills","metadata":{"permalink":"/skills/what-is-agent-skills","source":"@site/blog/skills/what-is-agent-skills.mdx","title":"What Is an Agent Skill? The Standard Unit for AI Agent Capabilities","description":"Agent Skills define what AI agents can do with explicit, governable capabilities. Learn how Skills replace prompt-only behavior with structured, auditable execution.","date":"2026-01-27T12:38:19.000Z","tags":[{"inline":false,"label":"Skills","permalink":"/tags/skills","description":"Skills refer to specific capabilities or competencies that AI models can utilize to perform tasks, often through integration with external tools or APIs.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"},{"inline":false,"label":"Agentic AI","permalink":"/tags/agentic-ai","description":"Agentic AI refers to artificial intelligence systems that can autonomously perform tasks, make decisions, and interact with their environment to achieve specific goals.\\n"}],"readingTime":7.81,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"What Is an Agent Skill? The Standard Unit for AI Agent Capabilities","description":"Agent Skills define what AI agents can do with explicit, governable capabilities. Learn how Skills replace prompt-only behavior with structured, auditable execution.","authors":["adrian"],"tags":["skills","ai-integration","agentic-ai"],"keywords":["agent skills","ai agent capabilities","mcp skills","agent skill definition","ai governance","prompt vs skills","agent execution units","structured ai capabilities"],"image":"/img/skills/agent-skills.png"},"unlisted":false,"nextItem":{"title":"Mastering Skills: Your Gateway to Enhanced AI Capabilities","permalink":"/skills"}},"content":"import Head from \'@docusaurus/Head\';\\n\\nexport const faqJsonLd = {\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"FAQPage\\",\\n  \\"mainEntity\\": [\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is an Agent Skill?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"An Agent Skill is a structured, declarative capability that an AI agent can invoke to perform an action through a system. Unlike prompts, Skills define explicit boundaries, permissions, and execution rules that machines can enforce.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"How do Agent Skills differ from prompts?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Prompts are implicit natural language suggestions with trust-based, non-deterministic behavior. Skills are explicit structured capabilities with contract-based, auditable, and governable execution. Prompts decide what to try; Skills define what is allowed.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What\'s the difference between Skills, tools, and workflows?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Tools are low-level primitives, workflows are pre-wired sequences, and Skills are bounded capabilities that agents choose to invoke. Skills sit at the decision boundary between reasoning and execution.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Why do AI agents need Skills instead of just prompts?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Prompt-driven agents don\'t scale at enterprise level. They can hallucinate actions, have implicit permissions, opaque execution paths, and are impossible to audit. Skills provide the control, governance, and security that enterprises demand.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What role does MCP play with Agent Skills?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"MCP (Model Context Protocol) provides a transport-agnostic execution layer for Skills, enabling remote skill invocation, enterprise security boundaries, air-gap compatibility, and audit/governance hooks. MCP turns Skills from ideas into infrastructure.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Are Agent Skills becoming a standard?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Yes. What started as framework-specific abstractions is converging into shared specifications, common schemas, public registries, installation tooling, and usage tracking. Skills are becoming the standard unit of agent execution, governance, and enterprise adoption.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Can Agent Skills be audited for security?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Yes. Unlike prompts, Skills are structured with explicit schemas, making them auditable and governable. They provide clear artifacts for security reviews, permission tracking, and execution path analysis.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Where do Agent Skills execute?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Skills don\'t live in the model\u2014they live in systems. The model handles reasoning, while Skills execute in controlled environments with proper security boundaries and governance. This separation ensures authority stays with the system, not the AI.\\"\\n      }\\n    }\\n  ]\\n};\\n\\n<Head>\\n  <script type=\\"application/ld+json\\">\\n    {JSON.stringify(faqJsonLd)}\\n  <\/script>\\n</Head>\\n\\n**AI agents are getting smarter \u2014 and more dangerous.**\\n\\nNot because they reason better, but because they act without boundaries.\\n\\n**Agent Skills exist to fix that.**\\n\\n\x3c!-- truncate --\x3e\\n\\nThey define **what an agent can do**, **how it can do it**, and **under what constraints** \u2014 in a way machines can enforce, not humans hope for.\\n\\n---\\n\\n## What Is an Agent Skill? (Simple Definition)\\n\\nAn **Agent Skill** is a structured, declarative capability that an AI agent can invoke to perform an action through a system.\\n\\n- **Not a suggestion** \u2014 it\'s enforceable\\n- **Not a prompt** \u2014 it\'s structured\\n- **Not open-ended** \u2014 it has boundaries\\n\\nA capability with rules that machines enforce.\\n\\n---\\n\\n## Why Agent Skills Became Inevitable\\n\\nPrompt-driven agents don\'t scale beyond experimentation.\\n\\n**At small scale**, prompts feel powerful and flexible.  \\n**At enterprise scale**, they create unacceptable risk:\\n\\n### The Prompt Problem\\n- \ud83d\udea8 Agents hallucinate actions that don\'t exist\\n- \ud83d\udd13 Permissions are implicit and unenforceable\\n- \ud83c\udf2b\ufe0f Execution paths are opaque and unpredictable\\n- \u274c Security reviews are nearly impossible\\n- \ud83d\udcdd Audits have no structured artifacts to examine\\n\\n### The Industry Response\\n\\nSkills emerged because **enterprises demanded control**.\\n\\nThe industry responded with:\\n- Shared **Skill specifications** (not vendor-locked)\\n- Standard schemas for cross-platform compatibility\\n- Public registries and catalogs for discovery\\n- Installation, versioning, and tracking mechanisms\\n- Observability and governance tooling\\n\\nSkills are now appearing everywhere \u2014 AI frameworks, runtime environments, marketplaces, and enterprise dashboards.\\n\\n---\\n\\n## Skills vs Prompts: The Real Difference\\n\\nUnderstanding this distinction is critical for building production-grade AI systems.\\n\\n| Aspect | Prompts | Skills |\\n|--------|---------|--------|\\n| **Behavior** | Implicit, suggested | Explicit, enforced |\\n| **Format** | Natural language | Structured schema |\\n| **Security** | Trust-based | Contract-based |\\n| **Auditability** | Hard to audit | Fully auditable |\\n| **Execution** | Non-deterministic | Governable |\\n| **Permissions** | Implied | Explicit |\\n| **Lifecycle** | Ad-hoc | Versioned & tracked |\\n\\n### The Core Distinction\\n\\n**Prompts** decide *what to try*.  \\n**Skills** define *what is allowed*.\\n\\nPrompts ask. Skills authorize.\\n\\n---\\n\\n## Skills vs Tools vs Workflows: Clearing the Confusion\\n\\nThese terms are often used interchangeably. They shouldn\'t be.\\n\\n### The Hierarchy of Agent Capabilities\\n\\n**\ud83d\udd27 Tools** are low-level primitives\\n- Individual functions or API calls\\n- Example: `get_user(id)` or `send_email(to, subject, body)`\\n- No decision-making, just execution\\n\\n**\ud83d\udd04 Workflows** are pre-wired sequences\\n- Fixed chains of predetermined steps\\n- Example: \\"When form submitted \u2192 validate \u2192 save \u2192 send email\\"\\n- No agent choice, just automation\\n\\n**\ud83c\udfaf Skills** are bounded capabilities that agents choose to invoke\\n- Define what CAN be done and under what constraints\\n- Example: \\"Search customer database (read-only, max 100 results, audit logged)\\"\\n- Agent decides WHEN to use them based on context\\n\\n### Why This Matters\\n\\nSkills sit at the **decision boundary** between reasoning and execution.\\n\\n- The **model reasons** about what to do\\n- The **Skill authorizes** what can be done\\n- The **tool executes** the actual action\\n\\nThis separation is what makes AI agents governable.\\n\\n---\\n\\n## Agent Skills Are Becoming a Standard Layer\\n\\nWhat started as framework-specific abstractions is now converging into industry standards.\\n\\n### The Standardization Wave\\n\\n**Foundation:**\\n- Shared specifications (like MCP)\\n- Common schemas and interfaces\\n- Cross-platform compatibility\\n\\n**Distribution:**\\n- Public registries and catalogs\\n- Installation and discovery tooling\\n- Version management\\n\\n**Operations:**\\n- Usage tracking and observability\\n- Permission management\\n- Audit logging and compliance\\n\\n### Why This Matters\\n\\nThis is how sustainable AI ecosystems form.\\n\\n**Not around models** (which change constantly)  \\n**But around capabilities** (which systems can rely on)\\n\\nWhen Skills become standardized:\\n- Developers can publish once, run anywhere\\n- Enterprises can audit once, trust everywhere\\n- Agents can discover capabilities dynamically\\n- Security teams can govern at the Skill level\\n\\n---\\n\\n## Why MCP Matters for Agent Skills\\n\\n**Critical insight:** Skills don\'t live in the model. They live in systems.\\n\\nThe model generates *reasoning*. Systems provide *capabilities*.\\n\\n### What MCP Provides\\n\\nThe [Model Context Protocol (MCP)](/) solves the infrastructure problem for Skills:\\n\\n**Execution Layer:**\\n- Transport-agnostic communication (stdio, HTTP, SSE)\\n- Remote skill invocation across boundaries\\n- Standardized request/response patterns\\n\\n**Enterprise Requirements:**\\n- Security boundaries and permissions\\n- Air-gap compatibility for sensitive environments\\n- Authentication and authorization hooks\\n\\n**Governance & Compliance:**\\n- Audit trails for all skill invocations\\n- Usage tracking and monitoring\\n- Policy enforcement points\\n\\n### The Transformation\\n\\nMCP turns Skills from **abstract ideas** into **operational infrastructure**.\\n\\n- Before MCP: Each framework had its own Skill implementation\\n- After MCP: Skills work across frameworks, runtimes, and platforms\\n- Result: True interoperability and enterprise adoption\\n\\n---\\n\\n## The Mental Model to Remember\\n\\n> **Reasoning stays with the model.**  \\n> **Authority stays with the system.**\\n\\nSkills are where that line is drawn.\\n\\nThis separation ensures:\\n- AI can be creative within bounds\\n- Systems maintain control\\n- Humans can audit and govern\\n- Security isn\'t dependent on prompt engineering\\n\\n---\\n\\n## FAQ: Understanding Agent Skills\\n\\n**Q: What is an Agent Skill?**  \\nA: An Agent Skill is a structured, declarative capability that an AI agent can invoke to perform an action through a system. Unlike prompts, Skills define explicit boundaries, permissions, and execution rules that machines can enforce.\\n\\n**Q: How do Agent Skills differ from prompts?**  \\nA: Prompts are implicit natural language suggestions with trust-based, non-deterministic behavior. Skills are explicit structured capabilities with contract-based, auditable, and governable execution. Prompts decide what to try; Skills define what is allowed.\\n\\n**Q: What\'s the difference between Skills, tools, and workflows?**  \\nA: Tools are low-level primitives (individual functions), workflows are pre-wired sequences (fixed automation), and Skills are bounded capabilities that agents choose to invoke. Skills sit at the decision boundary between AI reasoning and system execution.\\n\\n**Q: Why do AI agents need Skills instead of just prompts?**  \\nA: Prompt-driven agents don\'t scale at enterprise level. They can hallucinate actions, have implicit permissions, opaque execution paths, and are impossible to audit. Skills provide the control, governance, and security that enterprises demand.\\n\\n**Q: What role does MCP play with Agent Skills?**  \\nA: MCP (Model Context Protocol) provides a transport-agnostic execution layer for Skills, enabling remote skill invocation, enterprise security boundaries, air-gap compatibility, and audit/governance hooks. MCP turns Skills from ideas into infrastructure.\\n\\n**Q: Are Agent Skills becoming a standard?**  \\nA: Yes. What started as framework-specific abstractions is converging into shared specifications, common schemas, public registries, installation tooling, and usage tracking. Skills are becoming the standard unit of agent execution, governance, and enterprise adoption.\\n\\n**Q: Can Agent Skills be audited for security?**  \\nA: Yes. Unlike prompts, Skills are structured with explicit schemas, making them auditable and governable. They provide clear artifacts for security reviews, permission tracking, and execution path analysis.\\n\\n**Q: Where do Agent Skills execute?**  \\nA: Skills don\'t live in the model\u2014they live in systems. The model handles reasoning, while Skills execute in controlled environments with proper security boundaries and governance. This separation ensures authority stays with the system, not the AI.\\n\\n---\\n\\n## What Comes Next: The Skill-First Future\\n\\nAgent Skills are now the fundamental unit of:\\n\\n\u2705 **Agent execution** \u2014 how AI agents perform actions  \\n\u2705 **Platform governance** \u2014 how organizations control AI behavior  \\n\u2705 **Security review** \u2014 how teams audit AI capabilities  \\n\u2705 **Enterprise adoption** \u2014 how AI becomes production-ready\\n\\n### Your Next Steps\\n\\nThe rest of this section explores how to:\\n- **Design** Skills that are secure and maintainable\\n- **Build** Skills using MCP and standard patterns\\n- **Evaluate** Skills for quality and safety\\n- **Deploy** Skills across environments\\n- **Govern** Skills at enterprise scale\\n\\nWe\'re treating Skills **as systems** \u2014 because that\'s what they are.\\n\\n**The era of prompt-only agents is ending.**  \\n**The era of Skill-driven systems is here.**"},{"id":"/skills","metadata":{"permalink":"/skills","source":"@site/blog/skills/index.md","title":"Mastering Skills: Your Gateway to Enhanced AI Capabilities","description":"Unlock the full potential of AI with our comprehensive guide to Skills, empowering developers to create smarter, more efficient applications.","date":"2026-01-27T10:08:04.000Z","tags":[{"inline":false,"label":"Skills","permalink":"/tags/skills","description":"Skills refer to specific capabilities or competencies that AI models can utilize to perform tasks, often through integration with external tools or APIs.\\n"}],"readingTime":3.03,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Mastering Skills: Your Gateway to Enhanced AI Capabilities","description":"Unlock the full potential of AI with our comprehensive guide to Skills, empowering developers to create smarter, more efficient applications.","authors":["adrian"],"tags":["skills"],"image":"/img/skills/skills-gateway.png","hide_table_of_contents":true},"unlisted":false,"prevItem":{"title":"What Is an Agent Skill? The Standard Unit for AI Agent Capabilities","permalink":"/skills/what-is-agent-skills"},"nextItem":{"title":"How to Deploy MCP Servers","permalink":"/university/deploy-mcp-server-in-seconds"}},"content":"In the rapidly evolving landscape of AI, **Skills** have emerged as a transformative force, enabling developers to extend the capabilities of AI models far beyond their native functions. Whether you\'re building chatbots, virtual assistants, or complex AI-driven applications, mastering Skills is essential to unlocking new levels of performance and user engagement.\\n\\n\x3c!-- truncate --\x3e\\n\\n**Where agents stop guessing \u2014 and start acting**\\n\\nAI agents don\u2019t fail because they\u2019re not smart.  \\nThey fail because they don\u2019t know **what they\u2019re allowed to do**.\\n\\nSkills are the missing layer between *reasoning* and *execution*.  \\nThey turn vague prompts into **explicit, auditable, testable actions**.\\n\\nThis section is the home of everything you need to **understand, design, and operationalize Skills** using the **Model Context Protocol (MCP)**.\\n\\n---\\n\\n## What are Skills?\\n\\nA **Skill** is a structured, declarative capability that an AI agent can invoke safely and deterministically.\\n\\nThink of a Skill as:\\n\\n- A **contract**, not a prompt\\n- A **capability**, not a suggestion\\n- A **tool with boundaries**, not a magic trick\\n\\nAt a technical level, a Skill is:\\n- Defined using **MCP**\\n- Exposed as a **tool** with a clear schema\\n- Executed by **systems**, not the model itself\\n\\n> Reasoning stays with the model.  \\n> Authority stays with the system.\\n\\n---\\n\\n## Why Skills exist (and prompts are not enough)\\n\\nPrompt-only agents break at scale.\\n\\nThey:\\n- Hallucinate actions\\n- Overreach permissions\\n- Leak secrets\\n- Fail silently\\n- Cannot be audited, tested, or governed\\n\\nSkills exist to solve that.\\n\\nThey allow you to:\\n- Explicitly declare **what an agent can do**\\n- Control **how and when execution happens**\\n- Separate **decision-making from authority**\\n- Build agents that pass **security, compliance, and platform reviews**\\n\\nIf prompts are **thoughts**, Skills are **hands**.\\n\\n---\\n\\n## Skills are not plugins. Not functions. Not workflows.\\n\\nSkills are often misunderstood.\\n\\nThey are **not**:\\n- Plugins (too UI-driven)\\n- Functions (too low-level)\\n- Workflows (too rigid)\\n\\nSkills live in between.\\n\\nThey are:\\n- **Composable**\\n- **Discoverable**\\n- **Context-aware**\\n- **Governable**\\n\\nThis is why MCP matters: it gives Skills a **standardized, machine-readable contract** that works across:\\n- IDEs\\n- Agents\\n- Runtimes\\n- Enterprises\\n- Air-gapped environments\\n\\n---\\n\\n## What you\u2019ll learn in this section\\n\\nThis Skills section is not a tutorial dump.  \\nIt\u2019s a **mental model + execution guide**.\\n\\nHere you\u2019ll learn how to:\\n\\n### \ud83d\udd39 Design Skills\\n- How to think in **capabilities**, not endpoints\\n- How to model inputs, outputs, and constraints\\n- How to avoid over-privileged Skills\\n\\n### \ud83d\udd39 Build Skills\\n- API-to-MCP (a2m) Skill patterns\\n- Tool schemas that scale\\n- Error handling for agents (not humans)\\n\\n### \ud83d\udd39 Test & Evaluate Skills\\n- Skill evaluation (mcp-eval)\\n- Deterministic vs probabilistic behavior\\n- Guardrails, contracts, and failure modes\\n\\n### \ud83d\udd39 Deploy Skills\\n- Local vs remote MCP servers\\n- Enterprise-ready Skill exposure\\n- Air-gap and zero-trust patterns\\n\\n### \ud83d\udd39 Govern Skills\\n- Skill registries\\n- Versioning and deprecation\\n- Security reviews and auditability\\n\\n---\\n\\n## Who this section is for\\n\\nThis section is written for people building **real systems**, not demos.\\n\\n- **Platform teams** defining agent capabilities\\n- **API teams** turning services into agent-ready tools\\n- **Security teams** asking \u201cwhat can this agent actually do?\u201d\\n- **Product leaders** trying to ship AI features without chaos\\n- **Builders** who want agents that survive production\\n\\nIf you\u2019ve ever asked:\\n> \u201cHow do we control what the agent can do?\u201d\\n\\nYou\u2019re in the right place.\\n\\n---\\n\\n## Skills are the unit of scale for agents\\n\\nAgents don\u2019t scale by being smarter.  \\nThey scale by being **better constrained**.\\n\\nSkills are:\\n- The unit of **execution**\\n- The unit of **security**\\n- The unit of **governance**\\n- The unit of **enterprise adoption**\\n\\nThis section exists because Skills are not optional anymore.\\n\\nThey are the foundation.\\n\\n---\\n\\n## Start here\\n\\nIf you\u2019re new:\\n- Read **What is a Skill?**\\n- Then **API \u2192 MCP Skills (a2m)**\\n- Then **Skill Evaluation & Safety**\\n\\nIf you\u2019re advanced:\\n- Jump straight to **Skill Lifecycle Management**\\n- Or **Enterprise Skill Architectures**\\n\\nEither way \u2014 welcome.\\n\\nThis is where agents become systems.\\nBe HAPI, and Go Rebels! \u270a\ud83c\udffc"},{"id":"/university/deploy-mcp-server-in-seconds","metadata":{"permalink":"/university/deploy-mcp-server-in-seconds","source":"@site/blog/university/deploy-mcp-server-in-seconds.mdx","title":"How to Deploy MCP Servers","description":"A step-by-step guide to deploying MCP servers using HAPI CLI.","date":"2026-01-27T10:08:04.000Z","tags":[{"inline":false,"label":"Guide","permalink":"/tags/guide","description":"Curated instructions or documentation designed to help users understand and implement specific use cases around MCP and related technologies.\\n"}],"readingTime":3.1,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How to Deploy MCP Servers","description":"A step-by-step guide to deploying MCP servers using HAPI CLI.","tags":["guide"],"keywords":["MCP deployment","HAPI CLI","Cloudflare Workers","Docker","Fly.io"],"image":"/img/university/deploy-mcp-server.png"},"unlisted":false,"prevItem":{"title":"Mastering Skills: Your Gateway to Enhanced AI Capabilities","permalink":"/skills"},"nextItem":{"title":"MCP at Scale: Engineering the Future of AI Platforms","permalink":"/mcp-at-scale"}},"content":"Setting up a **Model Context Protocol (MCP)** server is easier than you might think! It is a straightforward process that doesn\'t require extensive DevOps skills. Whether you\'re testing, packaging, or scaling globally, the **HAPI MCP Stack** equips you with everything you need to launch your server in just seconds.\\n\\nIn this guide, we\'ll explore **4 different ways** to run and deploy MCP servers using the HAPI CLI.\\n\\n**Bonus:** Agent Skills provided to automate MCP server deployment.\\n\\n\x3c!-- truncate --\x3e\\n\\n## 1. Local Development (The Quickest Way)\\n\\nFor rapid iteration and testing, running your MCP server locally is the best approach. You can instantly spin up a server and inspect its tools using the official MCP Inspector.\\n\\nIn this example, we\'ll run an **OpenAI Tools** server.\\n\\n```bash\\n# Run the MCP Server Locally and pipe to Inspector\\nhapi serve openai-tools \\\\\\n  --headless \\\\\\n  --port 3030 \\\\\\n  --url https://api.openai.com/v1 | bunx @modelcontextprotocol/inspector\\n```\\n\\nFind more MCP server definitions in the official [MCP Registry](https://registry.modelcontextprotocol.io/?q=ai.com.mcp).\\n\\n### What\'s happening here?\\n- `hapi serve`: Starts the MCP server.\\n- `--headless`: Runs without a UI (optimized for machine interaction).\\n- `--port 3030`: Binds the server to port 3030.\\n- `| bunx @modelcontextprotocol/inspector`: Pipes the output directly to the MCP Inspector, allowing you to interact with your tools in a web interface locally.\\n\\n---\\n\\n## 2. Docker Containers (The Portable Way)\\n\\nIf you need to ship your server to Kubernetes, ECS, or any container orchestration platform, Docker is the industry standard. We provide a pre-built image `hapimcp/hapi-cli` that is ready to serve.\\n\\n```bash\\ndocker run --name hapi-openai -d \\\\\\n  -p 3030:3030 \\\\\\n  hapimcp/hapi-cli:latest serve \\\\\\n  --openapi https://docs.mcp.com.ai/servers-apis/openapi/openai-tools.yaml \\\\\\n  --headless \\\\\\n  --url https://api.openai.com/v1\\n```\\n\\n### Breakdown:\\n- `hapimcp/hapi-cli:latest`: The official HAPI CLI Docker image.\\n- `--openapi ...`: Specifies the OpenAPI definition for the server (defining the tools/resources).\\n- `-p 3030:3030`: Maps the container port to your host.\\n\\nYour server is now running in a container, ready to accept connections on port 3030!\\n\\n---\\n\\n## 3. Cloudflare Workers (The Scalable Way)\\n\\nFor a serverless solution with global low latency, **Cloudflare Workers** is the ultimate deployment target. HAPI CLI handles the entire build and deployment process for you.\\n\\n```bash\\nhapi deploy --name openai-tools \\\\\\n  --project openai \\\\\\n  --openapi https://docs.mcp.com.ai/servers-apis/openapi/openai-tools.yaml \\\\\\n  --url https://api.openai.com/v1\\n```\\n\\nYou\'ll see output like this:\\n\\n```text\\n\ud83d\udcdd Generating temporary Wrangler config...\\n\u2699\ufe0f Deploying to Cloudflare Workers...\\n\ud83c\udf0d Live at: https://openai-tools.runmcp.workers.dev\\n\u2705 Deployed successfully!\\n```\\n\\n### Why Cloudflare Workers?\\n- **Zero Cold Starts:** Instant response times.\\n- **Global Distribution:** Deployed to 300+ cities worldwide.\\n- **Cost Effective:** Pay only for what you use.\\n\\n---\\n\\n## 4. Fly.io (The Global Way)\\n\\nFor those who prefer running on **Fly.io**, you can deploy your MCP server instantly using our pre-built image, bypassing the need for Dockerfiles or complex overrides.\\n\\n```bash\\nfly machine run hapimcp/hapi-cli:latest --command \\"hapi serve\\" \\\\\\n  -e openapi=\\"https://docs.mcp.com.ai/servers-apis/openapi/openai-tools.yaml\\" \\\\\\n  -e url=\\"https://api.openai.com/v1\\"\\n```\\n\\n### Why Fly.io?\\n- **Instant Machines:** Boot full VM instances in milliseconds.\\n- **Global Anycast:** Run close to your users.\\n- **Pre-built Image:** No build step required\u2014just run.\\n\\n## Agent Skills to Automate Deployment\\n\\nTo make deployment even easier, we provide **Agent Skills** that automate the entire process of deploying MCP servers across different platforms. You can find this and more skills in the [mcp.com.ai skills registry](https://skills.sh/?q=mcp-com-ai).\\n\\n\x3c!-- Quick install command --\x3e\\n```bash\\nnpx skills add https://github.com/mcp-com-ai/api-to-mcp-skills --skill api-to-mcp\\n```\\n\\n---\\n\\n## Summary\\n\\n| Method | Best For | Requirement |\\n| :--- | :--- | :--- |\\n| **Local** | Development, Testing, Debugging | HAPI CLI |\\n| **Docker** | Enterprise, Kubernetes, VPS | Docker Engine |\\n| **Workers** | Serverless, Scaling, Public APIs | Cloudflare Account |\\n| **Fly.io** | Global VMs, Persistent Apps | Fly.io Account |\\n\\nReady to build your own? Check out the full documentation at [docs.mcp.com.ai](https://docs.mcp.com.ai).\\n\\n\ud83c\udfc1 **Done. Be HAPI, and go Rebels! \u270a**"},{"id":"/mcp-at-scale","metadata":{"permalink":"/mcp-at-scale","source":"@site/blog/mcp-at-scale/index.md","title":"MCP at Scale: Engineering the Future of AI Platforms","description":"A deep dive series into the architectural challenges of running Model Context Protocol in production at enterprise scale.","date":"2026-01-20T00:33:45.000Z","tags":[{"inline":false,"label":"MCP at Scale","permalink":"/tags/mcp-at-scale","description":"MCP at Scale refers to the implementation and management of the Model Context Protocol in large-scale environments, ensuring performance, reliability, and security for extensive AI applications.\\n"},{"inline":false,"label":"Architecture","permalink":"/tags/architecture","description":"The structural design and organization of systems, components, and their interactions within a software or hardware environment.\\n"},{"inline":false,"label":"Platform Engineering","permalink":"/tags/platform-engineering","description":"Platform Engineering involves designing and building the underlying infrastructure and tools that support the development, deployment, and operation of software applications and services.\\n"}],"readingTime":1.86,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"MCP at Scale: Engineering the Future of AI Platforms","description":"A deep dive series into the architectural challenges of running Model Context Protocol in production at enterprise scale.","authors":["adrian"],"tags":["mcp-at-scale","architecture","platform-engineering"],"image":"/img/mcp-at-scale/enterprise-mcp.png","hide_table_of_contents":true},"unlisted":false,"prevItem":{"title":"How to Deploy MCP Servers","permalink":"/university/deploy-mcp-server-in-seconds"},"nextItem":{"title":"How to Scale MCP to Thousands of Tools Without Destroying Your Budget","permalink":"/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget"}},"content":"**The \\"Hello World\\" phase of the Model Context Protocol is over.**\\n\\nAs enterprises move from experimental chatbots to production-grade agentic systems, they are hitting the invisible walls of scale: token bloat, latency, governance, and discovery. What works for ten tools fails catastrophically at ten thousand.\\n\\n\x3c!-- truncate --\x3e\\n\\n[**MCP at Scale**](/mcp-at-scale) is a dedicated series exploring the engineering reality of building robust, high-performance AI platforms.\\n\\n## Why This Series Exists\\n\\nWe are witnessing a shift. MCP is evolving from a simple connector protocol into the **operating system for AI execution**. This transition demands a new set of architectural patterns. It\'s no longer just about exposing an API; it\'s about orchestration, security, and efficiency.\\n\\nIn this ongoing series, we dissect the critical challenges of **large-scale MCP deployments**:\\n\\n*   **Token Economics & Efficiency:** Managing the cost and latency of massive tool contexts.\\n*   **Dynamic Discovery:** Moving beyond static injection to search-driven tool loading.\\n*   **Governance & Security:** Implementing \\"[Connect Authorities](/tags/mcp-connect-authority)\\" and preventing Shadow AI.\\n*   **High-Volume Orchestration:** Handling thousands of concurrent agent sessions without degradation.\\n\\n## The Guide\\n\\nThis series is written for platform engineers, architects, and technical leaders who are building the infrastructure that will power the next generation of AI.\\n\x3c!-- \\n### Core Architecture\\n\\n*   [**How to Scale MCP to Thousands of Tools Without Destroying Your Budget**](/blog/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget)  \\n    *Strategies to manage token bloat using lazy loading and dynamic discovery taking cues from SEP-1576.*\\n\\n*   [**Ranking MCP Tools for Better Discovery**](/blog/mcp-at-scale/how-to-rank-mcp-tools-to-improve-discovery)  \\n    *Algorithms and patterns for surfacing the right tools to the right agents at the right time.*\\n\\n### Upcoming Articles\\n\\n*   **Implementing Connect Authorities for Secure MCP**  \\n    *A deep dive into governance models that ensure only authorized tools are accessible to agents.*\\n*   **Building a High-Performance MCP Orchestrator**  \\n    *Architectural patterns for managing thousands of concurrent agent sessions efficiently.*\\n*   **Optimizing Token Usage in Large-Scale MCP Deployments**  \\n    *Techniques for reducing token consumption while maintaining context richness.*\\n*   **Case Studies: MCP at Scale in the Wild**  \\n    *Real-world examples of enterprises successfully implementing MCP at scale.*\\n --\x3e\\n---\\n\\n**Join us as we define the standards for enterprise MCP architecture.**\\n\\nBe HAPI, and Go Rebels! \u270a\ud83c\udffc"},{"id":"/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget","metadata":{"permalink":"/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget","source":"@site/blog/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget.mdx","title":"How to Scale MCP to Thousands of Tools Without Destroying Your Budget","description":"Strategies to manage token bloat in MCP systems as tool catalogs grow.","date":"2026-01-19T18:49:49.000Z","tags":[{"inline":false,"label":"MCP at Scale","permalink":"/tags/mcp-at-scale","description":"MCP at Scale refers to the implementation and management of the Model Context Protocol in large-scale environments, ensuring performance, reliability, and security for extensive AI applications.\\n"},{"inline":false,"label":"Architecture","permalink":"/tags/architecture","description":"The structural design and organization of systems, components, and their interactions within a software or hardware environment.\\n"}],"readingTime":11.41,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"How to Scale MCP to Thousands of Tools Without Destroying Your Budget","description":"Strategies to manage token bloat in MCP systems as tool catalogs grow.","keywords":["MCP Scaling","Token Bloat","AI Platform Design","MCP token optimization","HAPI MCP","Tool Discovery"],"tags":["mcp-at-scale","architecture"],"authors":["adrian"],"image":"/img/blog/dynamic-discovery-tools.png"},"unlisted":false,"prevItem":{"title":"MCP at Scale: Engineering the Future of AI Platforms","permalink":"/mcp-at-scale"},"nextItem":{"title":"SDKs are Dead: Embracing Agent Skills for Automation","permalink":"/skills/sdks-are-dead"}},"content":"import Head from \'@docusaurus/Head\';\\n\\nexport const faqJsonLd = {\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"FAQPage\\",\\n  \\"mainEntity\\": [\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is token bloat in MCP?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Token bloat in MCP happens when an MCP client injects too many tool definitions (schemas + descriptions) into the model context, inflating prompt size before reasoning even starts.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Why is token bloat a problem for MCP systems?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Token bloat increases cost per request, adds latency, degrades tool selection quality, and expands the security/compliance surface because more tools appear in context than are needed.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What causes token bloat in MCP tool catalogs?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"The most common cause is static tool injection: loading the full tool catalog into the prompt on every request instead of discovering and loading only what\u2019s needed.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is lazy loading for MCP tools?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Lazy loading means you load tool schemas only after the agent has identified relevant tools (usually via search/ranking), rather than preloading every tool into context.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is tool discovery in MCP?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Tool discovery is a step where the agent queries a registry (or authority layer) to retrieve a small, ranked set of candidate tools for a task, then loads only those.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"How do you mitigate token bloat when you have thousands of MCP tools?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Use search-based discovery + ranking, enforce tool/context budgets, filter tools by policy (role/tenant), and expand schemas on demand (summaries first, full schemas later).\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is a context budget for MCP tools?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"A context budget is a hard limit on how many tools or schema tokens can be included in a request. It keeps cost and latency predictable and prevents runaway prompts.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Should I use FAQPage or QAPage schema for MCP Q&A content?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Use FAQPage when each question has a single authoritative answer you provide. Use QAPage only when users can submit answers (like forums).\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is shadow MCP and how does it relate to token bloat?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Shadow MCP is ungoverned MCP tooling (servers/tools) that appear without centralized discovery, policy, or audit. It often shows up first as tool sprawl and token bloat.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What\u2019s the best MCP architecture pattern to scale tool catalogs?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Registry-first discovery with an authority/policy layer: the agent searches a catalog, gets a small ranked shortlist, and only then loads the selected tool schemas for execution.\\"\\n      }\\n    }\\n  ]\\n};\\n\\n<Head>\\n  <script type=\\"application/ld+json\\">\\n    {JSON.stringify(faqJsonLd)}\\n  <\/script>\\n</Head>\\n\\n**Your MCP just became a memory hog. And it\u2019s quietly burning your budget.**\\n\\nIf your Model Context Protocol (MCP) catalog is growing into the hundreds\u2014or thousands\u2014of tools, you\u2019re already facing the next invisible scalability wall: **token bloat**.\\n\\nAnd it\u2019s not a theory anymore.\\n\\n\x3c!-- truncate --\x3e\\n\\nClaude shipped its **[Tool Search Tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)** \u2014 a long-requested feature that dynamically discovers and loads tools on demand. The MCP community is actively debating [**lazy loading**](https://github.com/modelcontextprotocol/modelcontextprotocol/issues/1978), [**dynamic discovery**](https://github.com/modelcontextprotocol/modelcontextprotocol/issues/1881), and **context minimization**. There\u2019s even a formal proposal now:\\n\ud83d\udc49 [**SEP-1576: Mitigating Token Bloat in MCP**](https://github.com/modelcontextprotocol/modelcontextprotocol/issues/1576)\\n\\nWe talked about this issue back in August 2025: [why too many tools can break your AI](https://rebelion.la/agent-tools-guardrails-why-too-many-tools-can-break-your-ai), and now it\u2019s time to get practical. This is the moment where MCP moves from \u201ccool demo tech\u201d to **real platform engineering**.\\n\\nIf you don\u2019t solve token bloat early, your MCP will become:\\n\\n* Expensive to run\\n* Slow to reason\\n* Hard to govern\\n* Risky for enterprise compliance\\n* Hallucination-prone \\n\\nLet\u2019s break down what\u2019s happening \u2014 and how to design MCP systems that scale cleanly.\\n\\n---\\n\\n## Token Bloat in MCP: Why Your Tool Catalog Is Becoming a Cost, Latency, and Security Problem\\n\\n### Business impact first\\n\\nToken bloat creates some immediate problems:\\n\\n| Problem               | Business Impact                                      |\\n| --------------------- | ---------------------------------------------------- |\\n| Cost explosion        | Every request loads thousands of unused tool schemas |\\n| Latency               | Larger prompts = slower inference                    |\\n| Reasoning degradation | LLMs perform worse with noisy context                |\\n| Security risk         | Tools leak into contexts they should never be in     |\\n| Compliance failure    | Shadow tools get injected into AI workflows          |\\n\\nAt enterprise scale, token bloat is not a technical issue.\\nIt\u2019s a **platform liability**.\\n\\n---\\n\\n### What Is Token Bloat in MCP?\\n\\n#### Simple definition\\n\\n**Token bloat happens when your MCP client sends too many tool definitions into the model context \u2014 even when only one tool is needed.**\\n\\nInstead of:\\n\\n> \u201cHere is the one tool you need.\u201d\\n\\nYou send:\\n\\n> \u201cHere are 4,200 tools. Pick one.\u201d\\n\\nEach tool contains:\\n\\n* Name\\n* Description\\n* JSON schema\\n* Input types\\n* Output types\\n* Metadata\\n\\nMultiply that by thousands.\\n\\nNow your model prompt is tens of thousands of tokens before reasoning even starts.\\n\\nThat\u2019s token bloat.\\n\\n---\\n\\n### Why MCP Is Uniquely Vulnerable?\\n\\nMCP is powerful because it standardizes tools.\\n\\nBut that same power creates a new failure mode:\\n\\n#### MCP encourages tool catalogs\\n\\n* Public registries\\n* Internal enterprise registries\\n* Department registries\\n* Vendor registries\\n* Marketplace registries\\n\\nSoon you have:\\n\\n* CRM tools\\n* ERP tools\\n* Cloud tools\\n* DevOps tools\\n* Security tools\\n* Finance tools\\n* HR tools\\n\\nAll MCP-compatible.\\n\\nNow your agent needs to choose one.\\n\\nSo na\xefve implementations load **everything**.\\n\\n---\\n\\n#### The Breaking Point: Thousands of Tools\\n\\nThe MCP community hit this wall in 2025.\\n\\nWhich led to:\\n\\n* **SEP-1576: Mitigating Token Bloat in MCP**\\n* Feature request: **Lazy Loading for MCP Servers**\\n* Claude shipping **Tool Search Tool**\\n\\nThis is the signal:\\n\\n> The ecosystem is moving from static tool injection to dynamic discovery.\\n\\n---\\n\\n## Claude\u2019s Tool Search Tool: The New MCP Pattern\\n\\nClaude\u2019s new **Tool Search Tool** introduces an important shift.\\n\\nInstead of loading all tools into context:\\n\\n1. Claude receives a task\\n2. Claude searches a tool registry\\n3. Claude selects relevant tools\\n4. Only those tools are loaded into context\\n5. Execution begins\\n\\nThis mirrors how real software works:\\n\\n* You don\u2019t load every library\\n* You import what you need\\n\\nThis is the path to the future of MCP.\\n\\n---\\n\\n## The Core MCP Scaling Problem\\n\\nLet\u2019s formalize it.\\n\\nYour MCP system has four layers:\\n\\n```\\nUser \u2192 Agent \u2192 MCP Client \u2192 MCP Registry \u2192 MCP Servers\\n```\\n\\nThe failure happens at:\\n\\n```\\nMCP Client \u2192 Model Context\\n```\\n\\nWhere:\\n\\n* The MCP client injects tool schemas\\n* The model must reason over them\\n* The prompt explodes\\n\\n---\\n\\n### SEP-1576: The Community\u2019s Wake-Up Call\\n\\nSEP-1576 proposes:\\n\\n* Lazy tool loading\\n* Partial schemas\\n* Tool summaries\\n* On-demand expansion\\n* Context budgets\\n\\nIt acknowledges a core truth:\\n\\n> MCP systems must become **context-aware platforms**, not dumb tool injectors.\\n\\n---\\n\\n### Why Token Bloat Breaks AI Reasoning\\n\\nLLMs do not reason better with more tools.\\n\\nThey reason better with:\\n\\n* Clear options\\n* Minimal noise\\n* Focused schemas\\n* Small decision trees\\n\\nToken bloat causes:\\n\\n* Tool confusion\\n* Hallucinated tool calls\\n* Slower planning\\n* Lower accuracy\\n* Higher cost\\n\\nThis is not theoretical.\\nThis is measurable.\\n\\n---\\n\\n## MCP Needs Platform Architecture \u2014 Not Just Protocols\\n\\nThis is where most teams fail.\\n\\nThey treat MCP like:\\n\\n> \u201cJust expose APIs as tools.\u201d\\n\\nBut MCP is not just transport.\\nIt is an **AI execution platform**.\\n\\nYou need:\\n\\n* Tool governance\\n* Context orchestration\\n* Discovery\\n* Authorization\\n* Policy\\n* Auditing\\n\\nThis is why naive MCP deployments become **Shadow MCP**.\\n\\n---\\n\\n## Shadow MCP: The Silent Compliance Risk\\n\\nShadow MCP is when:\\n\\n* Teams spin up MCP servers ad-hoc\\n* No registry\\n* No governance\\n* No audit\\n* No access control\\n* No policy\\n\\nNow tools silently enter AI contexts.\\n\\n**This is Shadow IT \u2014 but for AI.**\\n\\nToken bloat is often the first symptom.\\n\\n---\\n\\n## Best Practices for Token-Efficient MCP Design\\n\\nLet\u2019s get practical. Here are nine best practices to scale MCP tool catalogs without destroying your budget:\\n\\n### 1. Never Load All Tools\\n\\n**Rule:**\\nNo MCP client should ever inject all tools into context.\\n\\nEver.\\n\\nUse:\\n\\n* Search\\n* Discovery\\n* Ranking\\n* Filtering\\n\\n---\\n\\n### 2. Implement Tool Discovery\\n\\nYour agent should:\\n\\n1. Understand the task\\n2. Query a registry\\n3. Receive ranked candidates\\n4. Load only relevant tools\\n\\nThis is exactly what Claude\u2019s Tool Search Tool enables.\\n\\n---\\n\\n### 3. Use Tool Summaries First\\n\\nInstead of loading full schemas:\\n\\nStart with:\\n\\n* Name\\n* Description\\n* Capability tags\\n\\nThen expand only the chosen tool.\\n\\n---\\n\\n### 4. Enforce Context Budgets\\n\\nDefine:\\n\\n* Max tool count per request\\n* Max schema tokens\\n* Max metadata size\\n\\nReject or paginate when limits are exceeded.\\n\\n---\\n\\n### 5. Add Policy-Based Tool Filtering\\n\\nNot every agent should see every tool.\\n\\nFilter by:\\n\\n* Role\\n* Tenant\\n* Department\\n* Environment\\n* Compliance level\\n\\n---\\n\\n### 6. Add Tool Ranking\\n\\nUse:\\n\\n* Semantic search\\n* Tags\\n* Domain\\n* Past usage\\n* Cost\\n* Latency\\n\\nReturn top N candidates only.\\n\\n---\\n\\n### 7. Add Tool Versioning\\n\\nNever inject multiple versions of the same tool.\\n\\nUse:\\n\\n* Stable aliases\\n* Deprecation policies\\n* Controlled rollouts\\n\\n---\\n\\n### 8. Use Partial Schemas\\n\\nLoad:\\n\\n* Input shape only\\n* Output later\\n* Examples on demand\\n\\n---\\n\\n### 9. Add Audit Trails\\n\\nTrack:\\n\\n* Tool discovery\\n* Tool selection\\n* Tool execution\\n* Tool failures\\n\\nThis becomes your AI governance layer.\\n\\n---\\n\\n## MCP Is Becoming an AI Operating System\\n\\nThis is the real shift.\\n\\nMCP is no longer:\\n\\n> \u201cA protocol for tools.\u201d\\n\\nIt is becoming:\\n\\n> \u201cAn operating system for AI execution.\u201d\\n\\nWhich means:\\n\\n* Scheduling\\n* Discovery\\n* Security\\n* [Connect Authority](/mcp-registry-connect-authority/)\\n* Cost control\\n* Governance\\n* Observability\\n\\nToken bloat is the first scaling signal.\\n\\n---\\n\\n## Where HAPI MCP Fits in This Architecture\\n\\nHAPI MCP Stack was designed for exactly this future.\\n\\nNot as a toy MCP wrapper.\\nBut as a **Headless API platform for AI execution.**\\n\\nCore principles:\\n\\n* [API-first MCP servers](https://hapi.mcp.com.ai/)\\n* Registry-first discovery\\n* [Connect Authority](/tags/mcp-connect-authority) enforcement\\n* Zero-trust architecture\\n* [Enterprise-grade deployment](https://docs.mcp.com.ai/deployment/)\\n* Airgap-ready\\n* Cloud-ready\\n* VM-first friendly\\n\\nHAPI treats [MCP as **platform infrastructure**](https://docs.mcp.com.ai/introduction/architecture).\\n\\nNot prompt glue.\\n\\n---\\n\\n## The Future: Tool Search, Lazy Loading, and AI Gateways\\n\\nWe\u2019re entering the next phase of AI platforms:\\n\\n| Old              | New                   |\\n| ---------------- | --------------------- |\\n| Static tools     | Dynamic discovery     |\\n| Prompt injection | Context orchestration |\\n| Manual schemas   | Search-driven tools   |\\n| Flat catalogs    | Ranked registries     |\\n| No governance    | Policy enforcement    |\\n| Shadow MCP       | MCP Authority         |\\n\\nThis is exactly the direction Claude is moving.  \\nThis is exactly what SEP-1576 proposes.  \\nAnd this is exactly what enterprises need. HAPI MCP Stack is built for this future.\\n\\n---\\n\\n## Final Takeaways: How to Build MCP Systems That Scale\\n\\nIf you\'re building with MCP today, here is your roadmap:\\n\\n1. **Adopt tool discovery**\\n2. **Implement lazy loading**\\n3. **Use a registry**\\n4. **Add a connect authority**\\n5. **Enforce context budgets**\\n6. **Filter by policy**\\n7. **Rank tools**\\n8. **Audit everything**\\n9. **Kill shadow MCP**\\n10. **Treat MCP as platform infrastructure**\\n\\n---\\n\\n## MCP Without Token Discipline Will Fail\\n\\nToken bloat is not a bug.\\nIt\u2019s a design failure.\\n\\nThe teams that solve it now will own the next generation of AI platforms.\\n\\nThe teams that ignore it will build expensive demos that never scale.\\n\\n---\\n\\n## The question is simple:\\n\\nAre you building MCP tools...\\n\\nOr are you building an MCP platform?\\n\\n---\\n\\nIf you\'re serious about AI at scale, start designing for token efficiency now.\\n\\nBecause your AI is only as smart as the context you give it.\\n\\nBe HAPI, and Go Rebels! \u270a\ud83c\udffc\\n\\n---\\n\\n## FAQ: Token bloat in MCP\\n\\n**Q: What is token bloat in MCP?**  \\nA: Token bloat in MCP happens when an MCP client injects too many tool definitions (schemas + descriptions) into the model context, inflating prompt size before reasoning even starts.\\n\\n**Q: Why is token bloat a problem for MCP systems?**  \\nA: Token bloat increases cost per request, adds latency, degrades tool selection quality, and expands the security/compliance surface because more tools appear in context than are needed.\\n\\n**Q: What causes token bloat in MCP tool catalogs?**  \\nA: The most common cause is static tool injection: loading the full tool catalog into the prompt on every request instead of discovering and loading only what\u2019s needed.\\n\\n**Q: What is lazy loading for MCP tools?**  \\nA: Lazy loading means you load tool schemas only after the agent has identified relevant tools (usually via search/ranking), rather than preloading every tool into context.\\n\\n**Q: What is tool discovery in MCP?**  \\nA: Tool discovery is a step where the agent queries a registry (or authority layer) to retrieve a small, ranked set of candidate tools for a task, then loads only those.\\n\\n**Q: How do you mitigate token bloat when you have thousands of MCP tools?**  \\nA: Use search-based discovery + ranking, enforce tool/context budgets, filter tools by policy (role/tenant), and expand schemas on demand (summaries first, full schemas later).\\n\\n**Q: What is a context budget for MCP tools?**  \\nA: A context budget is a hard limit on how many tools or schema tokens can be included in a request. It keeps cost and latency predictable and prevents runaway prompts.\\n\\n**Q: Should I use FAQPage or QAPage schema for MCP Q&A content?**  \\nA: Use FAQPage when each question has a single authoritative answer you provide. Use QAPage only when users can submit answers (like forums).\\n\\n**Q: What is shadow MCP and how does it relate to token bloat?**  \\nA: Shadow MCP is ungoverned MCP tooling (servers/tools) that appear without centralized discovery, policy, or audit. It often shows up first as tool sprawl and token bloat.\\n\\n**Q: What\u2019s the best MCP architecture pattern to scale tool catalogs?**  \\nA: Registry-first discovery with an authority/policy layer: the agent searches a catalog, gets a small ranked shortlist, and only then loads the selected tool schemas for execution.\\n\\n\\n## References:\\n\\n- Feature Request: [Lazy Loading](https://github.com/anthropics/claude-code/issues/7336) for MCP Servers and Tools\\n- https://venturebeat.com/orchestration/claude-code-just-got-updated-with-one-of-the-most-requested-user-features\\n- [Tool search tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)\\n  - [X Post](https://x.com/trq212/status/2011523109871108570) with more details.\\n- [SEP-1576: Mitigating Token Bloat in MCP](https://github.com/modelcontextprotocol/modelcontextprotocol/issues/1576)"},{"id":"/skills/sdks-are-dead","metadata":{"permalink":"/skills/sdks-are-dead","source":"@site/blog/skills/sdks-are-dead.mdx","title":"SDKs are Dead: Embracing Agent Skills for Automation","description":"Discover why traditional SDKs are becoming obsolete in the age of Agentic AI. Learn how Agent Skills enable smarter, more adaptable applications without rigid code structures.","date":"2026-01-19T18:49:49.000Z","tags":[{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"},{"inline":false,"label":"Agentic AI","permalink":"/tags/agentic-ai","description":"Agentic AI refers to artificial intelligence systems that can autonomously perform tasks, make decisions, and interact with their environment to achieve specific goals.\\n"},{"inline":false,"label":"Skills","permalink":"/tags/skills","description":"Skills refer to specific capabilities or competencies that AI models can utilize to perform tasks, often through integration with external tools or APIs.\\n"}],"readingTime":9.4,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"SDKs are Dead: Embracing Agent Skills for Automation","description":"Discover why traditional SDKs are becoming obsolete in the age of Agentic AI. Learn how Agent Skills enable smarter, more adaptable applications without rigid code structures.","authors":["adrian"],"tags":["ai-integration","agentic-ai","skills"],"keywords":["agentic ai","future of sdk development","ai-powered automation","replacing sdks with ai","building with agentic ai","claude code skills","agent skills","sdk alternatives","mcp servers","ai automation tools"],"image":"/img/skills/agentic-ai-vs-sdks.png"},"unlisted":false,"prevItem":{"title":"How to Scale MCP to Thousands of Tools Without Destroying Your Budget","permalink":"/mcp-at-scale/how-to-scale-mcp-to-thousands-of-tools-without-distroying-budget"},"nextItem":{"title":"Unlocking Podcast Insights with MCP","permalink":"/lenny-rachitsky-podcast-mcp-server"}},"content":"import Head from \'@docusaurus/Head\';\\n\\nexport const faqJsonLd = {\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"FAQPage\\",\\n  \\"mainEntity\\": [\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Are SDKs really dead?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"SDKs aren\'t completely dead yet, but they\'re becoming less relevant for modern flexible applications. They still have their place for low-level system programming, game development, and enterprise software with strict compliance needs. However, for applications requiring flexibility and adaptability, Agentic AI with Agent Skills offers a superior alternative.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What are Agent Skills?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Agent Skills are capabilities that enable AI agents to perform tasks dynamically by reasoning about goals rather than following rigid code paths. Claude Code Skills, for example, allow developers to define what should happen rather than how, letting the AI determine the best approach.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"How do Agent Skills differ from traditional SDKs?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"SDKs require extensive coding to handle various scenarios with static, predetermined logic. Agent Skills use AI to reason and adapt dynamically, allowing applications to respond to new challenges without manual updates. This shift from deterministic code to intelligent reasoning makes systems more flexible and maintainable.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Can I replace my existing SDK-based automations with Agent Skills?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Yes, as demonstrated by Brian Casel who rebuilt his n8n workflow as a Claude Code Skill. Many SDK-based automations can be replaced with Skills, including API integrations, testing workflows, and data processing pipelines. Check platforms like skills.sh for examples of Skills replacing complex SDK implementations.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What is the Model Context Protocol (MCP)?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"The Model Context Protocol (MCP) is a standard developed by Anthropic that revolutionized how AI systems interact with APIs. MCP Servers provide AI-powered API interfaces that enable intelligent responses and actions, reducing the need for complex SDKs and manual integration work.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"What are the benefits of Agentic AI over traditional development?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Agentic AI enables goal-oriented design, dynamic adaptation to new scenarios, continuous learning and improvement, easier integration with AI services, and allows developers to focus on user experience rather than complex implementation details. This results in more maintainable and adaptable applications.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"How do I get started with Agent Skills?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Start by defining high-level goals for your application rather than step-by-step instructions. Explore platforms like Claude Code Skills and browse community-built Skills at agentskills.io or skills.sh. Focus on what you want to achieve and let the AI determine the implementation approach.\\"\\n      }\\n    },\\n    {\\n      \\"@type\\": \\"Question\\",\\n      \\"name\\": \\"Will SDKs be completely replaced by AI?\\",\\n      \\"acceptedAnswer\\": {\\n        \\"@type\\": \\"Answer\\",\\n        \\"text\\": \\"Not entirely and not immediately\u2014SDKs may remain relevant for another decade or more in specific domains like game development, embedded systems, and highly regulated enterprise software. However, for most modern web applications and automations, Agentic AI approaches are becoming the preferred choice.\\"\\n      }\\n    }\\n  ]\\n};\\n\\n<Head>\\n  <script type=\\"application/ld+json\\">\\n    {JSON.stringify(faqJsonLd)}\\n  <\/script>\\n</Head>\\n\\nWhat\'s the lesson from [Brian Casel\'s experience](https://www.youtube.com/watch?v=Jo168H2m5lw) about the future of SDKs, no-code workflows, and automation?\\n\\nIn short: **SDKs are dead** - well, at least for many use cases in modern application development.\\n\\n\x3c!-- truncate --\x3e\\n\\nBrian Casel, a well-known developer and entrepreneur, shared his experience building an AI-powered image generation automation. He spent a full week constructing a complex automation in [n8n](https://n8n.io) (a popular no-code workflow engine) for AI image generation \u2014 but ultimately scrapped it and rebuilt the entire thing as a Claude Code Skill instead. \\n\\nHis conclusion? **Claude Code Skills are better suited for flexible, maintainable, and powerful automations than traditional no-code workflows for many use cases.**\\n\\n## Why SDKs Are Dying\\n\\nIn the age of Agentic AI, traditional Software Development Kits (SDKs) are becoming increasingly obsolete for many applications. Here\'s why:\\n\\n**The Problem with SDKs:**\\n- SDKs are rigid structures that require extensive coding to handle various scenarios\\n- They lock developers into specific implementation patterns\\n- Updates and changes require manual code rewrites\\n- Error handling and edge cases multiply code complexity\\n- As Brian Casel demonstrated, even no-code platforms like [n8n](https://n8n.io/) can become complex, brittle, and hard to maintain when building sophisticated automations\\n\\n**The Agentic AI Advantage:**\\n\\n[Claude Code Skills](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview) and similar agentic approaches flip this model on its head. Instead of prescribing exactly how to accomplish a task, you define:\\n- High-level goals and constraints\\n- What success looks like\\n- The AI reasons about the best approach dynamically\\n\\nThis shift from static, deterministic code to intelligent reasoning means applications can evolve and respond to new challenges without constant manual updates.\\n\\n[Anthropic](https://www.anthropic.com/) did it again. Just as they revolutionized the AI-API landscape with the Model Context Protocol (MCP) and MCP Servers, they\'re now pioneering how we build automations and applications with [Agent Skills](https://agentskills.io).\\n\\n## How to Build with Agentic AI\\n\\nTo leverage the power of Agentic AI, developers should focus on these key principles:\\n\\n### 1. Goal-Oriented Design\\nDefine **what** the application should achieve rather than **how** to achieve it step-by-step. This allows the AI to determine the best course of action based on context and constraints.\\n\\n### 2. Dynamic Adaptation\\nUtilize AI\'s ability to adapt to new inputs and scenarios. This reduces the need for:\\n- Hard-coded logic branches\\n- Extensive conditional statements\\n- Manual handling of edge cases\\n\\n### 3. Continuous Learning\\nImplement feedback loops where the AI can learn from its actions and improve over time, enhancing the application\'s performance and reliability.\\n\\n### 4. Integration with AI Services\\nLeverage existing AI platforms and services that offer agentic capabilities, reducing the need to build complex systems from scratch.\\n\\n### 5. Focus on User Experience\\nWith AI handling the complexity, developers can concentrate on creating intuitive and engaging user experiences.\\n\\n## Real-World Examples of Agentic AI\\n\\n### Agent Skills in Action\\n\\nAs demonstrated by Brian Casel, Claude Code Skills allow for building flexible automations that can adapt to changing requirements without extensive rewrites.\\n\\n**Community Examples from [mcp.com.ai skills](https://skills.sh/?q=mcp-com-ai):**\\n\\n* **[API To MCP](https://skills.sh/mcp-com-ai/api-to-mcp)** - Automates the conversion of REST APIs and deployment into MCP Servers without writing SDK code\\n* **[Test Remote MCPs](https://skills.sh/mcp-com-ai/mcp-server-evaluations-skills/mcp-server-evaluations)** - Automates testing of remote MCP servers without SDK dependencies or language-specific requirements\\n\\n**Community-Built Skills:**\\n* Automating [content generation](https://skills.sh/?q=content) workflows\\n* Dynamic [data processing](https://skills.sh/?q=data+process) pipelines\\n* Intelligent [customer support](https://skills.sh/?q=customer) systems\\n\\n### Other AI Services\\n\\n* **Code Copilots**: AI-powered coding assistants that help developers write code faster with fewer errors\\n* **Custom AI Agents**: Tailored agents for specific tasks or workflows. Examples:\\n  * The `HAPI MCP Visual Identity System Agent` - Helps maintain and enhance visual identity systems, creating assets dynamically without rigid templates (inspired by Brian\'s example)\\n  * [VS Code AI Agents](https://code.visualstudio.com/docs/copilot/customization/custom-agents) - Assist in code generation, debugging, and optimization\\n* **AI-Powered APIs (MCP Servers)**: APIs that leverage AI to provide intelligent responses and actions, eliminating the need for complex SDKs\\n\\n## The Future is Agentic\\n\\nThe future of application development lies in embracing Agentic AI. As traditional SDKs become less relevant, anyone building software\u2014whether developers or non-developers\u2014must adapt to this new paradigm by focusing on:\\n\\n- **High-level goals** instead of step-by-step instructions\\n- **Dynamic adaptation** over rigid code structures\\n- **Continuous learning** rather than static implementations\\n\\nBy doing so, they can build smarter, more resilient applications that evolve with changing needs and challenges.\\n\\nCreating systems that can think and adapt on their own unlocks new possibilities not only in software development but across industries and specialized domains. \\n\\n**The Five Pillars of Agentic Success:**\\n1. **Design** - Think in goals, not steps\\n2. **Adapt** - Let AI handle variations\\n3. **Learn** - Improve through feedback\\n4. **Integrate** - Leverage existing AI services\\n5. **Evolve** - Continuously refine based on outcomes\\n\\nAgility, innovation, and flexibility are the cornerstones of successful applications in the age of Agentic AI. This shift clearly indicates that the era of rigid SDKs is coming to an end. The future belongs to those who can harness the power of Agentic AI to create flexible, intelligent systems that can think and adapt independently.\\n\\n## The Reality Check\\n\\nDon\'t get me wrong\u2014**SDKs aren\'t entirely dead yet**. They\'ll probably remain relevant for another decade or more in certain scenarios:\\n\\n- **Low-level system programming** where direct hardware control is needed\\n- **Performance-critical applications** like game development and real-time systems\\n- **Embedded systems** with strict resource constraints\\n- **Enterprise software** with rigid compliance and certification requirements\\n- **Specialized domains** with deterministic behavior requirements\\n\\nHowever, for modern web applications, automations, and business logic\u2014areas requiring flexibility and adaptability\u2014Agentic AI with Agent Skills offers a superior alternative.\\n\\n## Key Takeaways\\n\\nTeams and developers should embrace new technologies and paradigms that enhance productivity and innovation. By shifting focus from rigid SDKs to dynamic, goal-oriented AI systems, people can:\\n\\n- \u2705 Build more maintainable systems\\n- \u2705 Reduce time spent on edge cases and error handling\\n- \u2705 Create applications that adapt to user needs automatically\\n- \u2705 Focus on user experience instead of implementation details\\n- \u2705 Unlock new possibilities in automation and integration\\n\\nRebels, take note: **the future is agentic, and it\'s time to adapt.**  \\nBe HAPI, and Go Rebels! \u270a\ud83c\udffc\\n\\n## FAQ: Agent Skills and the Future of SDKs\\n\\n**Q: Are SDKs really dead?**  \\nA: Not completely\u2014they\'ll remain relevant for low-level programming, game development, and compliance-heavy enterprise software. But for most modern applications needing flexibility, Agentic AI offers better alternatives.\\n\\n**Q: What are Agent Skills?**  \\nA: Agent Skills are capabilities that enable AI agents to perform tasks by reasoning about goals rather than following rigid code. You define what should happen; the AI figures out how.\\n\\n**Q: How do Agent Skills differ from traditional SDKs?**  \\nA: SDKs require extensive coding for every scenario with static logic. Agent Skills use AI to reason and adapt dynamically, responding to new challenges without manual updates.\\n\\n**Q: Can I replace my existing automations with Agent Skills?**  \\nA: Yes! Brian Casel demonstrated this by replacing his week-long [n8n](https://n8n.io) workflow with a Claude Code Skill. Check platforms like [skills.sh](https://skills.sh/) for examples of Skills replacing SDK implementations.\\n\\n**Q: What is the Model Context Protocol (MCP)?**  \\nA: MCP is Anthropic\'s standard that revolutionized AI-API interactions. MCP Servers provide AI-powered API interfaces, reducing the need for complex SDKs and manual integration work.\\n\\n**Q: What are the benefits of Agentic AI over traditional development?**  \\nA: Goal-oriented design, dynamic adaptation, continuous learning, easier integration, and focus on user experience. This results in more maintainable and adaptable applications.\\n\\n**Q: How do I get started with Agent Skills?**  \\nA: Define high-level goals for your application instead of step-by-step instructions. Explore Claude Code Skills and browse community-built Skills at agentskills.io or skills.sh.\\n\\n**Q: Will SDKs be completely replaced by AI?**  \\nA: Not for another decade or more in domains like game development, embedded systems, and highly regulated software. But for most modern web apps and automations, agentic approaches are becoming the preferred choice.\\n\\n## References\\n\\n\x3c!-- [![Replacing my n8n workflow with a Claude Code Skill](https://img.youtube.com/vi/Jo168H2m5lw/0.jpg)](https://www.youtube.com/watch?v=Jo168H2m5lw) --\x3e\\n- [Replacing my n8n workflow with a Claude Code Skill](https://www.youtube.com/watch?v=Jo168H2m5lw)"},{"id":"/lenny-rachitsky-podcast-mcp-server","metadata":{"permalink":"/lenny-rachitsky-podcast-mcp-server","source":"@site/blog/lenny-rachitsky-podcast-mcp-server.mdx","title":"Unlocking Podcast Insights with MCP","description":"Discover how the Lenny Rachitsky Podcast Transcripts MCP Server empowers marketers, product managers, and creators to extract insights and repurpose content effortlessly.","date":"2026-01-16T13:19:54.000Z","tags":[{"inline":false,"label":"API-First","permalink":"/tags/api-first","description":"API-First is a design approach that prioritizes the development of APIs before building the actual application, ensuring better integration and scalability.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"}],"readingTime":5.01,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Unlocking Podcast Insights with MCP","description":"Discover how the Lenny Rachitsky Podcast Transcripts MCP Server empowers marketers, product managers, and creators to extract insights and repurpose content effortlessly.","authors":["adrian"],"tags":["api-first","ai-integration"],"keywords":["podcast transcript analysis","mcp for marketers","lenny rachitsky podcast insights","ai-powered content repurposing","product management podcast tools","deploy mcp server for content creators","content marketing with mcp"],"image":"/img/screenshots-demos/chatMCP-LennyRachitsky.png"},"unlisted":false,"prevItem":{"title":"SDKs are Dead: Embracing Agent Skills for Automation","permalink":"/skills/sdks-are-dead"},"nextItem":{"title":"The MCP Connect Authority: A Zero Trust Architecture for AI","permalink":"/mcp-registry-connect-authority"}},"content":"import ReactPlayer from \'react-player\'\\n\\nTranscripts from podcasts are treasure troves of insights, ideas, and stories. However, accessing and utilizing this wealth of information can be challenging for marketers, product managers, and content creators\u2014especially those without deep technical expertise.\\n\\n[Lenny Rachitsky posted on LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7417011928159629313?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7417011928159629313%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29) about sharing transcripts of his podcast episodes, I decided to format the transcripts for easy consumption by language models and AI tools.\\n\\n\x3c!-- truncate --\x3e\\n\\nAt this point, you should know about MCP ([Model Context Protocol](https://modelcontextprotocol.io/docs/getting-started/intro)) and how it enables secure, scalable AI servers. In this post, I\u2019m excited to introduce the **Lenny Rachitsky Podcast Transcripts MCP Server**\u2014a powerful solution designed specifically for marketers, product managers, and creators to unlock the full potential of podcast content.\\n\\n## What is MCP (Model Context Protocol) and Why Should You Care?\\n\\nModel Context Protocol (MCP) is revolutionizing how businesses, marketers, and creators (well, everyone) interact with AI. MCP provides a standardized way to build, manage, and deploy AI servers. With MCP, you can easily build AI-powered applications that analyze, summarize, and extract insights from large content archives\u2014like podcasts, webinars, and interviews\u2014without deep technical expertise.\\n\\n## Introducing the Lenny Rachitsky Podcast Transcripts MCP Server\\n\\nIf you\u2019re a marketer, product manager, or content creator looking to tap into the wisdom of Lenny Rachitsky\u2019s podcast, the new MCP-powered Podcast Transcripts API is your gateway. This solution makes it easy to search, analyze, and repurpose podcast content for marketing, product research, and content creation.\\n\\n### Key Features for Marketers and Product Teams\\n\\n- **Instant Podcast Search**: Find episodes, guests, and topics in seconds using natural language queries.\\n- **Content Summarization**: Generate summaries and key takeaways for newsletters, blogs, or social media.\\n- **Topic & Keyword Extraction**: Identify trending topics and guest insights for campaign planning.\\n- **Personalized Recommendations**: Build tools that suggest relevant episodes to your audience or team.\\n\\n## How the Lenny Rachitsky Podcast MCP Server Works\\n\\nFollowing this approach, the MCP server ingests and indexes Lenny Rachitsky\u2019s podcast transcripts, making them accessible via a simple REST API. In fact, anyone can [deploy their own instance of this MCP server](https://docs.mcp.com.ai/deployment/cloud/cloudflare) to analyze different podcasts or content archives.\\n\\nHere\u2019s how it works under the hood:\\n\\n### 1. Automated Ingestion & Indexing\\n\\n- **Cloudflare Workers** handle transcript ingestion and processing.\\n- **D1 Database** stores episode metadata and transcript chunks.\\n- **Vectorize** enables fast, AI-powered semantic search across all transcripts.\\n\\n### 2. Scalable API Access\\n\\n- Query the transcripts via a simple REST API.\\n- Retrieve episode details, transcript snippets, and keyword highlights.\\n- Integrate with your marketing dashboards, product research tools, or content workflows.\\n\\n### 3. Built for Non-Technical Users\\n\\n- No coding required to get started\u2014just connect any MCP-compatible AI tool.\\n- The MCP Server consumes the data from the API trascripts and makes it available for AI models.\\n- Designed with marketers and product managers in mind.\\n\\n## Demo: Searching Lenny Rachitsky\'s Podcast Transcripts\\n\\n\\n<ReactPlayer\\n  src=\'https://youtu.be/_lmQTlzGWSQ\'\\n  style={{ width: \'90%\', height: \'auto\', aspectRatio: \'4/3\' }}\\n  controls\\n/>\\n\\n## Example Use Cases\\n\\n- **Content Marketing**: Instantly find and repurpose podcast insights for blog posts, newsletters, and social media.\\n- **Product Research**: Analyze discussions on product management, growth, and startup strategies.\\n- **Creator Tools**: Build AI chatbots or assistants that answer questions about podcast content.\\n\\n## How to Get Started\\n\\n- **API Endpoint**: [https://lenny-rachitsky.search.mcp.com.ai](https://lenny-rachitsky.search.mcp.com.ai)\\n- **OpenAPI Spec**: [Podcast Transcripts YAML](https://docs.mcp.com.ai/servers-apis/openapi/podcast-transcripts.yaml)\\n- **MCP Server**: [https://lenny-rachitsky.run.mcp.com.ai/mcp](https://lenny-rachitsky.run.mcp.com.ai/mcp)\\n\\n## Why MCP is the Future for Marketers and Product Teams\\n\\n- **Enterprise-Grade**: Deploy on your own infrastructure or trusted cloud.\\n- **Scalable & Fast**: Handles thousands of transcripts and queries with ease.\\n- **Customizable**: Adapt the solution for any podcast, webinar, or content archive.\\n\\n---\\n\\n## Deploy Your Own MCP Server for Content Archives\\n\\nYou can deploy your own instance of the Lenny Rachitsky Podcast Transcripts MCP Server or any other content archive using the [HAPI CLI](https://docs.mcp.com.ai/components/hapi-server/hapi-cli), [Docker](https://docs.mcp.com.ai/deployment/docker), to the cloud provider of your choice, for now Cloudflare Workers and Fly.io are supported.\\n\\n```bash\\nhapi serve lenny-rachitsky-podcast --port 3030 --headless --url https://lenny-rachitsky.search.mcp.com.ai --openapi https://docs.mcp.com.ai/servers-apis/openapi/podcast-transcripts.yaml\\n```\\n\\nFind the MCP Server in the [MCP Registry](https://registry.modelcontextprotocol.io/?q=lenny-rachitsky) and connect it to your favorite AI tools and language models.\\n\\n## Final Thoughts\\n\\nWith MCP, you can unlock the full value of podcast content\u2014turning hours of audio into actionable insights for your marketing, product, or content strategy. Whether you\u2019re a non-technical marketer or a product manager, MCP makes advanced AI accessible and secure.\\n\\n## Join the Revolution - Future features\\n\\nWhat would you like to see next? Here are some ideas for future enhancements to the Lenny Rachitsky Podcast Transcripts MCP Server:\\n\\n- [ ] **AI-Powered Summarization**: Generate episode summaries and key takeaways automatically.\\n- [ ] **Advanced Analytics**: Track listener engagement and topic trends over time.\\n- [ ] **Custom Integrations**: Connect with your favorite marketing and product tools seamlessly.\\n- [ ] **ChatGPT App Integration**: Use the MCP server directly within ChatGPT for interactive podcast exploration.\\n- [ ] **More Podcast Archives**: Expand to include transcripts from other popular podcasts.\\n\\nIdeas? Feedback? Reach out on [LinkedIn](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=adrianescutia) or join the [HAPI MCP Discord Community](https://discord.gg/uTPRBnSV). Let\u2019s build the future of AI-powered content together, Be HAPI and Go Rebels! \u270a\ud83c\udffc\\n\\n<a class=\\"libutton\\" href=\\"https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=adrianescutia\\" target=\\"_blank\\">Follow on LinkedIn</a>\\n\\n---\\n\\n## Disclaimer\\n\\nThis archive is for educational and research purposes. All content belongs to Lenny\'s Podcast and the respective guests. Please visit the official YouTube channel to support the creators.\\n\\n## Transcript Archive Details\\n- [Dropboxh](ttps://www.dropbox.com/scl/fo/yxi4s2w998p1gvtpu4193/AMdNPR8AOw0lMklwtnC0TrQ?rlkey=mwwj2oygno72le23o6kvzq5wq&st=75ga9ff9&dl=0) - Lenny\'s Podcast Transcripts (all episodes in plain text format).\\n- [GitHub Repository](https://github.com/la-rebelion/lennys-podcast-transcripts) - Forked from [Claire Vo](https://github.com/cvolawless) repository. Contains the transcripts in markdown format with frontmatter metadata."},{"id":"/mcp-registry-connect-authority","metadata":{"permalink":"/mcp-registry-connect-authority","source":"@site/blog/mcp-registry-connect-authority/index.mdx","title":"The MCP Connect Authority: A Zero Trust Architecture for AI","description":"Defining the MCP Connect Authority model: separating control-plane governance from data-plane traffic to enable secure, scalable, and decentralized AI systems.","date":"2026-01-12T13:30:36.000Z","tags":[{"inline":false,"label":"Architecture","permalink":"/tags/architecture","description":"The structural design and organization of systems, components, and their interactions within a software or hardware environment.\\n"},{"inline":false,"label":"MCP Connect Authority","permalink":"/tags/mcp-connect-authority","description":"A Connect Authority is a trusted entity that issues connection credentials and governs access to services, enabling secure and authorized connections.\\n"},{"inline":false,"label":"Zero Trust","permalink":"/tags/zero-trust","description":"Zero Trust is a security model that requires strict identity verification for every person and device trying to access resources on a private network, regardless of whether they are inside or outside the network perimeter.\\n"},{"inline":false,"label":"MCP Registry","permalink":"/tags/mcp-registry","description":"The MCP Registry is a centralized directory that maintains metadata about available MCP-compliant services, tools, and resources for discovery and access by clients.\\n"},{"inline":false,"label":"MCP Connect Authority","permalink":"/tags/mcp-connect-authority","description":"A Connect Authority is a trusted entity that issues connection credentials and governs access to services, enabling secure and authorized connections.\\n"}],"readingTime":4.04,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"The MCP Connect Authority: A Zero Trust Architecture for AI","description":"Defining the MCP Connect Authority model: separating control-plane governance from data-plane traffic to enable secure, scalable, and decentralized AI systems.","image":"/img/mcp-connect-authority/mcp-connect-authority.png","tags":["architecture","connect-authority","zero-trust","mcp-registry","connect-authority"],"keywords":["mcp","connect authority","registry","mcp gateway","zero trust","hapi","distributed enforcement"],"authors":["adrian"]},"unlisted":false,"prevItem":{"title":"Unlocking Podcast Insights with MCP","permalink":"/lenny-rachitsky-podcast-mcp-server"},"nextItem":{"title":"MCP Registry vs Gateway: Why Connect Authority Wins","permalink":"/mcp-registry-connect-authority/beyond-mcp-gateways"}},"content":"import InlineSVG from \'@site/src/components/SyncImage\';\\n\\nIn the rapidly evolving landscape of the **Model Context Protocol (MCP)**, architects are facing a critical decision: how to secure and govern connections between AI clients and a sprawling ecosystem of tools and data servers.\\n\\nThe traditional answer is a **Gateway**\u2014a centralized proxy that inspects every byte.\\nThe modern answer is a **Connect Authority**\u2014a distributed Zero Trust model that separates permission from traffic.\\n\\n\x3c!-- truncate --\x3e\\n\\nThis detailed guide introduces the **MCP Connect Authority** architecture, a standard championed by HAPI to enable scalable, secure, and governed AI ecosystems without the bottlenecks of a central data-plane proxy.\\n\\n\\n## The Architectural Shift\\n\\nThe instinct in microservices was often \\"put a gateway in front of it.\\" In the world of decentralized AI agents and remote tools, however, forcing all traffic through a single pipe creates unacceptable latency, operational fragility, and a massive security target.\\n\\nWe argue for a cleaner architectural split:\\n\\n*   **Control Plane (The Registry):** Decides *who* connects.\\n*   **Data Plane (The Server):** Enforces *what* happens.\\n\\nBy treating the MCP Registry as a **Connect Authority**, we remove the need for a gateway to ever see the traffic, while maintaining stronger governance than a gateway could ever provide.\\n\\n### The Core Concept: Permission \u2260 Proxy\\n\\nA **Gateway** is a data-plane bottleneck. It answers: *\\"Let me route this packet for you.\\"*\\nA **Connect Authority** is a control-plane enabler. It answers: *\\"Are you allowed to connect right now?\\"*\\n\\nIf the answer is yes, the Authority issues a **Connect Descriptor**\u2014a digital \\"boarding pass\\" that allows the client to fly directly to the destination.\\n\\n## How it Works: The Connect Descriptor\\n\\nThe keystone of this architecture is the **Connect Descriptor**, primitives defined in the [MCP Connect Authority Spec](#).\\n\\n1.  **Discovery & Auth:** The Client asks the Registry for access to a specific tool or server.\\n2.  **Issuance:** The Registry acts as the Connect Authority. It checks policy, subscription status, and server health. If approved, it signs a short-lived **Connect Descriptor (JWT)**.\\n3.  **Direct Connection:** The Client connects **directly** to the HAPI MCP Server using streamable HTTP, presenting the descriptor in the headers.\\n4.  **Distributed Enforcement:** The Server (not a gateway) validates the descriptor using the Registry\'s public keys and enforces runtime policies (rate limiting, user auth, logging).\\n\\n<InlineSVG name=\\"mcp-registry-connect-authority-flow\\" \\n  alt=\\"HAPI MCP Registry Connect Authority Flow Diagram\\"\\n  width=\\"80%\\"\\n  className=\\"center-image\\"\\n/>\\n\\n## Why This Wins: Authority vs. Gateway\\n\\nWhy move to this model? Because it aligns with **Zero Trust** principles while solving the practical scaling problems of AI agents.\\n\\n| Feature | Traditional MCP Gateway | MCP Connect Authority |\\n| :--- | :--- | :--- |\\n| **Traffic Path** | Indirect (Client \u2192 Gateway \u2192 Server) | **Direct** (Client \u2192 Server) |\\n| **Bottleneck** | **High** (All data flows through one point) | **None** (Control plane traffic is tiny) |\\n| **Failure Mode** | Gateway down = System offline | Registry down = No *new* connects; existing work continues |\\n| **Security** | Centralized Honeypot (Sees all data) | **Zero Trust** (Registry sees no payload data) |\\n| **Enforcement** | Centralized Policy Engine | **Distributed** (Enforced at the edge) |\\n| **Cost** | High (Bandwidth & Compute) | **Low** (Signature generation only) |\\n\\n## Key Capabilities\\n\\n### 1. Zero Trust by Design\\nIn this model, network location means nothing. A client cannot connect to a HAPI server simply because it has the IP address. It requires a valid, time-limited cryptographic proof (the Descriptor) from the Authority. This is true **Zero Trust MCP Architecture**.\\n\\n### 2. Runtime Effective Moderation\\n\\"Governance without a gateway\\" sounds like a paradox, but it is achieved through specific mechanics:\\n*   **Short TTLs:** Descriptors expire in 30-120 seconds.\\n*   **Refresh Enforcement:** Servers can force clients to refresh their descriptors.\\n*   **Instant Revocation:** If a server is compromised or policy changes, the Registry simply stops issuing descriptors. The \\"hard shutoff\\" happens immediately at the next refresh interval.\\n\\n### 3. Scalability (Social and Technical)\\nTechnically, this removes the single point of failure and latency of a proxy. Socially, it allows the ecosystem to scale. A central Registry can govern thousands of independent servers without needing to host or route their traffic. It is the only viable path for a global, federated MCP ecosystem.\\n\\n## Reference Implementations\\n\\nThe HAPI ecosystem is building this standard today.\\n\\n*   **HAPI MCP Registry:** Acts as the Connect Authority, implementing the `POST /v1/connect` endpoint.\\n*   **HAPI MCP Servers:** Native support for validating Connect Descriptors and enforcing distributed policy.\\n*   **MCP Clients:** Updated SDKs that support the \\"Get Descriptor \u2192 Connect\\" flow seamlessly.\\n\\n## Conclusion\\n\\nYou don\'t need a gateway to have governance. You need **Authority**.\\n\\nBy adopting the MCP Connect Authority model, we move past the brittle, centralized proxy architectures of Web 2.0 and embrace a decentralized, secure, and performant standard for the Agentic AI era.\\n\\n*   [Read the Full Architecture Deep Dive](/mcp-registry-connect-authority/beyond-mcp-gateways)\\n*   [Review the Technical Specification](#) (coming soon)\\n\x3c!-- *   [Review the Technical Specification](/mcp-registry-connect-authority/mcp-connect-authority-spec) --\x3e\\n*   [Detailed Comparison: Why Authority Beats Gateway](/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway)\\n\\n**Be HAPI.** Governance is solved."},{"id":"/mcp-registry-connect-authority/beyond-mcp-gateways","metadata":{"permalink":"/mcp-registry-connect-authority/beyond-mcp-gateways","source":"@site/blog/mcp-registry-connect-authority/beyond-mcp-gateways.mdx","title":"MCP Registry vs Gateway: Why Connect Authority Wins","description":"Explore the differences between MCP Registries and Gateways, and understand why a Connect Authority is the superior choice for enabling secure, scalable MCP connections without a gateway.","date":"2026-01-12T02:55:49.000Z","tags":[{"inline":false,"label":"Architecture","permalink":"/tags/architecture","description":"The structural design and organization of systems, components, and their interactions within a software or hardware environment.\\n"},{"inline":false,"label":"MCP Connect Authority","permalink":"/tags/mcp-connect-authority","description":"A Connect Authority is a trusted entity that issues connection credentials and governs access to services, enabling secure and authorized connections.\\n"}],"readingTime":9.19,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"MCP Registry vs Gateway: Why Connect Authority Wins","description":"Explore the differences between MCP Registries and Gateways, and understand why a Connect Authority is the superior choice for enabling secure, scalable MCP connections without a gateway.","tags":["architecture","connect-authority"],"keywords":["mcp","registry","gateway","connect authority","hapi","architecture","mcp-registry"],"image":"/img/mcp-connect-authority/mcp-beyond-gateway.png"},"unlisted":false,"prevItem":{"title":"The MCP Connect Authority: A Zero Trust Architecture for AI","permalink":"/mcp-registry-connect-authority"},"nextItem":{"title":"Why a Registry + Connect Authority Beats a Gateway","permalink":"/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway"}},"content":"The [MCP Registry](https://registry.modelcontextprotocol.io) is designed as a centralized catalog and metadata service for MCP (Model Context Protocol) components. It provides discovery, verification, and governance capabilities for MCP clients and servers. The *HAPI MCP Registry* does not proxy traffic; instead, it acts as a **mcp connection authority**, issuing short-lived **mcp connect descriptor** tokens that authorize clients to connect directly to MCP Servers.\\n\\n\x3c!-- truncate --\x3e\\n\\n### The Architectural Dilemma: MCP Registry vs Gateway\\n\\nAt a high level, architects face a choice: treating the Registry as a control-plane for discovery and governance, or deploying a Gateway to sit on the data-plane and proxy traffic. This article argues for a **registry based mcp architecture** \u2014 one that provides robust **mcp connection governance** without the operational overhead of a gateway.\\n\\nWe will explore **mcp gateway alternatives** such as connect-authority issuance and distributed enforcement, demonstrating why this **mcp connection authority** model is often the superior choice for scalable, secure AI systems.\\n\\n\x3c!-- truncate--\x3e\\n\\nAI-native applications require scalable, secure, and manageable architectures. **Just as with microservices**, the same security and governance principles apply to MCP-based systems. Throughout MCP\'s brief yet rapid evolution, [security breaches](https://authzed.com/blog/timeline-mcp-breaches) and failures have taught us valuable lessons. In response, the MCP Registry was created, offering developers a dependable, community-driven platform to discover and share MCP servers, all while ensuring security and building trust.\\n\\nWhat the official MCP Registry actually promises today:\\n\\nThe official MCP Registry was launched as an open catalog + REST API for discovery and standardized metadata, with moderation and namespace verification. It is explicitly positioned as a \\"single source of truth\\" that sub-registries build on.\\n\\nKey constraints that matter for a gateway discussion:\\n\\n* It\'s metadata, not package hosting.\\n* It\'s designed primarily for programmatic consumption by sub-registries, not end-users/clients directly (at least today).\\n* Security scanning is delegated to package registries and/or sub-registries in the MVP.\\n* The API went into an \\"API freeze\\" period (v0.1), signaling stability, but it\'s still evolving toward GA.\\n\\nThe Registry can enable a gateway, but it\'s not trying to be one.\\n\\n## Why not a Gateway?\\n\\n*\\"Can the MCP Registry become an MCP Gateway?\\"*\\n\\nThat question hides a deeper one:\\n\\n> **Can we get gateway-level control without turning the Registry into a fragile, high-risk data plane?**\\n\\nThe answer is **yes** \u2014 *if we\'re precise about what a gateway actually is*.\\n\\n### Why not proxy MCP traffic?\\n\\nProxying MCP traffic creates a central data-plane that inspects or routes every session. That introduces latency, inspection risks, and operational complexity. A better approach for many deployments is to avoid proxying and rely on **mcp connect descriptor** issuance and server-side validation. This keeps the control plane (the Registry) strictly separate from the data plane.\\n\\n## Control-Plane vs Data-Plane in MCP\\n\\nFirst of all, we need to clarify what a gateway *usually* means. This distinction is critical for understanding **mcp control plane architecture** versus **mcp data plane design**.\\n### A Registry is usually **control-plane**\\n\\nIt answers questions like:\\n\\n* What exists?\\n* Where does it live?\\n* What does it support?\\n* Who owns it?\\n* Is it verified?\\n* Is it allowed?\\n\\nThink: **catalogs, metadata, governance, discovery**.\\n\\n### A Gateway is usually **data-plane**\\n\\nIt answers questions like:\\n\\n* I connect to *one* endpoint\\n* Traffic flows *through* it\\n* It authenticates\\n* It enforces policy\\n* It rate-limits\\n* It observes\\n* It transforms\\n\\nThink: **proxying, routing, runtime enforcement**.\\n\\nMost gateway designs fail not because gateways are bad \u2014 **but because they are asked to do *everything*.**\\n\\n### Do you need an MCP Gateway?\\n\\nThe short answer is: often, no.\\n\\nIf your requirements involve centralized deep packet inspection (DPI), inline payload transformation, or legacy protocol translation, a gateway is necessary. However, for **secure mcp server discovery**, runtime governance, and revocation, a **Connect Authority** is more efficient.\\n\\n**Connect Authority vs Gateway**:\\nA gateway intercepts and mediates data-plane traffic, introducing latency and a single point of failure. A Connect Authority mediates *permissions* and *discovery* in the control plane. By issuing **mcp connect descriptor** artifacts, it enables **mcp connection governance** without the heavy lift of inline proxying.\\n\\nSo the real architectural question becomes:\\n\\n> **Can we give the MCP Registry \\"gateway power\\" without making it a gateway?**\\n\\nYes \u2014 if we redefine what \\"gateway\\" means.\\n\\n---\\n\\n## The key insight: connection authority \u2260 traffic proxy\\n\\nHere\'s the mental flip:\\n\\n* A **gateway** doesn\'t need to see traffic to control *who is allowed to connect*\\n* Runtime enforcement doesn\'t need to be centralized\\n* Moderation doesn\'t need a proxy to be effective\\n\\nWhat you actually want is **connect-time authority**, not a data-plane choke point.\\n\\nIn this model:\\n\\n* The Registry governs **who may connect**\\n* The server enforces **what happens after**\\n* The client performs **one extra, intentional step**\\n\\nThis is where the MCP Registry becomes something more subtle \u2014 and more powerful.\\n\\n---\\n\\n## The Registry as a connection resolver\\n\\nInstead of proxying traffic, the Registry transforms into a **Connect Authority**. It becomes a control-plane gateway that facilitates **secure MCP server discovery**.\\n\\nClients query the Registry to find verified servers (\\"discovery\\"). But before they can connect, they must request permission. This turns the Registry into a policy engine that answers one critical question:\\n\\n> *\\"Are you allowed to connect to this server right now?\\"*\\n\\nIf yes \u2192 it issues a signed proof (descriptor).\\nIf no \u2192 the connection never starts.\\n\\nThis approach is comparable to **DNS + app store metadata**\u2014but with enforcement capabilities.\\n\\n---\\n\\n## The Connect Descriptor (the \\"boarding pass\\")\\n\\n![Boarding Pass](/img/mcp-connect-authority/mcp-beyond-gateway.png)\\n\\nThis is the missing primitive.\\n\\nA **Connect Descriptor** is a:\\n\\n* short-lived\\n* signed\\n* connect-time token\\n* issued by the Registry\\n* consumed by the client\\n* validated by the server\\n\\nIt contains:\\n\\n* the **actual server endpoint**\\n* the **transport** (streamable HTTP only)\\n* the **server identity**\\n* an **expiration window**\\n\\n### Think: *boarding pass*, not *passport*\\n\\n* It doesn\'t identify the user\\n* It doesn\'t authorize tool usage\\n* It doesn\'t replace authentication\\n\\nIt simply says:\\n\\n> *\\"You are allowed to attempt a connection to this server right now.\\"*\\n\\nThat\'s it.\\n\\nAnd that\'s enough.\\n\\n---\\n\\n## Why this extra client step matters (and why it\'s intentional)\\n\\nYes \u2014 this introduces an extra step for clients.\\n\\nAnd that\'s the entire point.\\n\\n### Old model (direct connect)\\n\\n```\\nClient \u2192 Server URL \u2192 Tools\\n```\\n\\n* Fast\\n* Simple\\n* Ungoverned\\n* Irrevocable\\n* No verification boundary\\n\\nBut we already know the risks of this model:\\n\\n* unverifiable endpoints\\n* unmoderatable servers\\n\\n**If security and governance matter, this model falls short.**\\n\\n### New model (governed connect)\\n\\n```\\nClient \u2192 Registry \u2192 Descriptor \u2192 Server URL \u2192 Tools\\n```\\n\\nThat one hop unlocks:\\n\\n* runtime-effective moderation\\n* revocation without proxies\\n* endpoint integrity\\n* server identity pinning\\n* version & transport guarantees\\n\\nClients that skip this step *can still connect* \u2014 but they explicitly opt out of governance.\\n\\nThis mirrors OAuth perfectly:\\n\\n* You can skip OAuth\\n* You just lose its guarantees\\n\\n---\\n\\n## Why streamable HTTP only changes everything\\n\\nThis model works **because** we constrain transport.\\n\\nBy supporting **remote, streamable HTTP only**:\\n\\n* No stdio bridging\\n* No local process trust\\n* No transport ambiguity\\n* No hidden execution contexts\\n\\nEvery MCP server is:\\n\\n* already running\\n* already reachable\\n* already enforcing policy\\n\\nThat\'s where **[HAPI MCP](https://hapi.mcp.com.ai) Servers** come in.\\n\\n---\\n\\n## Distributed enforcement MCP: why HAPI makes this viable\\n\\nThe Registry doesn\'t enforce runtime security directly\u2014and that is a feature, not a bug.\\n\\nThis aligns perfectly with a **Zero Trust MCP architecture**. In a Zero Trust model, we never trust an endpoint based solely on network location. Instead, we require a valid, short-lived **mcp connect descriptor**.\\n\\nBecause **HAPI MCP Servers** act as the data-plane enforcement points, they handle:\\n\\n* authentication termination\\n\x3c!-- * policy enforcement --\x3e\\n* rate limiting\\n* observability\\n* token mediation / exchange\\n\\nThis lets us distribute enforcement *to the edge*. The Registry decides **if a connection may exist**, while the HAPI server decides **what happens inside that connection**.\\n\\nNo proxy needed.\\n\\n---\\n\\n## MCP Governance Without a Gateway\\n\\n### Making moderation runtime-effective\\n\\nHere\'s the critical trick:\\n\\n### Stop issuing descriptors.\\n\\nThat\'s it.\\n\\nIf a server is revoked or moderated out:\\n\\n* the Registry refuses to issue new Connect Descriptors\\n* well-behaved clients cannot connect\\n* no traffic flows\\n* no proxy is involved\\n\\nWant stronger enforcement?\\n\\n### Descriptor refresh (hard cutoff)\\n\\nDescriptors are short-lived (configurable TTL, e.g. 30-120s).\\n\\nHAPI can require clients to:\\n\\n* refresh the descriptor periodically\\n* fail the session if refresh fails\\n\\nNow moderation becomes **hard runtime shutoff**:\\n\\n* revoke server\\n* no new descriptors\\n* active sessions expire naturally\\n\\nStill no gateway.\\n\\n---\\n\\n## What this architecture avoids (by design)\\n\\nThis is what we *intentionally* don\'t do:\\n\\n* No central proxy\\n* No data-plane bottleneck\\n* No secrets stored in the Registry\\n* No traffic inspection\\n* No latency tax\\n* No single point of failure\\n\\nThe Registry stays:\\n\\n* scalable\\n* safe\\n* boring (in a good way)\\n* reliable\\n* trustworthy\\n* low-risk\\n\\n---\\n\\n## The full flow (putting it all together)\\n\\n```mermaid\\nsequenceDiagram\\n  title Registry-Powered Connect Authority (Streamable HTTP + HAPI Enforcement)\\n\\n  participant Client as \\"MCP Client<br/>(chatMCP)\\"\\n  participant Registry as \\"MCP Registry<br/>(Connect Authority)\\"\\n  participant HAPI as \\"HAPI MCP Server<br/>(Streamable HTTP)\\"\\n  participant IdP as \\"IdP<br/>(OIDC / mTLS / OAuth)\\"\\n\\n  %% Discovery\\n  Client->>Registry: GET /v1/servers?query=payments\\n  Registry--\x3e>Client: Server metadata<br/>(id, version, endpoint, verified, jwks_uri)\\n\\n  %% Connect Descriptor issuance\\n  Client->>Registry: POST /v1/connect<br/>{ server_ref, client_id, tenant_id }\\n  alt Server revoked / unverified / policy-blocked\\n    Registry--\x3e>Client: 403 Error<br/>(server_revoked/server_unverified)\\n  else Eligible\\n    Registry->>Registry: (optional) Health check endpoint\\n    Registry->>Registry: Mint short-lived JWT descriptor<br/>(TTL 30-120s)\\n    Registry--\x3e>Client: 200 { descriptor, endpoint, expires_in }\\n  end\\n\\n  %% Direct connect to HAPI (no proxy)\\n  Client->>HAPI: GET /mcp (streamable)<br/>Headers:<br/>MCP-Connect: <descriptor><br/>Authorization: Bearer <user_token> (or mTLS)\\n\\n  %% HAPI validates Connect Descriptor\\n  HAPI->>Registry: GET /.well-known/jwks.json (or cached)\\n  Registry--\x3e>HAPI: Registry JWKS (public keys)\\n  HAPI->>HAPI: Verify descriptor signature, exp, aud, server_id match\\n  alt Descriptor invalid/expired\\n    HAPI--\x3e>Client: 401/403 Descriptor rejected<br/>(descriptor_invalid/expired)\\n  else Descriptor valid\\n    %% HAPI terminates user auth\\n    HAPI->>IdP: Validate user token / mTLS / OBO exchange\\n    IdP--\x3e>HAPI: OK + claims/scopes\\n\\n    %% Runtime enforcement (HAPI)\\n    HAPI->>HAPI: Apply policy (RBAC), rate limits, observability (trace/log/metrics)\\n\\n    %% MCP session\\n    HAPI--\x3e>Client: 200 Stream opened (SSE/HTTP streaming)\\n    Client->>HAPI: MCP tool call(s)\\n    HAPI--\x3e>Client: Tool results streamed\\n  end\\n```\\n\\n1. Client discovers a server in the Registry\\n2. Client requests a Connect Descriptor\\n3. Registry checks verification, moderation, compatibility\\n4. Registry issues a short-lived descriptor\\n5. Client extracts the endpoint from the descriptor\\n6. Client connects **directly** to the HAPI server\\n7. HAPI validates the descriptor\\n8. HAPI authenticates the user\\n9. HAPI enforces policy and executes tools\\n10. Descriptor refresh keeps governance live\\n\\nDiscovery is centralized.  \\nEnforcement is distributed.  \\nConnections are governed.  \\n\\n---\\n\\n## Why this scales (technically and socially)\\n\\nTechnically:\\n\\n* no proxy bottlenecks\\n* no hot path in the Registry\\n* horizontal scalability\\n* zero trust friendly\\n\\nSocially:\\n\\n* communities can build clients incrementally\\n* enterprises get governance without lock-in\\n* server authors keep autonomy\\n* moderation has real impact\\n\\n---\\n\\n## The final takeaway\\n\\nYou don\'t turn the MCP Registry into a gateway by adding more features.\\n\\nYou do it by **not turning it into one at all**.\\n\\nBy making it a **connection authority**, you get:\\n\\n* gateway-level control\\n* without gateway-level risk\\n\\nAnd that\'s the difference between a system that scales \u2014 and one that collapses under its own ambition.\\n\\n*Be HAPI*, and stay tuned for more MCP architecture deep dives. Go Rebels! \u270a\ud83c\udffc"},{"id":"/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway","metadata":{"permalink":"/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway","source":"@site/blog/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway.md","title":"Why a Registry + Connect Authority Beats a Gateway","description":"A comparison of MCP Registry as a Connect Authority versus traditional MCP Gateway architectures.","date":"2026-01-12T02:55:49.000Z","tags":[{"inline":false,"label":"Architecture","permalink":"/tags/architecture","description":"The structural design and organization of systems, components, and their interactions within a software or hardware environment.\\n"},{"inline":false,"label":"MCP Connect Authority","permalink":"/tags/mcp-connect-authority","description":"A Connect Authority is a trusted entity that issues connection credentials and governs access to services, enabling secure and authorized connections.\\n"},{"inline":false,"label":"MCP Registry","permalink":"/tags/mcp-registry","description":"The MCP Registry is a centralized directory that maintains metadata about available MCP-compliant services, tools, and resources for discovery and access by clients.\\n"}],"readingTime":3.18,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why a Registry + Connect Authority Beats a Gateway","description":"A comparison of MCP Registry as a Connect Authority versus traditional MCP Gateway architectures.","image":"/img/mcp-connect-authority/mcp-connect-authority-beats-gateway.png","tags":["architecture","connect-authority","mcp-registry"],"keywords":["mcp","registry","connect authority","gateway","hapi","architecture"]},"unlisted":false,"prevItem":{"title":"MCP Registry vs Gateway: Why Connect Authority Wins","permalink":"/mcp-registry-connect-authority/beyond-mcp-gateways"},"nextItem":{"title":"When Not to Use AI: Deterministic Workflows in Production Systems","permalink":"/when-not-to-use-ai"}},"content":"In the world of MCP (Model Context Protocol), two architectural patterns often come up for discussion: using a [Registry](https://registry.modelcontextprotocol.io) as a Connect Authority versus deploying a traditional Gateway. While both approaches aim to manage and secure connections between clients and servers, they do so in fundamentally different ways.\\n\\nIn this article, we will explore why the **MCP Registry + Connect Authority** model often outperforms the traditional Gateway approach.\\n\\n\x3c!-- truncate--\x3e\\n\\nA gateway **centralizes runtime traffic**. A connect authority **centralizes permission**.  \\nConsidering that the HAPI MCP servers already enforce auth, policy, rate limits, and observability, a proxy gateway is mostly cost and risk.\\n\\n:::tip\\nAren\'t MCP Servers already proxying traffic to backends?\\n:::\\n\\nHere\'s the **\\"Why Registry + Connect Authority beats a gateway\\"** comparison chart that breaks down the key dimensions:\\n\\n## Why Connect Authority beats a traditional MCP Gateway\\n\\n| Dimension                 | Traditional MCP Gateway<br/><small>&lt;&lt;proxy data-plane&gt;&gt;</small>                 | Registry + Connect Authority<br/><small>&lt;&lt;descriptor + direct connect&gt;&gt;</small>                                                | Why it wins                                             |\\n| ------------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------- |\\n| What it is                | One endpoint that **proxies** MCP traffic                  | Registry issues **permission to connect**, traffic goes **direct** to server                              | You get control without becoming the hot path           |\\n| Traffic path              | Client \u2192 **Gateway** \u2192 Server                              | Client \u2192 **Server** (after descriptor)                                                                    | No latency tax, no bandwidth bottleneck                 |\\n| Scaling                   | Must scale for **all requests**                            | Scales for **connect issuance only**                                                                      | Control-plane load is tiny vs data-plane load           |\\n| Reliability blast radius  | Gateway outage = everything breaks                         | Registry outage affects **new connects**; existing sessions can continue (depending on TTL/refresh model) | Fewer \\"all systems down\\" moments                        |\\n| Security boundary         | Centralized, attractive target                             | Distributed enforcement at HAPI servers; Registry only governs connects                                   | Smaller attack surface, less sensitive runtime exposure |\\n| Moderation / revocation   | Usually possible, but requires proxying or complex routing | **Stop issuing descriptors** \u2192 no new sessions; refresh \u2192 hard cut-off                                    | Runtime-effective moderation without proxy              |\\n| Auth termination          | Often at gateway (adds complexity + secrets)               | At **HAPI server** (already your design)                                                                  | Keeps secrets and policy where they belong              |\\n| Policy / RBAC             | Centralized policy engine needed                           | Enforced by **HAPI**; descriptor may carry hints (optional)                                               | No duplicated policy stack                              |\\n| Rate limiting             | Central choke point; risks noisy-neighbor                  | Per-server / per-tenant at HAPI                                                                           | Better isolation and fairness                           |\\n| Observability             | Centralized, but expensive and noisy                       | HAPI produces real runtime telemetry; Registry logs issuance                                              | Signals are cleaner and cheaper                         |\\n| Multi-tenancy             | Requires strict separation at gateway                      | Natural with per-tenant descriptors + HAPI enforcement                                                    | Tenant governance without a monolith                    |\\n| Data privacy              | Gateway can see payloads (risk)                            | Registry never sees tool payloads                                                                         | Big win for trust + compliance                          |\\n| Implementation complexity | Medium-to-high (proxy, routing, retries, SSE quirks)       | Low-to-medium (issue token + validate token + refresh)                                                    | Fewer moving parts, fewer outages                       |\\n| Vendor lock-in risk       | Often higher (gateway semantics creep)                     | Lower (descriptor is portable, servers remain standard)                                                   | You can swap implementations later                      |\\n| Best fit                  | Centralized platform teams who want full proxy control     | Ecosystems + enterprises that want governance **without** data-plane                                      | Scales socially and technically                         |\\n\\n---\\n\\n## When you *still* want a gateway\\n\\nWell, sometimes a gateway is still useful.  \\nYou may still want a proxy gateway when you need:\\n\\n* protocol bridging (stdio \u2194 HTTP) - `stdio` is legacy and we enforce HTTP natively, `stdio` is not supported\\n* multi-protocol consolidation (gRPC + HTTP + websockets)\\n* deep traffic transformation (e.g., SOAP \u2194 REST)\\n* deep payload inspection / transformation\\n* single endpoint requirements for legacy network constraints\\n* centralized caching of tool results (rare)\\n\\nBut for **streamable HTTP only + HAPI enforced servers**, the connect authority model is the cleaner default.\\n\\nWith that said, you can always pair both patterns: use the Registry as a Connect Authority *and* deploy gateways where needed. They\'re not mutually exclusive. What matters is that you separate **permission** (Registry) from **enforcement** (HAPI servers), and avoid becoming a fragile, high-risk data-plane bottleneck.\\n\\nWhat about you? Have you used either pattern? Share your experiences in the comments!\\n\\n*Be HAPI*, and stay tuned for more MCP architecture deep dives. Go Rebels! \u270a\ud83c\udffc"},{"id":"/when-not-to-use-ai","metadata":{"permalink":"/when-not-to-use-ai","source":"@site/blog/when-not-to-use-ai.md","title":"When Not to Use AI: Deterministic Workflows in Production Systems","description":"Exploring why AI isn\'t always the right tool for every task in production systems, and how deterministic workflows can provide reliability and cost-efficiency.","date":"2026-01-06T00:00:00.000Z","tags":[{"inline":false,"label":"Arazzo","permalink":"/tags/arazzo","description":"Arazzo defines API workflows\u2014sequences of calls and dependencies\u2014to deliver outcomes using API specs like OpenAPI.\\n"},{"inline":false,"label":"API-First","permalink":"/tags/api-first","description":"API-First is a design approach that prioritizes the development of APIs before building the actual application, ensuring better integration and scalability.\\n"},{"inline":false,"label":"REST","permalink":"/tags/rest","description":"REST (Representational State Transfer) is an architectural style for designing networked applications, using stateless communication and standard HTTP methods.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"}],"readingTime":8.26,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"When Not to Use AI: Deterministic Workflows in Production Systems","description":"Exploring why AI isn\'t always the right tool for every task in production systems, and how deterministic workflows can provide reliability and cost-efficiency.","date":"2026-01-06T00:00:00.000Z","authors":["adrian"],"publisher":"MCP Project","tags":["arazzo","api-first","rest","ai-integration"],"keywords":["AI","Deterministic Workflows","OpenAPI","Production Systems","Arazzo","OrcA","HAPI MCP"],"image":"/img/when-ai-does-everything.png"},"unlisted":false,"prevItem":{"title":"Why a Registry + Connect Authority Beats a Gateway","permalink":"/mcp-registry-connect-authority/why-a-registry+connect-authority-beats-a-gateway"},"nextItem":{"title":"Integrate the OpenAI UI SDK for ChatGPT With MCP in 60 Seconds","permalink":"/openai-ui-sdk-and-mcp-chatgpt"}},"content":"**AI is everywhere. Too everywhere.**\\nFrom answering \\"hi\\" to deciding how your production platform runs sanity checks, we\'ve quietly crossed a line. Not because AI *can\'t* do these things, but because **it shouldn\'t do all of them**.\\n\\n\x3c!-- truncate --\x3e\\n\\nThis post is not anti-AI. Quite the opposite.\\nIt\'s about **using AI where it creates leverage**, and removing it where it quietly burns money, reliability, and trust.\\n\\n---\\n\\n## Is AI Needed for Everything?\\n\\n### Why Determinism Still Wins in Production Systems\\n\\nI recently saw a meme: two young people \\"talking\\" to each other, but every response is generated by AI.\\nIt\'s funny. Then it\'s awkward. Then it\'s uncomfortable.\\n\\nBecause the joke hides a real question:\\n\\n> If we outsource even basic interaction to AI...\\n> what else are we delegating without thinking?\\n\\nAnd in tech, especially in platforms, DevOps, and production systems, that question matters a lot.\\n\\n---\\n\\n## The Problem Isn\'t AI. It\'s Where We Put It.\\n\\nLet\'s be clear:\\nAI is amazing at **ambiguity**.\\n\\n* Natural language\\n* Exploration\\n* Reasoning with incomplete context\\n* Translating intent into action\\n\\nBut production systems are not ambiguous.\\nThey are built on **expectations**.\\n\\n* Health checks must be consistent\\n* Sanity tests must be repeatable\\n* Compliance workflows must be predictable\\n* Outcomes must be explainable\\n\\nWhen we mix those two worlds carelessly, we get something dangerous:\\n**non-deterministic logic running deterministic systems**.\\n\\n---\\n\\n## A Real Example: \\"Run Full Platform Sanity\\"\\n\\nI\'ve seen teams implement AI-driven solutions for things like:\\n\\n* Platform health checks\\n* Full sanity runs\\n* Operational diagnostics\\n\\nThe UX looks great:\\n\\n> \\"Hey AI, run a full sanity of my platform.\\"\\n\\nMuch better than clicking through a complex UI, right?\\n\\nYes.\\nBut let\'s look under the hood.\\n\\n### What Actually Happens\\n\\n1. The LLM interprets the request\\n2. It decides which tools to call\\n3. It invokes them **one by one**\\n4. Each call:\\n\\n   * Consumes tokens\\n   * Adds latency\\n   * Introduces uncertainty\\n\\nSame request.\\nDifferent day.\\nDifferent internal reasoning path.\\n\\nSame *intent*, potentially different *execution*.\\n\\nThat\'s not intelligence.\\nThat\'s a **token-powered slot machine** \ud83c\udfb0.\\n\\n---\\n\\n## The Token Black Hole No One Talks About\\n\\nFrom a business perspective, this matters.\\n\\nSimple operational tasks:\\n\\n* Are repeated often\\n* Have stable logic\\n* Produce the same expected result every time\\n\\nUsing an LLM for these tasks means:\\n\\n* Paying token costs for zero new information\\n* Debugging behavior that should never change\\n* Accepting variability where none should exist\\n\\n**Executives see this as cost leakage.**\\n**Architects see it as system fragility.**\\n**Engineers feel it as unnecessary complexity.**\\n\\nWhat is your takeaway here?\\n\\n---\\n\\n## The Wrong Question We Keep Asking\\n\\nMost teams ask:\\n\\n> \\"Can AI do this?\\"\\n\\nThe better questions are:\\n\\n* **Should AI do this?**\\n* **What part of this needs intelligence?**\\n* **What part should be guaranteed?**\\n\\nBecause the truth is:\\n**AI is not a workflow engine.**\\n\\n---\\n\\n## Deterministic Workflows Are Not Anti-AI\\n\\nHere\'s the mental shift that changes everything:\\n\\n> AI should decide *what* to do.\\n> Deterministic systems should decide *how* it\'s done.\\n\\nThis is not a compromise.\\nIt\'s an optimization.\\n\\n### AI does:\\n\\n* Intent understanding\\n* Decision making\\n* Tool selection at a high level\\n\\n### Deterministic systems do:\\n\\n* Execution\\n* Sequencing\\n* Error handling\\n* Consistent outcomes\\n\\n---\\n\\n## From N Tools to One Outcome\\n\\nLet\'s simplify.\\n\\n### The na\xefve AI-first approach\\n\\n* Expose **N tools** to the LLM\\n* Let it figure out:\\n\\n  * Order\\n  * Dependencies\\n  * Retries\\n  * Failure modes\\n\\n### The smarter hybrid approach\\n\\n* Map the workflow once\\n* Make it deterministic\\n* Expose **one tool**:\\n\\n  > \\"Run full platform sanity\\"\\n\\nSame result.\\nLower cost.\\nHigher reliability.\\n\\n---\\n\\n![Image](https://weaviate.io/assets/images/types-of-workflows-8976ed4aad76322779634ef312962ae4.jpg)\\n\\n![Image](https://orkes.io/images/blogs/2025-05-19-agentic-ai-explained/Agentic-AI-Explained_Banner.jpg)\\n\\n![Image](https://www.researchgate.net/publication/398593556/figure/fig3/AS%3A11431281813750659%401766671032077/Hybrid-CNN-Transformer-LSTM-architecture-and-edge-AI-deployment-workflow.tif)\\n\\n---\\n\\n## This Is Where Standards Quietly Save Us\\n\\nThis approach works because we already have the right building blocks.\\n\\n### Deterministic workflows\\n\\nDefined once, versioned, testable.\\n\\nThat\'s where **Arazzo** comes in.\\nArazzo lets you describe workflows declaratively, no prompts, no guessing.\\n\\n### Execution engine\\n\\nThose workflows need an orchestrator.\\n\\nThat\'s the role of **OrcA**:\\n\\n* Executes deterministic workflows\\n* Handles sequencing and retries\\n* Guarantees consistent outcomes\\n\\n### Capabilities as APIs\\n\\nYour system capabilities already exist.\\n\\nThey are defined using the **OpenAPI Specification (OAS)**.\\n\\n### Exposing outcomes to AI\\n\\nNow the key step:\\nExpose *workflows*, not raw operations, as AI tools.\\n\\nThat\'s exactly what **HAPI MCP** enables.\\n\\n---\\n\\n## The Mapping That Changes Everything\\n\\nOnce you see it, it\'s hard to unsee:\\n\\n* **Arazzo \u2192 OrcA**\\n  Deterministic workflows, executed reliably\\n\\n* **OAS \u2192 HAPI MCP**\\n  APIs and workflows exposed as MCP tools\\n\\nThe LLM doesn\'t need to know *how* the sanity check runs.\\nIt only needs to know **that it exists**.\\n\\n---\\n\\n## What This Unlocks (For Everyone)\\n\\n### For AI systems\\n\\n* Fewer tools to reason about\\n* Cleaner context\\n* Lower token usage\\n* Higher accuracy\\n\\n### For Developers\\n\\n* Predictable behavior\\n* Reusable workflows\\n* Easier testing\\n* No prompt gymnastics\\n\\n### For Product Managers\\n\\n* Features with guarantees\\n* Stable UX\\n* Clear ownership of logic\\n\\n### For Executives\\n\\n* Controlled AI spend\\n* Reduced operational risk\\n* Compliance-friendly AI adoption\\n\\n---\\n\\n## AI + Determinism Is Collaboration, Not Replacement\\n\\nThis is the part most people miss.\\n\\nWe are not replacing humans with AI.\\nAnd we are not replacing systems with AI either.\\n\\nWe are **connecting intent to execution** more intelligently.\\n\\nThink of it this way:\\n\\n* AI is the **copilot**\\n* Deterministic workflows are the **autopilot**\\n* Humans still decide where the plane goes\\n\\n---\\n\\n## The Real Future of AI in Platforms\\n\\nThe future is not:\\n\\n> \\"AI does everything.\\"\\n\\nThe future is:\\n\\n> \\"AI knows when *not* to.\\"\\n\\nIf a task:\\n\\n* Must be consistent\\n* Must be repeatable\\n* Must be auditable\\n\\nThen AI should **trigger it**, not **perform it**.\\n\\n---\\n\\n## Final Thought\\n\\nThat meme about AI answering \\"hi\\" is funny because it\'s absurd.\\nBut the same absurdity exists in production systems, just quieter and more expensive.\\n\\n**Expose outcomes, not chaos.**\\n**Let AI reason. Let systems execute.**\\n\\nIf your AI needs to reason about execution, your system design is already leaking.\\nAI should reason about intent, not rebuild your workflows one token at a time.\\n\\nThanks for reading. Be _HAPI_ and Go Rebels! \u270a\ud83c\udffc\\n\\n---\\n\\n## FAQ - Common Questions\\n\\n### When Should AI Not Be Used?\\n\\nAI is powerful, but power without boundaries becomes a liability.\\n\\nAI should *not* be used when a task:\\n\\n* Must produce the **same result every time**\\n* Is executed **frequently at scale**\\n* Has **clear, predefined logic**\\n* Requires **auditability or compliance**\\n* Impacts **production stability**\\n\\nThese are not edge cases.\\nThese are **core platform operations**.\\n\\nHealth checks, sanity runs, compliance validations, and operational diagnostics do not benefit from probabilistic reasoning. They benefit from **guarantees**.\\n\\nUsing AI in these scenarios introduces:\\n\\n* Non-deterministic behavior\\n* Higher operational cost\\n* Hard-to-reproduce failures\\n* Loss of trust in the system\\n\\nAI excels at *deciding what to do*.\\nIt struggles when asked to *repeat the same thing perfectly*.\\n\\nThat\'s the line most teams cross without noticing.\\n\\n---\\n\\n### Why Deterministic Workflows Matter in Production Systems?\\n\\nDeterministic workflows are not a legacy concept.\\nThey are a **production necessity**.\\n\\nA deterministic workflow guarantees:\\n\\n* The same inputs lead to the same outputs\\n* Execution order is fixed and explainable\\n* Failures are reproducible\\n* Behavior can be tested, versioned, and audited\\n\\nThis is why deterministic workflows matter, especially in platforms, DevOps, and enterprise systems.\\n\\nWhen AI replaces deterministic execution, you lose:\\n\\n* Predictability\\n* Cost control\\n* Debuggability\\n* Confidence in outcomes\\n\\nIn production, consistency is not optional.\\nIt is the foundation of reliability.\\n\\nAI-generated execution paths might *work today* and *fail tomorrow*, without any code changes. That\'s not innovation. That\'s operational risk disguised as intelligence.\\n\\n---\\n\\n### How to Combine AI and Deterministic Systems (The Right Way)?\\n\\nThe most effective systems today are not \\"AI-first\\" or \\"AI-everywhere.\\"\\n\\nThey are **hybrid by design**.\\n\\nHere\'s the winning pattern:\\n\\n* **AI handles intent and ambiguity**\\n* **Deterministic systems handle execution**\\n\\nAI interprets *what the user wants*.\\nDeterministic workflows define *how it happens*.\\n\\nThis separation creates leverage:\\n\\n* AI remains flexible and expressive\\n* Execution remains predictable and cost-efficient\\n\\nInstead of exposing dozens of low-level tools to an LLM, you expose **one deterministic outcome**.\\n\\nThe AI triggers it.\\nThe system guarantees it.\\n\\nThis is how you combine AI and deterministic systems without sacrificing reliability, or burning tokens unnecessarily.\\n\\n---\\n\\n### Why OpenAPI Workflow Orchestration Is a Game Changer in AI Systems?\\n\\nMost systems already have what they need.\\nThey just expose it incorrectly.\\n\\nAPIs describe **capabilities**.\\nWorkflows describe **outcomes**.\\n\\nWith **OpenAPI workflow orchestration**, you move from raw operations to structured execution.\\n\\nHere\'s how it works in practice:\\n\\n* OpenAPI defines what your system can do\\n* Workflow specifications define *how operations are combined*\\n* Orchestrators execute those workflows deterministically\\n* AI tools expose workflows, not individual endpoints\\n\\nThis approach transforms APIs into **reliable building blocks for AI systems**.\\n\\nInstead of asking an LLM to guess:\\n\\n* Which endpoint to call\\n* In what order\\n* With which retries\\n\\nYou give it a single, well-defined tool:\\n\\n> \\"Run full platform sanity\\"\\n\\nSame result.\\nEvery time.\\n\\nThat\'s the difference between **AI-driven chaos** and **OpenAPI workflow orchestration done right**.\\n\\n---\\n\\n### Why AI can\'t Replace Deterministic Execution in Production Systems?\\n\\nAI is a powerful tool for interpreting intent and handling ambiguity. However, it fundamentally lacks the guarantees required for deterministic execution in production systems.\\n\\nDeterministic execution demands:\\n\\n* Consistency: The same inputs must always yield the same outputs.\\n* Predictability: Execution paths must be clear and explainable.\\n* Auditability: Actions must be traceable and verifiable.\\n* Reliability: Systems must behave consistently under all conditions.\\n\\nAI models, by their nature, introduce variability. Their outputs can change based on context, training data, and even random seed values. This unpredictability is incompatible with the stringent requirements of production systems.\\n\\n---\\n\\n### How Does HAPI MCP Facilitate Deterministic Workflows for AI Systems?\\n\\nHAPI MCP (Model Context Protocol) is not just another AI tool.\\nIt\'s a **bridge between AI intent and deterministic execution**.\\n\\nHAPI MCP enables you to:\\n\\n* Expose deterministic workflows as MCP tools\\n* Let AI models discover and invoke these workflows seamlessly\\n* Maintain clear separation between intent and execution\\n* Reduce token consumption by minimizing AI reasoning about execution details\\n* Ensure consistent, repeatable outcomes in production systems\\n\\nBy using HAPI MCP, you empower AI systems to leverage the reliability of deterministic workflows without losing the flexibility of AI-driven intent.\\n\\n---\\n\\nReady to make your AI systems more reliable and cost-efficient?"},{"id":"/openai-ui-sdk-and-mcp-chatgpt","metadata":{"permalink":"/openai-ui-sdk-and-mcp-chatgpt","source":"@site/blog/openai-ui-sdk-and-mcp-chatgpt.mdx","title":"Integrate the OpenAI UI SDK for ChatGPT With MCP in 60 Seconds","description":"Step-by-step guide to turn any OpenAPI 3.0+ spec into a ChatGPT-ready MCP server using HAPI MCP and the OpenAI UI SDK. Fast deployment, validation, and optimization for Generative and Answer Engine search.","date":"2025-11-24T17:48:55.000Z","tags":[{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"OpenAI","permalink":"/tags/openai","description":"OpenAI is an AI research and deployment company focused on ensuring that artificial general intelligence benefits all of humanity.\\n"},{"inline":false,"label":"API-First","permalink":"/tags/api-first","description":"API-First is a design approach that prioritizes the development of APIs before building the actual application, ensuring better integration and scalability.\\n"},{"inline":false,"label":"LLM","permalink":"/tags/llm","description":"Large Language Models (LLMs) are advanced AI models trained on vast text data to understand and generate human-like language.\\n"},{"inline":false,"label":"Guide","permalink":"/tags/guide","description":"Curated instructions or documentation designed to help users understand and implement specific use cases around MCP and related technologies.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"}],"readingTime":5.03,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Integrate the OpenAI UI SDK for ChatGPT With MCP in 60 Seconds","description":"Step-by-step guide to turn any OpenAPI 3.0+ spec into a ChatGPT-ready MCP server using HAPI MCP and the OpenAI UI SDK. Fast deployment, validation, and optimization for Generative and Answer Engine search.","tags":["mcp","openai","api-first","llm","guide","ai-integration"],"authors":["adrian"],"image":"/img/make-mcp-hapi.png"},"unlisted":false,"prevItem":{"title":"When Not to Use AI: Deterministic Workflows in Production Systems","permalink":"/when-not-to-use-ai"},"nextItem":{"title":"Composable Architectures and the Future of AI Integration: Why MCP Is the Missing Link","permalink":"/composable-architectures-and-the-future-of-ai-integration"}},"content":"You want your API to be instantly usable inside AI assistants like ChatGPT, and Web UIs. The OpenAI UI SDK plus the Model Context Protocol (MCP) lets you expose your API as structured tools that large language models can call directly.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn this hands-on guide, you deploy a fully functional MCP server from any OpenAPI 3.0 specification and make it usable by ChatGPT and other MCP-aware clients in under a minute using HAPI MCP. You learn to deploy using cloud and on\u2011premises workflows.\\n\\n---\\n\\nJust two months ago, I wrote about how [OpenAI announced the custom MCP](https://rebelion.la/chatgpt-meets-custom-mcps) (Model Context Protocol) interface to allow developers to integrate their APIs directly into ChatGPT, but there was [this caveat](https://rebelion.la/chatgpt-meets-custom-mcps#heading-the-caveat-search-and-fetch): Developers would need to implement two tools, a \\"search\\" tool to find relevant information and a \\"fetch\\" tool to retrieve that information. Today, with the OpenAI UI SDK, that process is greatly simplified.\\n\\n## Why Integrate Your API With the OpenAI UI SDK via MCP?\\n\\n* You expose real-time, authoritative data to ChatGPT and other MCP-aware clients.\\n* You eliminate brittle prompt engineering for retrieval and action execution.\\n* You accelerate feature delivery\u2014turn any supported OpenAPI spec into tool metadata.\\n\\n## Architecture Overview\\n\\nThe deployment flow:\\n\\n1. Provide an OpenAPI 3.0+ JSON or YAML spec.\\n2. HAPI MCP ingests paths, methods, parameters, and schemas.\\n3. Tools are generated with typed argument definitions.\\n4. The MCP server exposes a JSON-RPC style interface consumable by the OpenAI UI SDK or other MCP-clients.\\n5. Clients query available tools, then issue structured calls.\\n\\n### Key Components\\n\\n| Component | Role |\\n| :-- | :-- |\\n| OpenAPI Spec | Source of truth for endpoints, params, schemas |\\n| HAPI MCP CLI / Cloud | Transforms spec \u2192 MCP tool registry |\\n| MCP Server | Serves tool metadata and handles invocations |\\n| Client Runtime | ChatGPT / custom app calling tools |\\n\\n## Prerequisites\\n\\n* An OpenAPI 3.0+ spec URL or local file (JSON or YAML).\\n* A workstation with terminal access, only if you plan to use the HAPI MCP CLI (on-premises deployment).\\n* Basic familiarity with REST API concepts (no MCP experience required).\\n* Optional: A converted OAS 2.0 (Swagger) spec if you start from legacy format.\\n\\n## Quick Answer: What Is the Fastest Way to Get an API Inside ChatGPT?\\n\\nProvide an OpenAPI 3.0 spec to HAPI MCP (cloud or CLI), start the MCP server, then [connect ChatGPT](https://developers.openai.com/apps-sdk/deploy/connect-chatgpt) custom tools configuration at the generated endpoint.\\n\\n## Cloud Deployment (Fastest Path)\\n\\n1. Open the run portal: `https://run.mcp.com.ai/?oas=<YOUR_OPENAPI_SPEC_URL>&apiServer=<OPTIONAL_BASE_URL>`\\n2. Replace `<YOUR_OPENAPI_SPEC_URL>` with a direct spec URL (must be publicly accessible).\\n3. (Optional) Replace `<OPTIONAL_BASE_URL>` with your API server base URL if needed - not all specs include server definitions.\\n4. Wait for provisioning; you receive an MCP server endpoint URL.\\n5. Use that URL in the ChatGPT Apps & Connectors settings.\\n6. Validate tool listing (see Validation section below).\\n\\n### Example URL\\n\\n```console\\nhttps://run.mcp.com.ai/?oas=https://example.com/openapi.json\\n```\\n\\n## On-Premises Deployment With HAPI MCP CLI\\n\\n1. Install the CLI\\n[Download the latest release](https://github.com/la-rebelion/hapimcp/releases) and install the HAPI MCP CLI executable, depending on your OS. \\n\\nOr install via Bun/npm:\\n```bash\\nbun install -g @la-rebelion/hapimcp\\n```\\n2. Verify installation:\\n```bash\\nhapi --version\\n```\\n1. Start a local MCP server (using a spec alias - located in `HAPI_HOME/specs`):\\n```bash\\nhapi serve petstore --headless\\n```\\n1. Or specify a direct spec URL:\\n```bash\\nhapi serve my-api --openapi=\\"https://example.com/openapi.json\\" --headless\\n```\\n1. Capture the printed MCP server endpoint (e.g., `http://localhost:3000/mcp`).\\n2. Add that URL to ChatGPT Apps & Connectors settings.\\n\\n## Deploy to Cloud via CLI\\n\\n1. Run:\\n```bash\\nhapi deploy strava --var HAPI_OPENAPI:\\"https://docs.mcp.com.ai/apis/openapi/strava.json\\"\\n```\\n1. Use `--dry-run` to inspect generated YAML or JSON before committing:\\n```bash\\nhapi deploy strava --var HAPI_OPENAPI:\\"https://docs.mcp.com.ai/apis/openapi/strava.json\\" --dry-run\\n```\\n1. Store returned endpoint URL for ChatGPT integration.\\n\\n## Converting Swagger (OAS 2.0) to OpenAPI 3.0+\\n\\nDon\'t have an OpenAPI 3.0+ spec? Convert from Swagger (OAS 2.0) using these steps:\\n\\n1. Use the official online converter:\\n```bash\\ncurl -X POST -H \\"Content-Type: application/json\\" \\\\\\n  -d @swagger.json https://converter.swagger.io/api/convert \\\\\\n  -o openapi3.json\\n```\\n1. Confirm version:\\n```bash\\ngrep \'\\"openapi\\"\' openapi3.json\\n```\\n1. Fix any `schema` vs `definitions` mismatches manually if needed.\\n1. Retry deployment with the new file.\\n\\n## Validating Your MCP Server\\n\\n1. List tools:\\n```bash\\ncurl -s https://your-mcp-endpoint.example/mcp/tools | jq\\n```\\n1. Call a tool (example POST body):\\n```bash\\ncurl -X POST https://your-mcp-endpoint.example/mcp/call \\\\\\n  -H \'Content-Type: application/json\' \\\\\\n  -d \'{\\n    \\"tool\\":\\"getPetById\\",\\n    \\"params\\":{\\"petId\\": 123}\\n  }\'\\n```\\n1. Check response latency; target < 1s for best conversational UX.\\n1. Log errors; ensure input validation messages are concise and actionable.\\n1. Confirm schema alignment with expected OpenAPI parameter types.\\n\\n## Frequently Asked Questions\\n\\n### How fast can you expose an API to ChatGPT?\\nYou can expose a spec-driven API in under 60 seconds using the cloud portal or a single CLI command.\\n\\n### Do you need to write glue code?\\nYou do not need custom tool wrappers; HAPI MCP converts spec operations automatically.\\n\\n### Can you use private specs?\\nYes. Host the spec behind authenticated access or load from a local file via CLI.\\n\\n### What formats are supported?\\nOpenAPI 3.0+ JSON or YAML. Convert OAS 2.0 (Swagger) before deployment.\\n\\n### Is this limited to ChatGPT?\\nNo. Any MCP-aware client (custom apps, open-source chat UIs) can consume the server.\\n\\n## Conclusion\\n\\nYou now have a repeatable path to transform any OpenAPI 3.0+ specification into a production-ready MCP server consumable by the OpenAI UI SDK and AI assistants. By following validation, conversion, and optimization steps, you improve tool discoverability. Next, refine schema descriptions and add automated integration tests to ensure durable quality as your API evolves.\\n\\nYour APIs are now ready to be seamlessly integrated into ChatGPT and other MCP-aware clients, unlocking new possibilities for AI-driven interactions. Stop wasting time writing MCP Server code manually\u2014leverage HAPI MCP to accelerate your AI integration journey!\\n\\nBe HAPI and Go Rebels! \u270a\ud83c\udffd"},{"id":"/composable-architectures-and-the-future-of-ai-integration","metadata":{"permalink":"/composable-architectures-and-the-future-of-ai-integration","source":"@site/blog/composable-architectures-and-the-future-of-ai-integration.md","title":"Composable Architectures and the Future of AI Integration: Why MCP Is the Missing Link","description":"Instead of rebuilding APIs, learn how composable architectures and MCP Gateways help enterprises move from API-First to AI-First.","date":"2025-11-01T15:05:34.000Z","tags":[{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"},{"inline":false,"label":"LLM","permalink":"/tags/llm","description":"Large Language Models (LLMs) are advanced AI models trained on vast text data to understand and generate human-like language.\\n"},{"inline":false,"label":"API","permalink":"/tags/api","description":"An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate and interact with each other.\\n"},{"inline":false,"label":"MCP Gateway","permalink":"/tags/mcp-gateway","description":"An MCP Gateway acts as a bridge between existing APIs and the Model Context Protocol, enabling seamless integration of legacy systems with AI applications.\\n"}],"readingTime":2.5,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Composable Architectures and the Future of AI Integration: Why MCP Is the Missing Link","description":"Instead of rebuilding APIs, learn how composable architectures and MCP Gateways help enterprises move from API-First to AI-First.","tags":["mcp","ai-integration","llm","api","mcp-gateway"],"keywords":["MCP","Model Context Protocol","Composable AI architecture","AI Integration","LLMs","APIs","MCP Gateway","future of AI system integration","API-First vs AI-First transformation"],"image":"https://images.unsplash.com/photo-1492355040260-cd982083603e?ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&q=80&w=1170","authors":["adrian"]},"unlisted":false,"prevItem":{"title":"Integrate the OpenAI UI SDK for ChatGPT With MCP in 60 Seconds","permalink":"/openai-ui-sdk-and-mcp-chatgpt"},"nextItem":{"title":"Using OpenAI Response API for MCP Integration","permalink":"/use-openai-api-for-smooth-mcp-integration"}},"content":"For years, **OpenAPI (OAS)** has been the cornerstone of how we describe, document, and integrate APIs. It standardized how systems talk to each other \u2014 and in many ways, it made the modern internet possible.\\n\\nSo when the **Model Context Protocol (MCP)** appeared, some developers were skeptical.\\n\\"Another spec?\\" they asked. \\"Why do we need this when we already have OAS?\\"\\n\\n\x3c!-- truncate --\x3e\\n\\nThat skepticism was fair \u2014 until people started to realize **what MCP actually unlocks**:\\n\ud83d\udc49 **Tool discovery for Large Language Models (LLMs)**.\\n\\nThis is the real spark \u2014 the value proposition that gave MCP its traction. It\'s not just another API spec; it\'s the bridge between traditional APIs and the AI agents that can use them.\\n\\n---\\n\\n### Why Re-Invent When You Can Re-Compose?\\n\\nMany enterprises today already have a vast API ecosystem \u2014 especially in industries like **telecommunications**, **finance**, or **healthcare**.\\nHundreds of services, standardized and custom, all tested, audited, and certified.\\n\\nSo when these organizations hear about \\"MCP servers,\\" it\'s natural to worry that they\'ll need to rebuild everything. But here\'s the truth:\\n\\n> **You don\'t need to re-implement your APIs as MCP servers. You just need to make them discoverable.**\\n\\nThat\'s where the **MCP Gateway** comes in.\\n\\n---\\n\\n### The Role of the MCP Gateway\\n\\nThink of an MCP Gateway as a **translator and orchestrator** between your existing APIs and AI-driven agents.\\n\\n* It receives MCP requests from LLMs.\\n* It routes them to your existing APIs.\\n* It transforms the responses back into MCP format.\\n\\nNo reinvention. No duplicate logic. Just a smarter bridge between systems.\\n\\nAnd because it sits at the intersection of APIs and AI, the MCP Gateway can handle the enterprise-grade essentials too \u2014\\n\u2705 Authentication & authorization\\n\u2705 Rate limiting\\n\u2705 Logging & observability\\n\u2705 Policy enforcement & compliance\\n\\nIt\'s the perfect layer to keep everything **secure, compliant, and manageable** while opening the door to AI-powered integration.\\n\\n---\\n\\n### Composable Architectures: The Future of Integration\\n\\nWe\'ve moved from monoliths to microservices, and now from **API-First to AI-First**.\\nThe next evolution is **composability** \u2014 the ability to assemble, re-use, and extend existing systems dynamically.\\n\\nMCP Gateways embody this principle.\\nThey empower teams to:\\n\\n* Reuse what already works.\\n* Expose APIs as AI-ready tools.\\n* Integrate with LLMs and agents seamlessly.\\n* Accelerate innovation instead of rewriting history.\\n\\nEnterprises can finally focus on **intent matching** \u2014 connecting what an AI agent *wants to do* with the right existing service, without reinventing the wheel.\\n\\n---\\n\\n### The Mindset Shift\\n\\nAdopting MCP isn\'t just a technical change \u2014 it\'s a cultural one.\\nIt\'s about moving from building APIs *for humans to consume* to building systems that *AI can understand and compose*.\\n\\nIt\'s about trust \u2014 trusting that your existing architecture already has value, and that the future doesn\'t require you to start over, but to **connect smarter**.\\n\\n---\\n\\n### Final Thought\\n\\n**Composable, AI-ready architectures are the future of integration.**\\nMCP Gateways are the missing link \u2014 enabling enterprises to evolve from *API-First* to *AI-First* without disruption.\\n\\nBecause innovation shouldn\'t mean rebuilding everything.\\nIt should mean **unlocking what you already have** \u2014 and letting intelligence flow through it."},{"id":"/use-openai-api-for-smooth-mcp-integration","metadata":{"permalink":"/use-openai-api-for-smooth-mcp-integration","source":"@site/blog/use-openai-api-for-smooth-mcp-integration.mdx","title":"Using OpenAI Response API for MCP Integration","description":"A step-by-step guide to integrating OpenAI\'s Response API with Model Context Protocol (MCP) using HAPI Server.","date":"2025-11-01T15:05:34.000Z","tags":[{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"OpenAI","permalink":"/tags/openai","description":"OpenAI is an AI research and deployment company focused on ensuring that artificial general intelligence benefits all of humanity.\\n"},{"inline":false,"label":"API-First","permalink":"/tags/api-first","description":"API-First is a design approach that prioritizes the development of APIs before building the actual application, ensuring better integration and scalability.\\n"},{"inline":false,"label":"LLM","permalink":"/tags/llm","description":"Large Language Models (LLMs) are advanced AI models trained on vast text data to understand and generate human-like language.\\n"},{"inline":false,"label":"Guide","permalink":"/tags/guide","description":"Curated instructions or documentation designed to help users understand and implement specific use cases around MCP and related technologies.\\n"},{"inline":false,"label":"AI Integration","permalink":"/tags/ai-integration","description":"AI Integration involves incorporating artificial intelligence technologies into existing systems and workflows to enhance functionality and performance.\\n"}],"readingTime":4.12,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Using OpenAI Response API for MCP Integration","description":"A step-by-step guide to integrating OpenAI\'s Response API with Model Context Protocol (MCP) using HAPI Server.","tags":["mcp","openai","api-first","llm","guide","ai-integration"],"keywords":["MCP","Model Context Protocol","OpenAI Response API","HAPI Server","API Integration","LLMs","Taco Ordering System","Postman AI Agent"],"image":"https://images.unsplash.com/photo-1676299081847-824916de030a?ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&q=80&w=1170","authors":["adrian"]},"unlisted":false,"prevItem":{"title":"Composable Architectures and the Future of AI Integration: Why MCP Is the Missing Link","permalink":"/composable-architectures-and-the-future-of-ai-integration"},"nextItem":{"title":"OpenAI SDK Meets MCP (Model Context Protocol)","permalink":"/openai-meets-mcp"}},"content":"import ReactPlayer from \'react-player\'\\n\\nThis guide demonstrates how to use the **OpenAI Response API** to integrate with the **Model Context Protocol (MCP)** for seamless, AI-driven API interactions.\\nYou will learn how to generate a REST API specification with Postman\'s AI Agent, deploy it as an **MCP server using HAPI Server**, and connect it through OpenAI\'s **Response API** for testing.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe goal of this demo is to show how OpenAI\'s new **Tools and Connectors for MCP** feature simplifies integration between large language models and your APIs, making it possible to interact with services such as a \\"Taco Ordering System\\" directly from an LLM client like ChatGPT or a Bun-based application.\\n\\nBy the end of this guide, you will have a working MCP server derived from a Swagger specification, exposed via ngrok, and connected to the OpenAI Response API for end-to-end interaction testing.\\n\\n\\n---\\n\\n## Prerequisites\\n\\nBefore you begin:\\n\\n* Install the following tools:\\n\\n  * [Bun](https://bun.sh/) \u2013 A fast JavaScript runtime for modern apps.\\n    * Alternatively, you can use Node.js if preferred.\\n  * [ngrok](https://ngrok.com/) \u2013 To expose your local server to the internet.\\n  * [HAPI Server](https://hapi.mcp.com.ai) \u2013 To host your MCP server.\\n  * [OpenAI SDK](https://www.npmjs.com/package/openai) \u2013 For client testing.\\n  * Obtain or install **Postman Desktop Agent** to generate APIs using AI.\\n    * Alternatively, you can ask **ChatGPT** to generate a Swagger specification (v3).\\n\\n:::info\\nThe example below uses a local environment and ngrok for simplicity, but you can deploy your server on any cloud instance or containerized environment.\\n:::\\n\\n---\\n\\n## Step 1: Generate an API Using Postman Agent\\n\\nYou can use Postman\'s AI Agent to quickly generate an API for any use case.\\nIn this example, you will create a simple Taco Ordering System.\\n\\n1. Open Postman\'s AI Agent and prompt:\\n\\n   ```\\n   Generate an API for a Taco ordering system with endpoints to view tacos and place an order.\\n   ```\\n2. The agent returns a Swagger (OpenAPI) specification for your taco API.\\n3. Review the generated specification to confirm it includes paths for:\\n\\n   * `GET /tacos`\\n   * `POST /order`\\n\\n:::info\\nSave the file in your `HAPI_HOME/specs` directory as `tacos.yaml` for use in the next step. (JSON format is also acceptable.)\\n:::\\n\\n---\\n\\n## Step 2: Start an MCP Server Using HAPI Server\\n\\nUse the [HAPI Server](https://hapi.mcp.com.ai) to host your Swagger API as an MCP server. This allows LLM-based clients such as ChatGPT to call your API directly.\\n\\n1. Connect to your instance and run the following command to start the MCP server:\\n\\n   ```bash\\n   bunx @la-rebelion/hapimcp serve tacos --headless --chatgpt\\n   ```\\n   \\n   Alternatively, you can use the native CLI (download from [GitHub releases](https://github.com/la-rebelion/hapimcp/releases)) and run:\\n\\n   ```bash\\n   hapi serve tacos --headless --chatgpt\\n   ```\\n2. Once running, expose the local server to the internet using ngrok:\\n\\n   ```bash\\n   ngrok http 8000\\n   ```\\n3. Copy the public URL generated by ngrok (e.g., `https://abcd1234.ngrok.io`).\\n\\n---\\n\\n## Step 3: Connect ChatGPT or Another Client to the MCP Server\\n\\n1. Open ChatGPT\'s settings and add a new connector with the ngrok URL you copied earlier.\\n2. Enable the connector.\\n   If the feature is not visible, note that **MCP connectors** in ChatGPT may still be in **beta**.\\n3. Alternatively, you can connect directly from an MCP-compatible client using the OpenAI SDK.\\n\\n---\\n\\n## Step 4: Test the MCP Server With OpenAI SDK\\n\\nYou can test the endpoint by sending a prompt that interacts with your Taco API.\\n\\n1. Initialize a new Bun project:\\n\\n   ```bash\\n   mkdir taco-client && cd taco-client\\n   bun init\\n   ```\\n2. Install dependencies:\\n\\n   ```bash\\n   bun install openai\\n   ```\\n3. Create an `index.ts` file and configure your endpoint:\\n\\n   ```typescript\\n   import OpenAI from \\"openai\\";\\n\\n   const client = new OpenAI({\\n     apiKey: process.env.OPENAI_API_KEY,\\n     baseURL: \\"https://abcd1234.ngrok.io/v1\\"\\n   });\\n\\n   const response = await client.chat.completions.create({\\n     model: \\"gpt-4.1\\",\\n     messages: [{ role: \\"user\\", content: \\"What tacos do you have in the menu?\\" }]\\n   });\\n\\n   console.log(response.choices[0].message);\\n   ```\\n4. Run the client:\\n\\n   ```bash\\n   bun run index.ts\\n   ```\\n\\nYou should see a response such as:\\n\\n```\\nWe have \\"carne asada\\" and \\"al pastor\\" tacos available.\\n```\\n\\n---\\n\\n## Step 5: Place an Order Through the API\\n\\nNow that your MCP server is connected, you can test the ordering functionality.\\n\\nRun:\\n\\n```bash\\nbun run index.ts\\n```\\n\\nWith the following request:\\n\\n```typescript\\nmessages: [\\n  { role: \\"user\\", content: \\"Place an order for 2 tacos al pastor and 1 carne asada.\\" }\\n]\\n```\\n\\nThe client confirms your order:\\n\\n```\\nOrder placed successfully!  \\nYou ordered 2 tacos al pastor and 1 carne asada.\\n```\\n\\n## Demo Video\\n\\n<ReactPlayer\\n  src=\'https://youtu.be/C6tz7K2og6I\'\\n  style={{ width: \'90%\', height: \'auto\', aspectRatio: \'4/3\' }}\\n  controls\\n/>\\n\\n---\\n\\n## Conclusion\\n\\nYou successfully:\\n\\n* Generated a Swagger API with Postman\'s AI Agent.\\n* Deployed it as an MCP server using HAPI Server.\\n* Exposed the service securely with ngrok.\\n* Connected and interacted with it using ChatGPT and Bun.\\n\\nThis setup allows you to prototype **API-first AI integrations** quickly. You can expand this demo to connect more endpoints or integrate it into a cluster for scalability.\\n\\n:::info\\nTo continue exploring, deploy your HAPI MCP server on **cloud instances** or integrate it into your existing CI/CD pipeline for real-world workloads.\\n:::\\n\\nBe HAPI, and go Rebels! \u270a\ud83c\udffd"},{"id":"/openai-meets-mcp","metadata":{"permalink":"/openai-meets-mcp","source":"@site/blog/openai-meets-mcp/index.mdx","title":"OpenAI SDK Meets MCP (Model Context Protocol)","description":"A comprehensive guide on how to integrate OpenAI\'s SDK with MCP (Model Context Protocol) to enhance AI model interactions through dynamic tool calling.","date":"2025-10-09T12:02:09.000Z","tags":[{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"OpenAI","permalink":"/tags/openai","description":"OpenAI is an AI research and deployment company focused on ensuring that artificial general intelligence benefits all of humanity.\\n"},{"inline":false,"label":"Tool Calling","permalink":"/tags/tool-calling","description":"Tool calling refers to the ability of AI models to invoke external tools or APIs to perform specific tasks or retrieve information, enhancing their functionality and capabilities.\\n"},{"inline":false,"label":"OAS","permalink":"/tags/oas","description":"OpenAPI Specification\u2014industry standard for describing RESTful APIs and enabling interoperability."},{"inline":false,"label":"Guide","permalink":"/tags/guide","description":"Curated instructions or documentation designed to help users understand and implement specific use cases around MCP and related technologies.\\n"}],"readingTime":5.87,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"OpenAI SDK Meets MCP (Model Context Protocol)","description":"A comprehensive guide on how to integrate OpenAI\'s SDK with MCP (Model Context Protocol) to enhance AI model interactions through dynamic tool calling.","authors":["adrian"],"tags":["mcp","openai","tool-calling","oas","guide"],"keywords":["OpenAI SDK","Model Context Protocol","MCP","Tool Calling","LLM Integration"],"image":"https://cdn.gamma.app/z3n406kubdfbysb/generated-images/ibH5HhVl1c3OZPUlUBXBp.png"},"unlisted":false,"prevItem":{"title":"Using OpenAI Response API for MCP Integration","permalink":"/use-openai-api-for-smooth-mcp-integration"},"nextItem":{"title":"MCP Threats and Misleadings - Prompt Injection","permalink":"/mcp-threats-prompt-injection"}},"content":"import ReactPlayer from \'react-player\'\\n\\nAn evolution of tool calling with MCP, thanks to OpenAI\'s latest SDK updates.\\n\\nStep-by-step, I\'ll guide you through setting up an MCP server, integrating it with the OpenAI SDK, and running a complete example that showcases **dynamic tool calling**. By the end of this post, you\'ll be equipped to leverage MCP in your own OpenAI-powered applications.\\n\\n\x3c!-- truncate --\x3e\\n\\nEnd-to-End Example, Setting Up an MCP Server, Integrating with OpenAI LLM, and Running some tests to see it in action.\\n\\n\\nMCP, or Model Context Protocol, is a framework that enhances how AI models interact with their operational context. By integrating MCP, you ensure your AI models are not only aware of the data they process but also the environment in which they operate. This leads to more accurate and contextually relevant outputs.\\n\\n## Why Integrate OpenAI with MCP?\\n\\nOpenAI\'s powerful language models take tool calling to the next level when you leverage MCP. This integration enables dynamic interactions, letting you build applications that adapt to various scenarios and user needs. I explained [how MCP tool calling works](/oas-v4-is-out#how-does-mcp-work-for-mere-mortals) in a previous post. Now, I\'ll show you how OpenAI\'s implementation impressed me.\\n\\nWith a simple, clever setup, you create applications that understand user queries in natural language and fetch relevant tools from MCP servers. This is extremely powerful\u2014it enables seamless, efficient interactions with AI models, making them more useful in real-world applications. Imagine an automated customer-support bot using MCP: it instantly retrieves necessary tools from MCP servers to resolve complex queries, such as billing discrepancies or technical troubleshooting, on the first call. This opens new possibilities for building intelligent applications that respond to user needs with greater precision and context-awareness.\\n\\nAnthropic\'s Claude Desktop app (MCP Client) was groundbreaking almost a year ago. Early adopters were impressed, and now OpenAI seamlessly integrates these capabilities into their SDKs. As the Spanish saying goes, \\"Nadie sabe para quien trabaja\\" (Nobody knows for whom they work), but MCP is clearly shaping the future of AI applications. OpenAI is making significant strides by implementing Anthropic\'s legacy directly in the LLM.\\n\\nYou can build smarter, more adaptive applications by letting AI models fetch and use tools from MCP servers, reducing manual integration and boosting context-awareness.\\n\\n:::note\\nThe OpenAI\'s MCP integration is currently in beta, so expect some rough edges. However, the potential is immense, and I\'m excited to see how this evolves.\\n:::\\n\\n## Three Approaches to Tool Calling\\n\\nYou have three main ways to implement tool calling:\\n\\n| Approach                   | Description                                                          | Key Strength                                  |\\n| -------------------------- | -------------------------------------------------------------------- | --------------------------------------------- |\\n| **MCP Clients**            | Intermediary applications bridging models and external tool servers. | Dynamic retrieval and adaptation              |\\n| **Direct Tool Calling**    | LLMs with built-in function calling via structured JSON.             | Precise programmatic control                  |\\n| **Native MCP Integration** | OpenAI\u2019s latest approach combining both worlds.                      | Automatic discovery and zero-config operation |\\n\\n\\nWhen choosing, remember: Direct Tool Calling is easy to set up but requires manual tool management. MCP Clients offer dynamic adaptability, fetching tools as needed and calling them for the user. LLMs with Native MCP Support provide the most seamless experience, automatically integrating and using tools from MCP Servers, though you may need some upfront knowledge about OpenAI\'s system and SDKs.\\n\\n**Summary:**  \\nSelect the approach that best fits your workflow\u2014manual, dynamic, or fully automated tool integration.\\n\\n:::note\\nThe OpenAI\'s MCP integration may not be call by the model directly; my guess is that it uses an internal MCP Client to fetch and call the tools, similar to how [QBot](https://docs.mcp.com.ai/components/qbot) works.\\n:::\\n\\n## End-to-End Example\\n\\nQuick check:\\n\\n```bash\\ncurl -X POST \\"https://api.openai.com/v1/responses\\" \\\\\\n -H \\"Authorization: Bearer $OPENAI_API_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d \'{\\n \\"model\\": \\"gpt-4.1\\",\\n \\"tools\\": [\\n {\\n \\"type\\": \\"mcp\\",\\n \\"server_label\\": \\"tacosmcp\\",\\n \\"server_url\\": \\"https://tacostore.run.mcp.com.ai\\",\\n \\"require_approval\\": \\"never\\"\\n }\\n ],\\n \\"input\\": \\"What tacos do you have in the menu?\\"\\n }\'\\n```\\n\\nLet\'s walk through the process: set up an MCP server, integrate the OpenAI SDK, write the code, run it, and see the results. These steps help you use MCP to enhance your applications.\\n\\n**Summary:**  \\nFollow these steps to quickly connect OpenAI models to MCP and unlock dynamic tool calling.\\n\\n### 1. Set Up an MCP Server\\n\\nFirst, set up an MCP server hosting the tools you want to use. You can run your own MCP server or use an existing one. For this example, use the HAPI MCP Server\u2014a simple way to get started. Find the [HAPI MCP Server docs here](https://docs.mcp.com.ai/components/hapi-server/).\\n\\nOpen a terminal, ensure Bun is installed, and run:\\n\\n```bash\\n# Start a HAPI MCP Server\\nbun dev serve tacos --headless\\n```\\n\\nThis starts a local MCP server hosting a tacos online store at `http://localhost:3000`. I asked [Postman Agent Builder](https://www.postman.com/product/ai-agent-builder/) to create a simple tacos store API, which I used for the MCP server.\\n\\n### 2. Create an OpenAI Account\\n\\nIf you don\'t have one, sign up for an OpenAI account and get your API key at the [OpenAI platform](https://platform.openai.com/).\\n\\n### 3. Install the OpenAI SDK\\n\\nUse the OpenAI SDK in your preferred language. For this example, use JavaScript and TypeScript with Bun. In another terminal, run:\\n\\n```bash\\n# Initialize a new Bun project\\nbun init -y -m\\n# Install the OpenAI SDK\\nbun add openai\\n```\\n\\n### 4. Write the Code\\n\\nCreate a new file, for example, `index.js`, and add:\\n\\n```javascript\\nimport OpenAI from \\"openai\\"\\n\\nconst client = new OpenAI({\\n  apiKey: process.env[\'OPENAI_API_KEY\'], // This is the default and can be omitted\\n})\\n\\nconst resp = await client.responses.create({\\n  model: \\"gpt-5\\",\\n  tools: [\\n    {\\n      type: \\"mcp\\",\\n      server_label: \\"tacosmcp\\",\\n      server_description: \\"The Tacos MCP Client\\",\\n      server_url: \\"https://tacostore.run.mcp.com.ai\\",\\n      require_approval: \\"never\\",\\n    },\\n  ],\\n  input: \\"What tacos do you have in the menu?\\",\\n})\\n\\nconsole.log(resp.output_text)\\n```\\n\\n### 5. Run the Code\\n\\nSet your OpenAI API key in the `OPENAI_API_KEY` environment variable, then run:\\n\\n```bash\\nbun run index.js\\n```\\n\\n### 6. See the Magic\\n\\nThe model fetches tools from the MCP server and uses them to answer your query. You should see a response listing the tacos available on the menu. To reinforce your learning, validate the returned taco list against the API response. This simple verification ensures tool execution works correctly and builds confidence in using MCP.\\n\\n### 7. Explore Further\\n\\nModify the input query to ask different questions or explore other tools on the MCP server. The possibilities are endless!\\n\\n**Summary:**  \\nYou can set up, connect, and validate MCP-powered tool calling in minutes, then experiment to discover more capabilities.\\n\\n## Demo Video\\n\\n<ReactPlayer\\n  src=\'https://youtu.be/hKN-5ZnVcnU\'\\n  style={{ width: \'90%\', height: \'auto\', aspectRatio: \'4/3\' }}\\n  controls\\n/>\\n\\n## Conclusion\\n\\nIntegrating OpenAI with MCP unlocks a world of possibilities for building intelligent applications that adapt to various scenarios and user needs. By leveraging MCP, you create dynamic, context-aware interactions with AI models, leading to more accurate and relevant outputs.\\n\\n**Summary:**  \\nUse MCP to make your AI applications smarter, more flexible, and better suited to real-world challenges.\\n\\n## References\\n\\n- [OpenAI API Documentation](https://platform.openai.com/docs/)\\n- [Connectors and MCP servers (Beta)](https://platform.openai.com/docs/guides/tools-connectors-mcp?lang=javascript)\\n- [OpenAI NPM Package](https://www.npmjs.com/package/openai)\\n- [Model Context Protocol (MCP) Overview](https://modelcontextprotocol.io/)"},{"id":"/mcp-threats-prompt-injection","metadata":{"permalink":"/mcp-threats-prompt-injection","source":"@site/blog/mcp-threats-prompt-injection.md","title":"MCP Threats and Misleadings - Prompt Injection","description":"An overview of threats and misleadings related to prompt injection in the context of MCP (Model Context Protocol).","date":"2025-10-08T11:36:31.000Z","tags":[{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"Security","permalink":"/tags/security","description":"Security involves protecting systems, networks, and data from digital attacks, unauthorized access, and damage\\n"}],"readingTime":3.15,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"MCP Threats and Misleadings - Prompt Injection","description":"An overview of threats and misleadings related to prompt injection in the context of MCP (Model Context Protocol).","authors":["adrian"],"tags":["mcp","security"],"image":"https://cdn.gamma.app/z3n406kubdfbysb/generated-images/trv8ZioPQIQ84iK46Bd8B.png"},"unlisted":false,"prevItem":{"title":"OpenAI SDK Meets MCP (Model Context Protocol)","permalink":"/openai-meets-mcp"},"nextItem":{"title":"Swagger/OAS v4 Is out","permalink":"/oas-v4-is-out"}},"content":"Prompt injection is a critical security risk for any system using large language models (LLMs), including those built with Model Context Protocol (MCP). You must understand how prompt injection works, why MCP cannot prevent it, and what steps you should take to protect your users and applications (MCP Clients).\\n\\n\x3c!-- truncate --\x3e\\n\\n## Introduction\\n\\nMCP enables users and clients to discover and pull prompts from MCP Servers. This flexibility means you, as a client developer, are responsible for validating and sanitizing all user inputs before they reach the LLM. MCP Clients act as intermediaries between MCP Servers, end users, and LLMs. If you do not implement proper validation, malicious prompts can reach the LLM and cause harmful or unintended outputs.\\n\\n:::warning\\nPrompt injection is recognized as a top risk by OpenAI ([OpenAI Prompt Injection Guide](https://platform.openai.com/docs/guides/prompt-injection)), Anthropic ([Anthropic Prompt Injection FAQ](https://www.anthropic.com/index/prompt-injection)), and OWASP ([OWASP AI Security Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)).\\n:::\\n\\n## How Prompt Injection Works in MCP\\n\\n```mermaid\\nflowchart RL\\n  A[Client Developer] --\x3e|Builds| E[MCP Client]\\n  E --\x3e|Connects to| B[MCP Server]\\n  B --\x3e|Serves Prompts| E\\n  E --\x3e|Delivers Prompts| C[End User]\\n  C --\x3e|Inputs/Queries| E\\n  E --\x3e|Forwards Inputs| D[LLM]\\n  D --\x3e|Generates Responses| E\\n  E --\x3e|Returns Responses| C\\n  B --\x3e|Provides Prompts| E\\n  subgraph Perspectives\\n    E\\n    C\\n    D\\n  end\\n```\\n\\n**Key Roles:**\\n- **Client Developer:** You build MCP Clients and must implement security and validation.\\n- **MCP Client:** Your app acts as an intermediary, handling prompt delivery and user input forwarding.\\n- **End User:** Users interact with LLMs via MCP Clients and may provide inputs that could be exploited.\\n- **LLM:** Processes prompts and user inputs, vulnerable to prompt injection if upstream validation is insufficient.\\n\\n## Threats\\n\\nPrompt injection can lead to several serious risks:\\n\\n- **Malicious Prompts:** Attackers craft prompts to manipulate the LLM into generating harmful or unintended outputs ([OpenAI](https://platform.openai.com/docs/guides/prompt-injection)).\\n- **User Input Manipulation:** End users may input data designed to exploit vulnerabilities in the LLM\'s response generation ([Anthropic](https://www.anthropic.com/index/prompt-injection)).\\n- **Data Leakage:** Sensitive information may be exposed through manipulated prompts or responses ([NIST AI RMF](https://airmf.nist.gov/)).\\n- **Reputation Damage:** Misleading outputs generated by LLMs due to prompt injection can harm your application\'s reputation.\\n\\n## Common Misleadings\\n\\nAvoid these misconceptions:\\n\\n- **False Sense of Security:** MCP does not provide inherent protection against prompt injection. You must implement your own safeguards.\\n- **Overreliance on LLMs:** LLMs do not automatically handle all types of inputs safely. Validation is essential.\\n- **Misunderstanding Roles:** Security measures must be implemented in the MCP Client, not just the server or LLM.\\n- **Assumption of Trustworthiness:** Do not trust all prompts from third-party MCP Servers. Use official or self-hosted servers when possible ([OWASP](https://owasp.org/www-project-top-10-for-large-language-model-applications/)).\\n- **Neglecting Client Responsibility:** Input validation is your responsibility as the MCP Client developer.\\n\\n## Mitigation Strategies\\n\\nFollow these best practices to reduce prompt injection risks:\\n\\n1. **Input Validation:** Check all user inputs for malicious content before forwarding to the LLM ([OWASP](https://owasp.org/www-project-top-10-for-large-language-model-applications/)).\\n2. **Sanitization:** Remove or neutralize potentially harmful elements in user inputs.\\n3. **User Education:** Inform users about prompt injection risks and safe input practices.\\n4. **Regular Audits:** Audit your MCP Client regularly to identify and fix vulnerabilities.\\n5. **Monitoring and Logging:** Track interactions and flag suspicious activities for review.\\n\\n## References\\n\\n- [OpenAI: Prompt Injection Guide](https://platform.openai.com/docs/guides/prompt-injection)\\n- [Anthropic: Prompt Injection FAQ](https://www.anthropic.com/index/prompt-injection)\\n- [OWASP: Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)\\n- [NIST: AI Risk Management Framework](https://airmf.nist.gov/)\\n\\nBy understanding and addressing these threats, you can secure your MCP Client against prompt injection vulnerabilities and protect your users and reputation."},{"id":"/oas-v4-is-out","metadata":{"permalink":"/oas-v4-is-out","source":"@site/blog/oas-v4-is-out.mdx","title":"Swagger/OAS v4 Is out","description":"Exploring the potential of OpenAPI Specification (OAS) v4 for AI tool integration and how it can complement Model Context Protocol (MCP).","date":"2025-10-08T11:36:31.000Z","tags":[{"inline":false,"label":"OAS","permalink":"/tags/oas","description":"OpenAPI Specification\u2014industry standard for describing RESTful APIs and enabling interoperability."},{"inline":false,"label":"MCP","permalink":"/tags/mcp","description":"MCP is an open protocol for connecting LLM apps to external data sources and tools, enabling seamless integration and interoperability.\\n"},{"inline":false,"label":"API","permalink":"/tags/api","description":"An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate and interact with each other.\\n"},{"inline":false,"label":"AI","permalink":"/tags/ai","description":"Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think and learn like humans.\\n"}],"readingTime":9.81,"hasTruncateMarker":true,"authors":[{"name":"Adrian Escutia","title":"La Rebelion Founder","url":"https://adrian.escutia.me","page":{"permalink":"/authors/adrian"},"socials":{"x":"https://x.com/ades_mx","linkedin":"https://www.linkedin.com/in/adrianescutia/","github":"https://github.com/adrianescutia","newsletter":"https://rebelion.la"},"bio":"Adrian is the founder of La Rebelion, a newsletter about AI, technology, and the future. He is also a software engineer and entrepreneur.","imageURL":"https://github.com/adrianescutia.png","key":"adrian"}],"frontMatter":{"title":"Swagger/OAS v4 Is out","description":"Exploring the potential of OpenAPI Specification (OAS) v4 for AI tool integration and how it can complement Model Context Protocol (MCP).","authors":["adrian"],"tags":["oas","mcp","api","ai"],"image":"/img/ai-friend-chatting.png"},"unlisted":false,"prevItem":{"title":"MCP Threats and Misleadings - Prompt Injection","permalink":"/mcp-threats-prompt-injection"}},"content":"import ReactPlayer from \'react-player\'\\n\\n\ud83d\udea8 \\"OpenAPI Specification (OAS) v4 is out\\" - *That I wish*, this is the kind of headline I would expect to see soon, because OAS can easily be extended to enable RESTful APIs work seamlessly with AI. \\n\\nBy the end of this article, you\'ll know how to let any LLM call your REST tools automatically using OAS.\\n\\n\x3c!-- truncate --\x3e\\n\\n**What Does It Mean for AI Tool Integration?** Let\'s explore how OAS v4 could fit into the AI landscape, complementing protocols like Model Context Protocol (MCP). \\n\\n:::note  \\nThis is a speculative article about what I would like to see in OAS v4, based on my experience with Model Context Protocol (MCP) and AI tool integration. OAS v4 is not yet released, and this article is not endorsed by the OpenAPI Initiative or any other organization.  \\n:::\\n\\nOver the past decade, OAS has become the standard for describing RESTful APIs and is widely adopted across various industries. Now, it\'s time to expand it to cover AI use cases, addressing the evolving needs of developers.\\n\\nModel Context Protocol (MCP) has recently gained a lot of attention. It\'s great for local integrations, allows you to adjust the MCP server for backend connections, and with the latest updates, it can now handle remote calls, moving closer to RESTful APIs. \\n\\nSince the beginning [MCP was designed for local integrations mainly](https://rebelion.la/model-context-protocol-mcp-is-it-a-protocol-or-a-contract#heading-the-lsp-connection-understanding-mcps-roots). The breakthrough of MCP lies in its **ability to let the LLM discover the tools available**. This tool discovery feature marks MCP\'s unique value proposition, transforming the way we approach AI integrations. From there, everything falls into place similar to RESTful APIs: the client acts as a lightweight orchestration layer, the server handles the backend tasks, and the LLM plays the role of the brain, deciding which tools to use and how to use them.\\n\\n## How does MCP work? For mere mortals\\n\\nI have noticed that many people struggle to understand how MCP works, so let me try to explain it in a simple way.\\n\\nLet\'s imagine a conversation between the client (you), the LLM (a friend), and the server (weather guy):\\n\\nSetting the scene: you have a person (the MCP Server) who speaks a language you don\'t understand, such as French, and you have a friend who speaks both languages (The LLM), French and English. You\'d like to know the weather in Paris, so you can ask your friend for help. Your friend asks the person in French, gets the answer, and translates it back to you in English. In this scenario, your friend represents the LLM supporting tool calling natively. \\n\\nNow, imagine you can write in French but don\'t speak it fluently. You\'d like to know the weather in Paris, but this time you need someone to guide you on what to ask in French. You write the message asking for the weather. Once you receive the answer, you can translate it without help. This scenario reflects the role of an LLM that doesn\'t support tool calling natively, and the client has to call the tool directly.\\n\\nComplex, right? Let\'s see it in a sequence diagram:\\n\\n```mermaid\\nsequenceDiagram\\n  participant U as User\\n  participant C as Client\\n  participant L as LLM\\n  participant S as Server\\n  U->>C: User input<br/>(e.g., \\"What tacos do you have in the menu?\\")\\n  C->>S: Fetch API spec (tools/list)\\n  S--\x3e>C: API spec (tools [list])\\n  alt LLM supports tool calling\\n    C->>L: API spec (tools [list])\\n    C->>L: User input & context<br/>(user preference, etc)\\n    L--\x3e>C: Tool selection<br/>(assistant suggests a function call)\\n    C->>S: API call\\n  else LLM does not support tool calling\\n    C->>L: User input, tools [list] & context<br/>(user preference, etc)\\n    L--\x3e>C: Tool selection\\n    C->>S: API call<br/>(Client decides protocol, auth, etc)\\n  end\\n  S--\x3e>C: API response\\n  C--\x3e>L: API response\\n  L--\x3e>C: Result to user\\n  C--\x3e>U: Final response\\n```\\n\\nThe LLM receives a prompt with a description of the [available tools](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#listing-tools). This tool list can be [mapped from the OpenAPI spec](https://rebelion.la/you-dont-need-to-implement-mcp-servers-a-contract-first-approach-to-ai-tool-integration?showSharer=true#heading-example-conversion-openapi-mcp). The LLM then chooses which tool to use and how to use it. The client simply passes the user input to the LLM, which decides what to do next. Some LLMs, like GPT-4-turbo and Llama2, support tool calling natively. Others, like Claude, do not, so the client calls the tool directly, based on the LLM\'s instruction.\\n\\nAs you can see, either the LLM supports tool calling natively or not, the flow is similar. The only difference is that in the latter case, the client does the call to the server, and forwards the response to the LLM to get the final result for the end-user - based on the LLM\'s instruction.\\n\\n## OAS v4 - The missing piece\\n\\nThe missing piece in OAS compared to MCP is that OAS does not have a discovery mechanism for the LLM to know which tools are available. This is where OAS v4 could shine, by adding a way for the LLM to discover the API spec and the available tools.\\n\\nImagine if OAS v4 had a way to describe the tools available in a way that the LLM could understand, and then the LLM could decide which tool to use, and how to use it. This would make it possible for any LLM to work seamlessly with RESTful APIs, without the need for a separate protocol like MCP, or even better, MCP could be used as a contract-first approach to AI tool integration, where the OAS v4 spec is the contract that defines the tools available, and the MCP server implements the backend logic. That\'s precisely what I have been advocating for a while now with my [contract-first approach to AI tool integration](https://rebelion.la/you-dont-need-to-implement-mcp-servers-a-contract-first-approach-to-ai-tool-integration?showSharer=true) and the *Headless API* (HAPI) initiative for MCP.\\n\\nNow that I have explained how MCP works, and how OAS v4 could be the missing piece, I hope you can see the potential of OAS v4 for AI tool integration. But, don\'t stop here, next is what I would like to see in OAS v4.\\n\\n## What You Should Expect in OAS v4\\n\\nOAS v4 is not just an incremental update\u2014it\'s an opportunity to rethink how APIs and AI tools work together. Here is what you should expect and advocate for in the next version, based on best practices and the needs of modern AI integrations.\\n\\n## Modular, Multi-File API Specifications\\n\\nYou need modular specs for real-world APIs. OAS v4 should support multi-file specifications natively, allowing you to break down large APIs into smaller, reusable modules (for example, pets, users, orders). This approach enhances maintainability and collaboration across teams. Instead of a single massive file, you organize your API into logical domains:\\n\\n- **API Root:** Main file with info, servers, and tags.\\n- **Security:** Dedicated files for OAuth2 and other schemes.\\n- **Paths by Domain:** Split endpoints into logical groups (e.g. `pet.api.yaml`, `user.api.yaml`).\\n- **Components/Models:** Reusable schemas separated by domain.\\n\\nThis modular structure keeps specs manageable (500\u20131000 lines each) and enables code generators and clients to see one unified spec. Tools like [Redocly CLI](https://redocly.com/docs/cli/file-management#one-large-file-to-many-small-ones) already offer splitting, but OAS v4 should standardize it. Modular specs also help AI tools (MCP servers) consume only the relevant modules, **improving performance and reducing cognitive load for LLMs** that may have context length limitations and make the LLMs\' job easier when deciding which tools to use.\\n\\n:::info\\nThe current `$ref` approach only allows referencing individual components, not entire files. Modular specs let you load what you need, when you need it.\\n:::\\n\\n**Benefits:**\\n- Parallel development and reviews\\n- Domain-specific clients (AI agents load only relevant modules)\\n- Easier maintenance and updates\\n- Improved collaboration\\n- Better tooling support\\n- Granular security schemes\\n\\n## Well-Known Tools Manifest for AI Discovery\\n\\nAI clients must discover available tools easily. OAS v4 should adopt a well-known URI convention (such as `/.well-known/mcp/tools-manifest.json`) so MCP clients and AI agents can auto-discover your API\'s tools. This follows patterns from [OpenID Connect Discovery](https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig) and [OAuth 2.0 Security Scheme](https://spec.openapis.org/oas/v3.2.0.html#security-scheme-object). Give agents a predictable URL to learn your API\u2014this small change pays off big in discoverability.\\n\\n## AI-First Annotations and Metadata\\n\\nOAS v4 should introduce AI-first annotations to help clients and LLMs use APIs effectively. Add metadata extensions (such as `x-llm-hint`, `x-llm-example`) to endpoints, parameters, and responses. Use the [`kind`](https://spec.openapis.org/registry/tag-kind/) property to categorize tags for AI relevance. For example:\\n\\n```yaml\\ntags:\\n  - name: contacts\\n    summary: Manage contacts\\n    description: Endpoints for creating, updating, and searching contacts\\n    kind: ai-tool\\n\\n  - name: internal\\n    summary: Internal admin endpoints\\n    description: Endpoints not intended for AI or public use\\n    kind: internal\\n```\\n\\nWith this approach, AI agents and MCP servers filter and discover only the endpoints relevant for tool calling, ignoring internal or non-AI endpoints. You can further extend this pattern with custom extensions:\\n\\n```yaml\\npaths:\\n  /contacts/search:\\n    get:\\n      tags: [contacts]\\n      x-llm-hint: \\"Use this endpoint to search for contacts by name or email.\\"\\n      x-llm-example: \\"Find all contacts named Alice.\\"\\n```\\n\\nThese annotations guide LLMs on how to use specific endpoints, making your API more AI-friendly and discoverable.\\n\\n## References\\n\\n- [OpenAPI Specification](https://spec.openapis.org/oas/latest.html)\\n- [Redocly CLI: File Management](https://redocly.com/docs/cli/file-management#one-large-file-to-many-small-ones)\\n- [OpenID Connect Discovery](https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig)\\n- [OWASP AI Security Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)\\n\\nBy advocating for these features, you help shape OAS v4 into a standard that supports scalable, AI-ready APIs for the next generation of applications.\\n\\n## Example: Conversion OpenAPI \u2192 MCP\\n\\nHere is a simple example of how an OpenAPI spec can be converted to an MCP tools manifest.\\n\\nUsing the [Petstore example](https://petstore3.swagger.io/api/v3/openapi.json) from Swagger, we can extract the relevant information to create an MCP tools manifest. Deploying an MCP server with the [`hapi` server](https://docs.mcp.com.ai/components/hapi-server/), we can extend the OpenAPI spec with AI-first annotations and modular structure.\\n\\nIn the demo below, the Petstore API is extended to integrate WorkOS for authentication, and the OpenAPI spec is modularized into separate files for better organization.\\n\\n```yaml\\napiVersion: mcp.com.ai/v1\\nkind: Security\\nmetadata:\\n  name: hapi-security-config\\n  namespace: demo\\n  labels:\\n    app: demo\\n  annotations:\\n    description: HAPI server security configuration\\n    owner: team-hapi\\n    environment: development\\n    version: v1.0.0\\nspec:\\n  cors:\\n    enabled: true\\n    origin:\\n      - http://localhost:8080 # Your MCP Client\\n      - http://localhost:6274 # MCP Inspector\\n    headers:\\n      - Content-Type\\n      - Authorization\\n      - X-Requested-With\\n    methods:\\n      - GET\\n      - POST\\n      - PUT\\n      - DELETE\\n      - OPTIONS\\n  security:\\n    demo_auth:\\n      client_id: client_0\\n      well-known: https://*****.app/.well-known/oauth-authorization-server\\n  securitySchemes:\\n    demo_auth:\\n      type: oauth2\\n      flows:\\n        authorizationCode:\\n          authorizationUrl: https://api.workos.com/sso/authorize?connection=conn_01\\n          tokenUrl: https://*****.app/oauth2/token\\n          scopes:\\n            read: Read\\n            write: Modify\\n            admin: Access to admin operations\\n            read_all: Read private resources\\n```\\n\\n<ReactPlayer\\n  src=\'https://youtu.be/S2_Z0rbnOH8\'\\n  style={{ width: \'90%\', height: \'auto\', aspectRatio: \'4/3\' }}\\n  controls\\n/>\\n\\n## Conclusion\\n\\nOAS v4 has the potential to revolutionize how AI systems interact with RESTful APIs. By incorporating modular specs, AI-first annotations, and well-known discovery endpoints, OAS v4 can make it easier for LLMs to understand and utilize APIs effectively. This would not only benefit developers but also pave the way for more seamless AI integrations across various applications."}]}}')}}]);