<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>MCP AI Blog Blog</title>
        <link>https://mcp.com.ai</link>
        <description>MCP AI Blog Blog</description>
        <lastBuildDate>Tue, 06 Jan 2026 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[When Not to Use AI: Deterministic Workflows in Production Systems]]></title>
            <link>https://mcp.com.ai/when-not-to-use-ai</link>
            <guid>https://mcp.com.ai/when-not-to-use-ai</guid>
            <pubDate>Tue, 06 Jan 2026 00:00:00 GMT</pubDate>
            <description><![CDATA[Exploring why AI isn't always the right tool for every task in production systems, and how deterministic workflows can provide reliability and cost-efficiency.]]></description>
            <content:encoded><![CDATA[<p><strong>AI is everywhere. Too everywhere.</strong>
From answering ‚Äúhi‚Äù to deciding how your production platform runs sanity checks, we've quietly crossed a line. Not because AI <em>can't</em> do these things, but because <strong>it shouldn't do all of them</strong>.</p>
<p>This post is not anti-AI. Quite the opposite.
It's about <strong>using AI where it creates leverage</strong>, and removing it where it quietly burns money, reliability, and trust.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="is-ai-needed-for-everything">Is AI Needed for Everything?<a href="https://mcp.com.ai/when-not-to-use-ai#is-ai-needed-for-everything" class="hash-link" aria-label="Direct link to Is AI Needed for Everything?" title="Direct link to Is AI Needed for Everything?" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-determinism-still-wins-in-production-systems">Why Determinism Still Wins in Production Systems<a href="https://mcp.com.ai/when-not-to-use-ai#why-determinism-still-wins-in-production-systems" class="hash-link" aria-label="Direct link to Why Determinism Still Wins in Production Systems" title="Direct link to Why Determinism Still Wins in Production Systems" translate="no">‚Äã</a></h3>
<p>I recently saw a meme: two young people ‚Äútalking‚Äù to each other, but every response is generated by AI.
It's funny. Then it's awkward. Then it's uncomfortable.</p>
<p>Because the joke hides a real question:</p>
<blockquote>
<p>If we outsource even basic interaction to AI‚Ä¶
what else are we delegating without thinking?</p>
</blockquote>
<p>And in tech, especially in platforms, DevOps, and production systems, that question matters a lot.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-problem-isnt-ai-its-where-we-put-it">The Problem Isn't AI. It's Where We Put It.<a href="https://mcp.com.ai/when-not-to-use-ai#the-problem-isnt-ai-its-where-we-put-it" class="hash-link" aria-label="Direct link to The Problem Isn't AI. It's Where We Put It." title="Direct link to The Problem Isn't AI. It's Where We Put It." translate="no">‚Äã</a></h2>
<p>Let's be clear:
AI is amazing at <strong>ambiguity</strong>.</p>
<ul>
<li class="">Natural language</li>
<li class="">Exploration</li>
<li class="">Reasoning with incomplete context</li>
<li class="">Translating intent into action</li>
</ul>
<p>But production systems are not ambiguous.
They are built on <strong>expectations</strong>.</p>
<ul>
<li class="">Health checks must be consistent</li>
<li class="">Sanity tests must be repeatable</li>
<li class="">Compliance workflows must be predictable</li>
<li class="">Outcomes must be explainable</li>
</ul>
<p>When we mix those two worlds carelessly, we get something dangerous:
<strong>non-deterministic logic running deterministic systems</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-real-example-run-full-platform-sanity">A Real Example: ‚ÄúRun Full Platform Sanity‚Äù<a href="https://mcp.com.ai/when-not-to-use-ai#a-real-example-run-full-platform-sanity" class="hash-link" aria-label="Direct link to A Real Example: ‚ÄúRun Full Platform Sanity‚Äù" title="Direct link to A Real Example: ‚ÄúRun Full Platform Sanity‚Äù" translate="no">‚Äã</a></h2>
<p>I've seen teams implement AI-driven solutions for things like:</p>
<ul>
<li class="">Platform health checks</li>
<li class="">Full sanity runs</li>
<li class="">Operational diagnostics</li>
</ul>
<p>The UX looks great:</p>
<blockquote>
<p>‚ÄúHey AI, run a full sanity of my platform.‚Äù</p>
</blockquote>
<p>Much better than clicking through a complex UI, right?</p>
<p>Yes.
But let's look under the hood.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-actually-happens">What Actually Happens<a href="https://mcp.com.ai/when-not-to-use-ai#what-actually-happens" class="hash-link" aria-label="Direct link to What Actually Happens" title="Direct link to What Actually Happens" translate="no">‚Äã</a></h3>
<ol>
<li class="">
<p>The LLM interprets the request</p>
</li>
<li class="">
<p>It decides which tools to call</p>
</li>
<li class="">
<p>It invokes them <strong>one by one</strong></p>
</li>
<li class="">
<p>Each call:</p>
<ul>
<li class="">Consumes tokens</li>
<li class="">Adds latency</li>
<li class="">Introduces uncertainty</li>
</ul>
</li>
</ol>
<p>Same request.
Different day.
Different internal reasoning path.</p>
<p>Same <em>intent</em>, potentially different <em>execution</em>.</p>
<p>That's not intelligence.
That's a <strong>token-powered slot machine</strong> üé∞.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-token-black-hole-no-one-talks-about">The Token Black Hole No One Talks About<a href="https://mcp.com.ai/when-not-to-use-ai#the-token-black-hole-no-one-talks-about" class="hash-link" aria-label="Direct link to The Token Black Hole No One Talks About" title="Direct link to The Token Black Hole No One Talks About" translate="no">‚Äã</a></h2>
<p>From a business perspective, this matters.</p>
<p>Simple operational tasks:</p>
<ul>
<li class="">Are repeated often</li>
<li class="">Have stable logic</li>
<li class="">Produce the same expected result every time</li>
</ul>
<p>Using an LLM for these tasks means:</p>
<ul>
<li class="">Paying token costs for zero new information</li>
<li class="">Debugging behavior that should never change</li>
<li class="">Accepting variability where none should exist</li>
</ul>
<p><strong>Executives see this as cost leakage.</strong>
<strong>Architects see it as system fragility.</strong>
<strong>Engineers feel it as unnecessary complexity.</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-wrong-question-we-keep-asking">The Wrong Question We Keep Asking<a href="https://mcp.com.ai/when-not-to-use-ai#the-wrong-question-we-keep-asking" class="hash-link" aria-label="Direct link to The Wrong Question We Keep Asking" title="Direct link to The Wrong Question We Keep Asking" translate="no">‚Äã</a></h2>
<p>Most teams ask:</p>
<blockquote>
<p>‚ÄúCan AI do this?‚Äù</p>
</blockquote>
<p>The better questions are:</p>
<ul>
<li class=""><strong>Should AI do this?</strong></li>
<li class=""><strong>What part of this needs intelligence?</strong></li>
<li class=""><strong>What part should be guaranteed?</strong></li>
</ul>
<p>Because the truth is:
<strong>AI is not a workflow engine.</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="deterministic-workflows-are-not-anti-ai">Deterministic Workflows Are Not Anti-AI<a href="https://mcp.com.ai/when-not-to-use-ai#deterministic-workflows-are-not-anti-ai" class="hash-link" aria-label="Direct link to Deterministic Workflows Are Not Anti-AI" title="Direct link to Deterministic Workflows Are Not Anti-AI" translate="no">‚Äã</a></h2>
<p>Here's the mental shift that changes everything:</p>
<blockquote>
<p>AI should decide <em>what</em> to do.
Deterministic systems should decide <em>how</em> it's done.</p>
</blockquote>
<p>This is not a compromise.
It's an optimization.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ai-does">AI does:<a href="https://mcp.com.ai/when-not-to-use-ai#ai-does" class="hash-link" aria-label="Direct link to AI does:" title="Direct link to AI does:" translate="no">‚Äã</a></h3>
<ul>
<li class="">Intent understanding</li>
<li class="">Decision making</li>
<li class="">Tool selection at a high level</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="deterministic-systems-do">Deterministic systems do:<a href="https://mcp.com.ai/when-not-to-use-ai#deterministic-systems-do" class="hash-link" aria-label="Direct link to Deterministic systems do:" title="Direct link to Deterministic systems do:" translate="no">‚Äã</a></h3>
<ul>
<li class="">Execution</li>
<li class="">Sequencing</li>
<li class="">Error handling</li>
<li class="">Consistent outcomes</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="from-n-tools-to-one-outcome">From N Tools to One Outcome<a href="https://mcp.com.ai/when-not-to-use-ai#from-n-tools-to-one-outcome" class="hash-link" aria-label="Direct link to From N Tools to One Outcome" title="Direct link to From N Tools to One Outcome" translate="no">‚Äã</a></h2>
<p>Let's simplify.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-na√Øve-ai-first-approach">The na√Øve AI-first approach<a href="https://mcp.com.ai/when-not-to-use-ai#the-na%C3%AFve-ai-first-approach" class="hash-link" aria-label="Direct link to The na√Øve AI-first approach" title="Direct link to The na√Øve AI-first approach" translate="no">‚Äã</a></h3>
<ul>
<li class="">
<p>Expose <strong>N tools</strong> to the LLM</p>
</li>
<li class="">
<p>Let it figure out:</p>
<ul>
<li class="">Order</li>
<li class="">Dependencies</li>
<li class="">Retries</li>
<li class="">Failure modes</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-smarter-hybrid-approach">The smarter hybrid approach<a href="https://mcp.com.ai/when-not-to-use-ai#the-smarter-hybrid-approach" class="hash-link" aria-label="Direct link to The smarter hybrid approach" title="Direct link to The smarter hybrid approach" translate="no">‚Äã</a></h3>
<ul>
<li class="">
<p>Map the workflow once</p>
</li>
<li class="">
<p>Make it deterministic</p>
</li>
<li class="">
<p>Expose <strong>one tool</strong>:</p>
<blockquote>
<p>‚ÄúRun full platform sanity‚Äù</p>
</blockquote>
</li>
</ul>
<p>Same result.
Lower cost.
Higher reliability.</p>
<hr>
<p><img decoding="async" loading="lazy" src="https://weaviate.io/assets/images/types-of-workflows-8976ed4aad76322779634ef312962ae4.jpg" alt="Image" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://orkes.io/images/blogs/2025-05-19-agentic-ai-explained/Agentic-AI-Explained_Banner.jpg" alt="Image" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://www.researchgate.net/publication/398593556/figure/fig3/AS%3A11431281813750659%401766671032077/Hybrid-CNN-Transformer-LSTM-architecture-and-edge-AI-deployment-workflow.tif" alt="Image" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="this-is-where-standards-quietly-save-us">This Is Where Standards Quietly Save Us<a href="https://mcp.com.ai/when-not-to-use-ai#this-is-where-standards-quietly-save-us" class="hash-link" aria-label="Direct link to This Is Where Standards Quietly Save Us" title="Direct link to This Is Where Standards Quietly Save Us" translate="no">‚Äã</a></h2>
<p>This approach works because we already have the right building blocks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="deterministic-workflows">Deterministic workflows<a href="https://mcp.com.ai/when-not-to-use-ai#deterministic-workflows" class="hash-link" aria-label="Direct link to Deterministic workflows" title="Direct link to Deterministic workflows" translate="no">‚Äã</a></h3>
<p>Defined once, versioned, testable.</p>
<p>That's where <strong>Arazzo</strong> comes in.
Arazzo lets you describe workflows declaratively, no prompts, no guessing.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="execution-engine">Execution engine<a href="https://mcp.com.ai/when-not-to-use-ai#execution-engine" class="hash-link" aria-label="Direct link to Execution engine" title="Direct link to Execution engine" translate="no">‚Äã</a></h3>
<p>Those workflows need an orchestrator.</p>
<p>That's the role of <strong>OrcA</strong>:</p>
<ul>
<li class="">Executes deterministic workflows</li>
<li class="">Handles sequencing and retries</li>
<li class="">Guarantees consistent outcomes</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="capabilities-as-apis">Capabilities as APIs<a href="https://mcp.com.ai/when-not-to-use-ai#capabilities-as-apis" class="hash-link" aria-label="Direct link to Capabilities as APIs" title="Direct link to Capabilities as APIs" translate="no">‚Äã</a></h3>
<p>Your system capabilities already exist.</p>
<p>They are defined using the <strong>OpenAPI Specification (OAS)</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="exposing-outcomes-to-ai">Exposing outcomes to AI<a href="https://mcp.com.ai/when-not-to-use-ai#exposing-outcomes-to-ai" class="hash-link" aria-label="Direct link to Exposing outcomes to AI" title="Direct link to Exposing outcomes to AI" translate="no">‚Äã</a></h3>
<p>Now the key step:
Expose <em>workflows</em>, not raw operations, as AI tools.</p>
<p>That's exactly what <strong>HAPI MCP</strong> enables.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-mapping-that-changes-everything">The Mapping That Changes Everything<a href="https://mcp.com.ai/when-not-to-use-ai#the-mapping-that-changes-everything" class="hash-link" aria-label="Direct link to The Mapping That Changes Everything" title="Direct link to The Mapping That Changes Everything" translate="no">‚Äã</a></h2>
<p>Once you see it, it's hard to unsee:</p>
<ul>
<li class="">
<p><strong>Arazzo ‚Üí OrcA</strong>
Deterministic workflows, executed reliably</p>
</li>
<li class="">
<p><strong>OAS ‚Üí HAPI MCP</strong>
APIs and workflows exposed as MCP tools</p>
</li>
</ul>
<p>The LLM doesn't need to know <em>how</em> the sanity check runs.
It only needs to know <strong>that it exists</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-this-unlocks-for-everyone">What This Unlocks (For Everyone)<a href="https://mcp.com.ai/when-not-to-use-ai#what-this-unlocks-for-everyone" class="hash-link" aria-label="Direct link to What This Unlocks (For Everyone)" title="Direct link to What This Unlocks (For Everyone)" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-ai-systems">For AI systems<a href="https://mcp.com.ai/when-not-to-use-ai#for-ai-systems" class="hash-link" aria-label="Direct link to For AI systems" title="Direct link to For AI systems" translate="no">‚Äã</a></h3>
<ul>
<li class="">Fewer tools to reason about</li>
<li class="">Cleaner context</li>
<li class="">Lower token usage</li>
<li class="">Higher accuracy</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-developers">For Developers<a href="https://mcp.com.ai/when-not-to-use-ai#for-developers" class="hash-link" aria-label="Direct link to For Developers" title="Direct link to For Developers" translate="no">‚Äã</a></h3>
<ul>
<li class="">Predictable behavior</li>
<li class="">Reusable workflows</li>
<li class="">Easier testing</li>
<li class="">No prompt gymnastics</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-product-managers">For Product Managers<a href="https://mcp.com.ai/when-not-to-use-ai#for-product-managers" class="hash-link" aria-label="Direct link to For Product Managers" title="Direct link to For Product Managers" translate="no">‚Äã</a></h3>
<ul>
<li class="">Features with guarantees</li>
<li class="">Stable UX</li>
<li class="">Clear ownership of logic</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-executives">For Executives<a href="https://mcp.com.ai/when-not-to-use-ai#for-executives" class="hash-link" aria-label="Direct link to For Executives" title="Direct link to For Executives" translate="no">‚Äã</a></h3>
<ul>
<li class="">Controlled AI spend</li>
<li class="">Reduced operational risk</li>
<li class="">Compliance-friendly AI adoption</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ai--determinism-is-collaboration-not-replacement">AI + Determinism Is Collaboration, Not Replacement<a href="https://mcp.com.ai/when-not-to-use-ai#ai--determinism-is-collaboration-not-replacement" class="hash-link" aria-label="Direct link to AI + Determinism Is Collaboration, Not Replacement" title="Direct link to AI + Determinism Is Collaboration, Not Replacement" translate="no">‚Äã</a></h2>
<p>This is the part most people miss.</p>
<p>We are not replacing humans with AI.
And we are not replacing systems with AI either.</p>
<p>We are <strong>connecting intent to execution</strong> more intelligently.</p>
<p>Think of it this way:</p>
<ul>
<li class="">AI is the <strong>copilot</strong></li>
<li class="">Deterministic workflows are the <strong>autopilot</strong></li>
<li class="">Humans still decide where the plane goes</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-real-future-of-ai-in-platforms">The Real Future of AI in Platforms<a href="https://mcp.com.ai/when-not-to-use-ai#the-real-future-of-ai-in-platforms" class="hash-link" aria-label="Direct link to The Real Future of AI in Platforms" title="Direct link to The Real Future of AI in Platforms" translate="no">‚Äã</a></h2>
<p>The future is not:</p>
<blockquote>
<p>‚ÄúAI does everything.‚Äù</p>
</blockquote>
<p>The future is:</p>
<blockquote>
<p>‚ÄúAI knows when <em>not</em> to.‚Äù</p>
</blockquote>
<p>If a task:</p>
<ul>
<li class="">Must be consistent</li>
<li class="">Must be repeatable</li>
<li class="">Must be auditable</li>
</ul>
<p>Then AI should <strong>trigger it</strong>, not <strong>perform it</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-thought">Final Thought<a href="https://mcp.com.ai/when-not-to-use-ai#final-thought" class="hash-link" aria-label="Direct link to Final Thought" title="Direct link to Final Thought" translate="no">‚Äã</a></h2>
<p>That meme about AI answering ‚Äúhi‚Äù is funny because it's absurd.
But the same absurdity exists in production systems, just quieter and more expensive.</p>
<p><strong>Expose outcomes, not chaos.</strong>
<strong>Let AI reason. Let systems execute.</strong></p>
<p>If your AI needs to reason about execution, your system design is already leaking.
AI should reason about intent, not rebuild your workflows one token at a time.</p>
<p>Thanks for reading. Be <em>HAPI</em> and Go Rebels! ‚úäüèº</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="faq---common-questions">FAQ - Common Questions<a href="https://mcp.com.ai/when-not-to-use-ai#faq---common-questions" class="hash-link" aria-label="Direct link to FAQ - Common Questions" title="Direct link to FAQ - Common Questions" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="when-should-ai-not-be-used">When Should AI Not Be Used?<a href="https://mcp.com.ai/when-not-to-use-ai#when-should-ai-not-be-used" class="hash-link" aria-label="Direct link to When Should AI Not Be Used?" title="Direct link to When Should AI Not Be Used?" translate="no">‚Äã</a></h3>
<p>AI is powerful, but power without boundaries becomes a liability.</p>
<p>AI should <em>not</em> be used when a task:</p>
<ul>
<li class="">Must produce the <strong>same result every time</strong></li>
<li class="">Is executed <strong>frequently at scale</strong></li>
<li class="">Has <strong>clear, predefined logic</strong></li>
<li class="">Requires <strong>auditability or compliance</strong></li>
<li class="">Impacts <strong>production stability</strong></li>
</ul>
<p>These are not edge cases.
These are <strong>core platform operations</strong>.</p>
<p>Health checks, sanity runs, compliance validations, and operational diagnostics do not benefit from probabilistic reasoning. They benefit from <strong>guarantees</strong>.</p>
<p>Using AI in these scenarios introduces:</p>
<ul>
<li class="">Non-deterministic behavior</li>
<li class="">Higher operational cost</li>
<li class="">Hard-to-reproduce failures</li>
<li class="">Loss of trust in the system</li>
</ul>
<p>AI excels at <em>deciding what to do</em>.
It struggles when asked to <em>repeat the same thing perfectly</em>.</p>
<p>That's the line most teams cross without noticing.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-deterministic-workflows-matter-in-production-systems">Why Deterministic Workflows Matter in Production Systems?<a href="https://mcp.com.ai/when-not-to-use-ai#why-deterministic-workflows-matter-in-production-systems" class="hash-link" aria-label="Direct link to Why Deterministic Workflows Matter in Production Systems?" title="Direct link to Why Deterministic Workflows Matter in Production Systems?" translate="no">‚Äã</a></h3>
<p>Deterministic workflows are not a legacy concept.
They are a <strong>production necessity</strong>.</p>
<p>A deterministic workflow guarantees:</p>
<ul>
<li class="">The same inputs lead to the same outputs</li>
<li class="">Execution order is fixed and explainable</li>
<li class="">Failures are reproducible</li>
<li class="">Behavior can be tested, versioned, and audited</li>
</ul>
<p>This is why deterministic workflows matter, especially in platforms, DevOps, and enterprise systems.</p>
<p>When AI replaces deterministic execution, you lose:</p>
<ul>
<li class="">Predictability</li>
<li class="">Cost control</li>
<li class="">Debuggability</li>
<li class="">Confidence in outcomes</li>
</ul>
<p>In production, consistency is not optional.
It is the foundation of reliability.</p>
<p>AI-generated execution paths might <em>work today</em> and <em>fail tomorrow</em>, without any code changes. That's not innovation. That's operational risk disguised as intelligence.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-to-combine-ai-and-deterministic-systems-the-right-way">How to Combine AI and Deterministic Systems (The Right Way)?<a href="https://mcp.com.ai/when-not-to-use-ai#how-to-combine-ai-and-deterministic-systems-the-right-way" class="hash-link" aria-label="Direct link to How to Combine AI and Deterministic Systems (The Right Way)?" title="Direct link to How to Combine AI and Deterministic Systems (The Right Way)?" translate="no">‚Äã</a></h3>
<p>The most effective systems today are not ‚ÄúAI-first‚Äù or ‚ÄúAI-everywhere.‚Äù</p>
<p>They are <strong>hybrid by design</strong>.</p>
<p>Here's the winning pattern:</p>
<ul>
<li class=""><strong>AI handles intent and ambiguity</strong></li>
<li class=""><strong>Deterministic systems handle execution</strong></li>
</ul>
<p>AI interprets <em>what the user wants</em>.
Deterministic workflows define <em>how it happens</em>.</p>
<p>This separation creates leverage:</p>
<ul>
<li class="">AI remains flexible and expressive</li>
<li class="">Execution remains predictable and cost-efficient</li>
</ul>
<p>Instead of exposing dozens of low-level tools to an LLM, you expose <strong>one deterministic outcome</strong>.</p>
<p>The AI triggers it.
The system guarantees it.</p>
<p>This is how you combine AI and deterministic systems without sacrificing reliability, or burning tokens unnecessarily.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-openapi-workflow-orchestration-is-a-game-changer-in-ai-systems">Why OpenAPI Workflow Orchestration Is a Game Changer in AI Systems?<a href="https://mcp.com.ai/when-not-to-use-ai#why-openapi-workflow-orchestration-is-a-game-changer-in-ai-systems" class="hash-link" aria-label="Direct link to Why OpenAPI Workflow Orchestration Is a Game Changer in AI Systems?" title="Direct link to Why OpenAPI Workflow Orchestration Is a Game Changer in AI Systems?" translate="no">‚Äã</a></h3>
<p>Most systems already have what they need.
They just expose it incorrectly.</p>
<p>APIs describe <strong>capabilities</strong>.
Workflows describe <strong>outcomes</strong>.</p>
<p>With <strong>OpenAPI workflow orchestration</strong>, you move from raw operations to structured execution.</p>
<p>Here's how it works in practice:</p>
<ul>
<li class="">OpenAPI defines what your system can do</li>
<li class="">Workflow specifications define <em>how operations are combined</em></li>
<li class="">Orchestrators execute those workflows deterministically</li>
<li class="">AI tools expose workflows, not individual endpoints</li>
</ul>
<p>This approach transforms APIs into <strong>reliable building blocks for AI systems</strong>.</p>
<p>Instead of asking an LLM to guess:</p>
<ul>
<li class="">Which endpoint to call</li>
<li class="">In what order</li>
<li class="">With which retries</li>
</ul>
<p>You give it a single, well-defined tool:</p>
<blockquote>
<p>‚ÄúRun full platform sanity‚Äù</p>
</blockquote>
<p>Same result.
Every time.</p>
<p>That's the difference between <strong>AI-driven chaos</strong> and <strong>OpenAPI workflow orchestration done right</strong>.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-ai-cant-replace-deterministic-execution-in-production-systems">Why AI can't Replace Deterministic Execution in Production Systems?<a href="https://mcp.com.ai/when-not-to-use-ai#why-ai-cant-replace-deterministic-execution-in-production-systems" class="hash-link" aria-label="Direct link to Why AI can't Replace Deterministic Execution in Production Systems?" title="Direct link to Why AI can't Replace Deterministic Execution in Production Systems?" translate="no">‚Äã</a></h3>
<p>AI is a powerful tool for interpreting intent and handling ambiguity. However, it fundamentally lacks the guarantees required for deterministic execution in production systems.</p>
<p>Deterministic execution demands:</p>
<ul>
<li class="">Consistency: The same inputs must always yield the same outputs.</li>
<li class="">Predictability: Execution paths must be clear and explainable.</li>
<li class="">Auditability: Actions must be traceable and verifiable.</li>
<li class="">Reliability: Systems must behave consistently under all conditions.</li>
</ul>
<p>AI models, by their nature, introduce variability. Their outputs can change based on context, training data, and even random seed values. This unpredictability is incompatible with the stringent requirements of production systems.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-does-hapi-mcp-facilitate-deterministic-workflows-for-ai-systems">How Does HAPI MCP Facilitate Deterministic Workflows for AI Systems?<a href="https://mcp.com.ai/when-not-to-use-ai#how-does-hapi-mcp-facilitate-deterministic-workflows-for-ai-systems" class="hash-link" aria-label="Direct link to How Does HAPI MCP Facilitate Deterministic Workflows for AI Systems?" title="Direct link to How Does HAPI MCP Facilitate Deterministic Workflows for AI Systems?" translate="no">‚Äã</a></h3>
<p>HAPI MCP (Model Context Protocol) is not just another AI tool.
It's a <strong>bridge between AI intent and deterministic execution</strong>.</p>
<p>HAPI MCP enables you to:</p>
<ul>
<li class="">Expose deterministic workflows as MCP tools</li>
<li class="">Let AI models discover and invoke these workflows seamlessly</li>
<li class="">Maintain clear separation between intent and execution</li>
<li class="">Reduce token consumption by minimizing AI reasoning about execution details</li>
<li class="">Ensure consistent, repeatable outcomes in production systems</li>
</ul>
<p>By using HAPI MCP, you empower AI systems to leverage the reliability of deterministic workflows without losing the flexibility of AI-driven intent.</p>
<hr>
<p>Ready to make your AI systems more reliable and cost-efficient?</p>]]></content:encoded>
            <category>Arazzo</category>
            <category>MCP</category>
            <category>API-First</category>
            <category>REST</category>
            <category>AI Integration</category>
        </item>
        <item>
            <title><![CDATA[Integrate the OpenAI UI SDK for ChatGPT With MCP in 60 Seconds]]></title>
            <link>https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt</link>
            <guid>https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt</guid>
            <pubDate>Mon, 24 Nov 2025 17:48:55 GMT</pubDate>
            <description><![CDATA[Step-by-step guide to turn any OpenAPI 3.0+ spec into a ChatGPT-ready MCP server using HAPI MCP and the OpenAI UI SDK. Fast deployment, validation, and optimization for Generative and Answer Engine search.]]></description>
            <content:encoded><![CDATA[<p>You want your API to be instantly usable inside AI assistants like ChatGPT, and Web UIs. The OpenAI UI SDK plus the Model Context Protocol (MCP) lets you expose your API as structured tools that large language models can call directly.</p>
<p>In this hands-on guide, you deploy a fully functional MCP server from any OpenAPI 3.0 specification and make it usable by ChatGPT and other MCP-aware clients in under a minute using HAPI MCP. You learn to deploy using cloud and on‚Äëpremises workflows.</p>
<hr>
<p>Just two months ago, I wrote about how <a href="https://rebelion.la/chatgpt-meets-custom-mcps" target="_blank" rel="noopener noreferrer" class="">OpenAI announced the custom MCP</a> (Model Context Protocol) interface to allow developers to integrate their APIs directly into ChatGPT, but there was <a href="https://rebelion.la/chatgpt-meets-custom-mcps#heading-the-caveat-search-and-fetch" target="_blank" rel="noopener noreferrer" class="">this caveat</a>: Developers would need to implement two tools, a "search" tool to find relevant information and a "fetch" tool to retrieve that information. Today, with the OpenAI UI SDK, that process is greatly simplified.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-integrate-your-api-with-the-openai-ui-sdk-via-mcp">Why Integrate Your API With the OpenAI UI SDK via MCP?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#why-integrate-your-api-with-the-openai-ui-sdk-via-mcp" class="hash-link" aria-label="Direct link to Why Integrate Your API With the OpenAI UI SDK via MCP?" title="Direct link to Why Integrate Your API With the OpenAI UI SDK via MCP?" translate="no">‚Äã</a></h2>
<ul>
<li class="">You expose real-time, authoritative data to ChatGPT and other MCP-aware clients.</li>
<li class="">You eliminate brittle prompt engineering for retrieval and action execution.</li>
<li class="">You accelerate feature delivery‚Äîturn any supported OpenAPI spec into tool metadata.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="architecture-overview">Architecture Overview<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#architecture-overview" class="hash-link" aria-label="Direct link to Architecture Overview" title="Direct link to Architecture Overview" translate="no">‚Äã</a></h2>
<p>The deployment flow:</p>
<ol>
<li class="">Provide an OpenAPI 3.0+ JSON or YAML spec.</li>
<li class="">HAPI MCP ingests paths, methods, parameters, and schemas.</li>
<li class="">Tools are generated with typed argument definitions.</li>
<li class="">The MCP server exposes a JSON-RPC style interface consumable by the OpenAI UI SDK or other MCP-clients.</li>
<li class="">Clients query available tools, then issue structured calls.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-components">Key Components<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#key-components" class="hash-link" aria-label="Direct link to Key Components" title="Direct link to Key Components" translate="no">‚Äã</a></h3>
<table><thead><tr><th style="text-align:left">Component</th><th style="text-align:left">Role</th></tr></thead><tbody><tr><td style="text-align:left">OpenAPI Spec</td><td style="text-align:left">Source of truth for endpoints, params, schemas</td></tr><tr><td style="text-align:left">HAPI MCP CLI / Cloud</td><td style="text-align:left">Transforms spec ‚Üí MCP tool registry</td></tr><tr><td style="text-align:left">MCP Server</td><td style="text-align:left">Serves tool metadata and handles invocations</td></tr><tr><td style="text-align:left">Client Runtime</td><td style="text-align:left">ChatGPT / custom app calling tools</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">‚Äã</a></h2>
<ul>
<li class="">An OpenAPI 3.0+ spec URL or local file (JSON or YAML).</li>
<li class="">A workstation with terminal access, only if you plan to use the HAPI MCP CLI (on-premises deployment).</li>
<li class="">Basic familiarity with REST API concepts (no MCP experience required).</li>
<li class="">Optional: A converted OAS 2.0 (Swagger) spec if you start from legacy format.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="quick-answer-what-is-the-fastest-way-to-get-an-api-inside-chatgpt">Quick Answer: What Is the Fastest Way to Get an API Inside ChatGPT?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#quick-answer-what-is-the-fastest-way-to-get-an-api-inside-chatgpt" class="hash-link" aria-label="Direct link to Quick Answer: What Is the Fastest Way to Get an API Inside ChatGPT?" title="Direct link to Quick Answer: What Is the Fastest Way to Get an API Inside ChatGPT?" translate="no">‚Äã</a></h2>
<p>Provide an OpenAPI 3.0 spec to HAPI MCP (cloud or CLI), start the MCP server, then <a href="https://developers.openai.com/apps-sdk/deploy/connect-chatgpt" target="_blank" rel="noopener noreferrer" class="">connect ChatGPT</a> custom tools configuration at the generated endpoint.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="cloud-deployment-fastest-path">Cloud Deployment (Fastest Path)<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#cloud-deployment-fastest-path" class="hash-link" aria-label="Direct link to Cloud Deployment (Fastest Path)" title="Direct link to Cloud Deployment (Fastest Path)" translate="no">‚Äã</a></h2>
<ol>
<li class="">Open the run portal: <code>https://run.mcp.com.ai/?oas=&lt;YOUR_OPENAPI_SPEC_URL&gt;&amp;apiServer=&lt;OPTIONAL_BASE_URL&gt;</code></li>
<li class="">Replace <code>&lt;YOUR_OPENAPI_SPEC_URL&gt;</code> with a direct spec URL (must be publicly accessible).</li>
<li class="">(Optional) Replace <code>&lt;OPTIONAL_BASE_URL&gt;</code> with your API server base URL if needed - not all specs include server definitions.</li>
<li class="">Wait for provisioning; you receive an MCP server endpoint URL.</li>
<li class="">Use that URL in the ChatGPT Apps &amp; Connectors settings.</li>
<li class="">Validate tool listing (see Validation section below).</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-url">Example URL<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#example-url" class="hash-link" aria-label="Direct link to Example URL" title="Direct link to Example URL" translate="no">‚Äã</a></h3>
<div class="language-console codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-console codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">https://run.mcp.com.ai/?oas=https://example.com/openapi.json</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="on-premises-deployment-with-hapi-mcp-cli">On-Premises Deployment With HAPI MCP CLI<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#on-premises-deployment-with-hapi-mcp-cli" class="hash-link" aria-label="Direct link to On-Premises Deployment With HAPI MCP CLI" title="Direct link to On-Premises Deployment With HAPI MCP CLI" translate="no">‚Äã</a></h2>
<ol>
<li class="">Install the CLI
<a href="https://github.com/la-rebelion/hapimcp/releases" target="_blank" rel="noopener noreferrer" class="">Download the latest release</a> and install the HAPI MCP CLI executable, depending on your OS.</li>
</ol>
<p>Or install via Bun/npm:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bun install -g @la-rebelion/hapimcp</span><br></span></code></pre></div></div>
<ol start="2">
<li class="">Verify installation:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi --version</span><br></span></code></pre></div></div>
<ol>
<li class="">Start a local MCP server (using a spec alias - located in <code>HAPI_HOME/specs</code>):</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi serve petstore --headless</span><br></span></code></pre></div></div>
<ol>
<li class="">Or specify a direct spec URL:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi serve my-api --openapi="https://example.com/openapi.json" --headless</span><br></span></code></pre></div></div>
<ol>
<li class="">Capture the printed MCP server endpoint (e.g., <code>http://localhost:3000/mcp</code>).</li>
<li class="">Add that URL to ChatGPT Apps &amp; Connectors settings.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="deploy-to-cloud-via-cli">Deploy to Cloud via CLI<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#deploy-to-cloud-via-cli" class="hash-link" aria-label="Direct link to Deploy to Cloud via CLI" title="Direct link to Deploy to Cloud via CLI" translate="no">‚Äã</a></h2>
<ol>
<li class="">Run:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi deploy strava --var HAPI_OPENAPI:"https://docs.mcp.com.ai/apis/openapi/strava.json"</span><br></span></code></pre></div></div>
<ol>
<li class="">Use <code>--dry-run</code> to inspect generated YAML or JSON before committing:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi deploy strava --var HAPI_OPENAPI:"https://docs.mcp.com.ai/apis/openapi/strava.json" --dry-run</span><br></span></code></pre></div></div>
<ol>
<li class="">Store returned endpoint URL for ChatGPT integration.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="converting-swagger-oas-20-to-openapi-30">Converting Swagger (OAS 2.0) to OpenAPI 3.0+<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#converting-swagger-oas-20-to-openapi-30" class="hash-link" aria-label="Direct link to Converting Swagger (OAS 2.0) to OpenAPI 3.0+" title="Direct link to Converting Swagger (OAS 2.0) to OpenAPI 3.0+" translate="no">‚Äã</a></h2>
<p>Don't have an OpenAPI 3.0+ spec? Convert from Swagger (OAS 2.0) using these steps:</p>
<ol>
<li class="">Use the official online converter:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST -H "Content-Type: application/json" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d @swagger.json https://converter.swagger.io/api/convert \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -o openapi3.json</span><br></span></code></pre></div></div>
<ol>
<li class="">Confirm version:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">grep '"openapi"' openapi3.json</span><br></span></code></pre></div></div>
<ol>
<li class="">Fix any <code>schema</code> vs <code>definitions</code> mismatches manually if needed.</li>
<li class="">Retry deployment with the new file.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="validating-your-mcp-server">Validating Your MCP Server<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#validating-your-mcp-server" class="hash-link" aria-label="Direct link to Validating Your MCP Server" title="Direct link to Validating Your MCP Server" translate="no">‚Äã</a></h2>
<ol>
<li class="">List tools:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -s https://your-mcp-endpoint.example/mcp/tools | jq</span><br></span></code></pre></div></div>
<ol>
<li class="">Call a tool (example POST body):</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST https://your-mcp-endpoint.example/mcp/call \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H 'Content-Type: application/json' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tool":"getPetById",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "params":{"petId": 123}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }'</span><br></span></code></pre></div></div>
<ol>
<li class="">Check response latency; target &lt; 1s for best conversational UX.</li>
<li class="">Log errors; ensure input validation messages are concise and actionable.</li>
<li class="">Confirm schema alignment with expected OpenAPI parameter types.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="frequently-asked-questions">Frequently Asked Questions<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#frequently-asked-questions" class="hash-link" aria-label="Direct link to Frequently Asked Questions" title="Direct link to Frequently Asked Questions" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-fast-can-you-expose-an-api-to-chatgpt">How fast can you expose an API to ChatGPT?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#how-fast-can-you-expose-an-api-to-chatgpt" class="hash-link" aria-label="Direct link to How fast can you expose an API to ChatGPT?" title="Direct link to How fast can you expose an API to ChatGPT?" translate="no">‚Äã</a></h3>
<p>You can expose a spec-driven API in under 60 seconds using the cloud portal or a single CLI command.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="do-you-need-to-write-glue-code">Do you need to write glue code?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#do-you-need-to-write-glue-code" class="hash-link" aria-label="Direct link to Do you need to write glue code?" title="Direct link to Do you need to write glue code?" translate="no">‚Äã</a></h3>
<p>You do not need custom tool wrappers; HAPI MCP converts spec operations automatically.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="can-you-use-private-specs">Can you use private specs?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#can-you-use-private-specs" class="hash-link" aria-label="Direct link to Can you use private specs?" title="Direct link to Can you use private specs?" translate="no">‚Äã</a></h3>
<p>Yes. Host the spec behind authenticated access or load from a local file via CLI.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-formats-are-supported">What formats are supported?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#what-formats-are-supported" class="hash-link" aria-label="Direct link to What formats are supported?" title="Direct link to What formats are supported?" translate="no">‚Äã</a></h3>
<p>OpenAPI 3.0+ JSON or YAML. Convert OAS 2.0 (Swagger) before deployment.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="is-this-limited-to-chatgpt">Is this limited to ChatGPT?<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#is-this-limited-to-chatgpt" class="hash-link" aria-label="Direct link to Is this limited to ChatGPT?" title="Direct link to Is this limited to ChatGPT?" translate="no">‚Äã</a></h3>
<p>No. Any MCP-aware client (custom apps, open-source chat UIs) can consume the server.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://mcp.com.ai/openai-ui-sdk-and-mcp-chatgpt#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">‚Äã</a></h2>
<p>You now have a repeatable path to transform any OpenAPI 3.0+ specification into a production-ready MCP server consumable by the OpenAI UI SDK and AI assistants. By following validation, conversion, and optimization steps, you improve tool discoverability. Next, refine schema descriptions and add automated integration tests to ensure durable quality as your API evolves.</p>
<p>Your APIs are now ready to be seamlessly integrated into ChatGPT and other MCP-aware clients, unlocking new possibilities for AI-driven interactions. Stop wasting time writing MCP Server code manually‚Äîleverage HAPI MCP to accelerate your AI integration journey!</p>
<p>Be HAPI and Go Rebels! ‚úäüèΩ</p>]]></content:encoded>
            <category>MCP</category>
            <category>OpenAI</category>
            <category>API-First</category>
            <category>LLM</category>
            <category>Guide</category>
            <category>AI Integration</category>
        </item>
        <item>
            <title><![CDATA[Composable Architectures and the Future of AI Integration: Why MCP Is the Missing Link]]></title>
            <link>https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration</link>
            <guid>https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration</guid>
            <pubDate>Sat, 01 Nov 2025 15:05:34 GMT</pubDate>
            <description><![CDATA[Instead of rebuilding APIs, learn how composable architectures and MCP Gateways help enterprises move from API-First to AI-First.]]></description>
            <content:encoded><![CDATA[<p>For years, <strong>OpenAPI (OAS)</strong> has been the cornerstone of how we describe, document, and integrate APIs. It standardized how systems talk to each other ‚Äî and in many ways, it made the modern internet possible.</p>
<p>So when the <strong>Model Context Protocol (MCP)</strong> appeared, some developers were skeptical.
"Another spec?" they asked. "Why do we need this when we already have OAS?"</p>
<p>That skepticism was fair ‚Äî until people started to realize <strong>what MCP actually unlocks</strong>:
üëâ <strong>Tool discovery for Large Language Models (LLMs)</strong>.</p>
<p>This is the real spark ‚Äî the value proposition that gave MCP its traction. It's not just another API spec; it's the bridge between traditional APIs and the AI agents that can use them.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-re-invent-when-you-can-re-compose">Why Re-Invent When You Can Re-Compose?<a href="https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration#why-re-invent-when-you-can-re-compose" class="hash-link" aria-label="Direct link to Why Re-Invent When You Can Re-Compose?" title="Direct link to Why Re-Invent When You Can Re-Compose?" translate="no">‚Äã</a></h3>
<p>Many enterprises today already have a vast API ecosystem ‚Äî especially in industries like <strong>telecommunications</strong>, <strong>finance</strong>, or <strong>healthcare</strong>.
Hundreds of services, standardized and custom, all tested, audited, and certified.</p>
<p>So when these organizations hear about "MCP servers," it's natural to worry that they'll need to rebuild everything. But here's the truth:</p>
<blockquote>
<p><strong>You don't need to re-implement your APIs as MCP servers. You just need to make them discoverable.</strong></p>
</blockquote>
<p>That's where the <strong>MCP Gateway</strong> comes in.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-role-of-the-mcp-gateway">The Role of the MCP Gateway<a href="https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration#the-role-of-the-mcp-gateway" class="hash-link" aria-label="Direct link to The Role of the MCP Gateway" title="Direct link to The Role of the MCP Gateway" translate="no">‚Äã</a></h3>
<p>Think of an MCP Gateway as a <strong>translator and orchestrator</strong> between your existing APIs and AI-driven agents.</p>
<ul>
<li class="">It receives MCP requests from LLMs.</li>
<li class="">It routes them to your existing APIs.</li>
<li class="">It transforms the responses back into MCP format.</li>
</ul>
<p>No reinvention. No duplicate logic. Just a smarter bridge between systems.</p>
<p>And because it sits at the intersection of APIs and AI, the MCP Gateway can handle the enterprise-grade essentials too ‚Äî
‚úÖ Authentication &amp; authorization
‚úÖ Rate limiting
‚úÖ Logging &amp; observability
‚úÖ Policy enforcement &amp; compliance</p>
<p>It's the perfect layer to keep everything <strong>secure, compliant, and manageable</strong> while opening the door to AI-powered integration.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="composable-architectures-the-future-of-integration">Composable Architectures: The Future of Integration<a href="https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration#composable-architectures-the-future-of-integration" class="hash-link" aria-label="Direct link to Composable Architectures: The Future of Integration" title="Direct link to Composable Architectures: The Future of Integration" translate="no">‚Äã</a></h3>
<p>We've moved from monoliths to microservices, and now from <strong>API-First to AI-First</strong>.
The next evolution is <strong>composability</strong> ‚Äî the ability to assemble, re-use, and extend existing systems dynamically.</p>
<p>MCP Gateways embody this principle.
They empower teams to:</p>
<ul>
<li class="">Reuse what already works.</li>
<li class="">Expose APIs as AI-ready tools.</li>
<li class="">Integrate with LLMs and agents seamlessly.</li>
<li class="">Accelerate innovation instead of rewriting history.</li>
</ul>
<p>Enterprises can finally focus on <strong>intent matching</strong> ‚Äî connecting what an AI agent <em>wants to do</em> with the right existing service, without reinventing the wheel.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-mindset-shift">The Mindset Shift<a href="https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration#the-mindset-shift" class="hash-link" aria-label="Direct link to The Mindset Shift" title="Direct link to The Mindset Shift" translate="no">‚Äã</a></h3>
<p>Adopting MCP isn't just a technical change ‚Äî it's a cultural one.
It's about moving from building APIs <em>for humans to consume</em> to building systems that <em>AI can understand and compose</em>.</p>
<p>It's about trust ‚Äî trusting that your existing architecture already has value, and that the future doesn't require you to start over, but to <strong>connect smarter</strong>.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-thought">Final Thought<a href="https://mcp.com.ai/composable-architectures-and-the-future-of-ai-integration#final-thought" class="hash-link" aria-label="Direct link to Final Thought" title="Direct link to Final Thought" translate="no">‚Äã</a></h3>
<p><strong>Composable, AI-ready architectures are the future of integration.</strong>
MCP Gateways are the missing link ‚Äî enabling enterprises to evolve from <em>API-First</em> to <em>AI-First</em> without disruption.</p>
<p>Because innovation shouldn't mean rebuilding everything.
It should mean <strong>unlocking what you already have</strong> ‚Äî and letting intelligence flow through it.</p>]]></content:encoded>
            <category>MCP</category>
            <category>AI Integration</category>
            <category>LLM</category>
            <category>API</category>
            <category>MCP Gateway</category>
        </item>
        <item>
            <title><![CDATA[Using OpenAI Response API for MCP Integration]]></title>
            <link>https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration</link>
            <guid>https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration</guid>
            <pubDate>Sat, 01 Nov 2025 15:05:34 GMT</pubDate>
            <description><![CDATA[A step-by-step guide to integrating OpenAI's Response API with Model Context Protocol (MCP) using HAPI Server.]]></description>
            <content:encoded><![CDATA[<p>This guide demonstrates how to use the <strong>OpenAI Response API</strong> to integrate with the <strong>Model Context Protocol (MCP)</strong> for seamless, AI-driven API interactions.
You will learn how to generate a REST API specification with Postman's AI Agent, deploy it as an <strong>MCP server using HAPI Server</strong>, and connect it through OpenAI's <strong>Response API</strong> for testing.</p>
<p>The goal of this demo is to show how OpenAI's new <strong>Tools and Connectors for MCP</strong> feature simplifies integration between large language models and your APIs, making it possible to interact with services such as a "Taco Ordering System" directly from an LLM client like ChatGPT or a Bun-based application.</p>
<p>By the end of this guide, you will have a working MCP server derived from a Swagger specification, exposed via ngrok, and connected to the OpenAI Response API for end-to-end interaction testing.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">‚Äã</a></h2>
<p>Before you begin:</p>
<ul>
<li class="">
<p>Install the following tools:</p>
<ul>
<li class=""><a href="https://bun.sh/" target="_blank" rel="noopener noreferrer" class="">Bun</a> ‚Äì A fast JavaScript runtime for modern apps.<!-- -->
<ul>
<li class="">Alternatively, you can use Node.js if preferred.</li>
</ul>
</li>
<li class=""><a href="https://ngrok.com/" target="_blank" rel="noopener noreferrer" class="">ngrok</a> ‚Äì To expose your local server to the internet.</li>
<li class=""><a href="https://hapi.mcp.com.ai/" target="_blank" rel="noopener noreferrer" class="">HAPI Server</a> ‚Äì To host your MCP server.</li>
<li class=""><a href="https://www.npmjs.com/package/openai" target="_blank" rel="noopener noreferrer" class="">OpenAI SDK</a> ‚Äì For client testing.</li>
<li class="">Obtain or install <strong>Postman Desktop Agent</strong> to generate APIs using AI.<!-- -->
<ul>
<li class="">Alternatively, you can ask <strong>ChatGPT</strong> to generate a Swagger specification (v3).</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The example below uses a local environment and ngrok for simplicity, but you can deploy your server on any cloud instance or containerized environment.</p></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-generate-an-api-using-postman-agent">Step 1: Generate an API Using Postman Agent<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#step-1-generate-an-api-using-postman-agent" class="hash-link" aria-label="Direct link to Step 1: Generate an API Using Postman Agent" title="Direct link to Step 1: Generate an API Using Postman Agent" translate="no">‚Äã</a></h2>
<p>You can use Postman's AI Agent to quickly generate an API for any use case.
In this example, you will create a simple Taco Ordering System.</p>
<ol>
<li class="">
<p>Open Postman's AI Agent and prompt:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Generate an API for a Taco ordering system with endpoints to view tacos and place an order.</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>The agent returns a Swagger (OpenAPI) specification for your taco API.</p>
</li>
<li class="">
<p>Review the generated specification to confirm it includes paths for:</p>
<ul>
<li class=""><code>GET /tacos</code></li>
<li class=""><code>POST /order</code></li>
</ul>
</li>
</ol>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Save the file in your <code>HAPI_HOME/specs</code> directory as <code>tacos.yaml</code> for use in the next step. (JSON format is also acceptable.)</p></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-start-an-mcp-server-using-hapi-server">Step 2: Start an MCP Server Using HAPI Server<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#step-2-start-an-mcp-server-using-hapi-server" class="hash-link" aria-label="Direct link to Step 2: Start an MCP Server Using HAPI Server" title="Direct link to Step 2: Start an MCP Server Using HAPI Server" translate="no">‚Äã</a></h2>
<p>Use the <a href="https://hapi.mcp.com.ai/" target="_blank" rel="noopener noreferrer" class="">HAPI Server</a> to host your Swagger API as an MCP server. This allows LLM-based clients such as ChatGPT to call your API directly.</p>
<ol>
<li class="">
<p>Connect to your instance and run the following command to start the MCP server:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bunx @la-rebelion/hapimcp serve tacos --headless --chatgpt</span><br></span></code></pre></div></div>
<p>Alternatively, you can use the native CLI (download from <a href="https://github.com/la-rebelion/hapimcp/releases" target="_blank" rel="noopener noreferrer" class="">GitHub releases</a>) and run:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hapi serve tacos --headless --chatgpt</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>Once running, expose the local server to the internet using ngrok:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ngrok http 8000</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>Copy the public URL generated by ngrok (e.g., <code>https://abcd1234.ngrok.io</code>).</p>
</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-3-connect-chatgpt-or-another-client-to-the-mcp-server">Step 3: Connect ChatGPT or Another Client to the MCP Server<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#step-3-connect-chatgpt-or-another-client-to-the-mcp-server" class="hash-link" aria-label="Direct link to Step 3: Connect ChatGPT or Another Client to the MCP Server" title="Direct link to Step 3: Connect ChatGPT or Another Client to the MCP Server" translate="no">‚Äã</a></h2>
<ol>
<li class="">Open ChatGPT's settings and add a new connector with the ngrok URL you copied earlier.</li>
<li class="">Enable the connector.
If the feature is not visible, note that <strong>MCP connectors</strong> in ChatGPT may still be in <strong>beta</strong>.</li>
<li class="">Alternatively, you can connect directly from an MCP-compatible client using the OpenAI SDK.</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-4-test-the-mcp-server-with-openai-sdk">Step 4: Test the MCP Server With OpenAI SDK<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#step-4-test-the-mcp-server-with-openai-sdk" class="hash-link" aria-label="Direct link to Step 4: Test the MCP Server With OpenAI SDK" title="Direct link to Step 4: Test the MCP Server With OpenAI SDK" translate="no">‚Äã</a></h2>
<p>You can test the endpoint by sending a prompt that interacts with your Taco API.</p>
<ol>
<li class="">
<p>Initialize a new Bun project:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir taco-client &amp;&amp; cd taco-client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bun init</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>Install dependencies:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bun install openai</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>Create an <code>index.ts</code> file and configure your endpoint:</p>
<div class="language-typescript codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-typescript codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> OpenAI </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"openai"</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> </span><span class="token class-name">OpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  apiKey</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> process</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">env</span><span class="token punctuation" style="color:#393A34">.</span><span class="token constant" style="color:#36acaa">OPENAI_API_KEY</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  baseURL</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"https://abcd1234.ngrok.io/v1"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">await</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"gpt-4.1"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  messages</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> role</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"user"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> content</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"What tacos do you have in the menu?"</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin">console</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">message</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
</li>
<li class="">
<p>Run the client:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bun run index.ts</span><br></span></code></pre></div></div>
</li>
</ol>
<p>You should see a response such as:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">We have "carne asada" and "al pastor" tacos available.</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-5-place-an-order-through-the-api">Step 5: Place an Order Through the API<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#step-5-place-an-order-through-the-api" class="hash-link" aria-label="Direct link to Step 5: Place an Order Through the API" title="Direct link to Step 5: Place an Order Through the API" translate="no">‚Äã</a></h2>
<p>Now that your MCP server is connected, you can test the ordering functionality.</p>
<p>Run:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bun run index.ts</span><br></span></code></pre></div></div>
<p>With the following request:</p>
<div class="language-typescript codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-typescript codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">messages</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> role</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"user"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> content</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Place an order for 2 tacos al pastor and 1 carne asada."</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div>
<p>The client confirms your order:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Order placed successfully!  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">You ordered 2 tacos al pastor and 1 carne asada.</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="demo-video">Demo Video<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#demo-video" class="hash-link" aria-label="Direct link to Demo Video" title="Direct link to Demo Video" translate="no">‚Äã</a></h2>
<!--$?--><template id="B:0"></template><!--/$-->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://mcp.com.ai/use-openai-api-for-smooth-mcp-integration#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">‚Äã</a></h2>
<p>You successfully:</p>
<ul>
<li class="">Generated a Swagger API with Postman's AI Agent.</li>
<li class="">Deployed it as an MCP server using HAPI Server.</li>
<li class="">Exposed the service securely with ngrok.</li>
<li class="">Connected and interacted with it using ChatGPT and Bun.</li>
</ul>
<p>This setup allows you to prototype <strong>API-first AI integrations</strong> quickly. You can expand this demo to connect more endpoints or integrate it into a cluster for scalability.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>To continue exploring, deploy your HAPI MCP server on <strong>cloud instances</strong> or integrate it into your existing CI/CD pipeline for real-world workloads.</p></div></div>
<p>Be HAPI, and go Rebels! ‚úäüèΩ</p>]]></content:encoded>
            <category>MCP</category>
            <category>OpenAI</category>
            <category>API-First</category>
            <category>LLM</category>
            <category>Guide</category>
            <category>AI Integration</category>
        </item>
        <item>
            <title><![CDATA[OpenAI SDK Meets MCP (Model Context Protocol)]]></title>
            <link>https://mcp.com.ai/openai-meets-mcp</link>
            <guid>https://mcp.com.ai/openai-meets-mcp</guid>
            <pubDate>Thu, 09 Oct 2025 12:02:09 GMT</pubDate>
            <description><![CDATA[A comprehensive guide on how to integrate OpenAI's SDK with MCP (Model Context Protocol) to enhance AI model interactions through dynamic tool calling.]]></description>
            <content:encoded><![CDATA[<p>An evolution of tool calling with MCP, thanks to OpenAI's latest SDK updates.</p>
<p>Step-by-step, I'll guide you through setting up an MCP server, integrating it with the OpenAI SDK, and running a complete example that showcases <strong>dynamic tool calling</strong>. By the end of this post, you'll be equipped to leverage MCP in your own OpenAI-powered applications.</p>
<p>End-to-End Example, Setting Up an MCP Server, Integrating with OpenAI LLM, and Running some tests to see it in action.</p>
<p>MCP, or Model Context Protocol, is a framework that enhances how AI models interact with their operational context. By integrating MCP, you ensure your AI models are not only aware of the data they process but also the environment in which they operate. This leads to more accurate and contextually relevant outputs.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-integrate-openai-with-mcp">Why Integrate OpenAI with MCP?<a href="https://mcp.com.ai/openai-meets-mcp#why-integrate-openai-with-mcp" class="hash-link" aria-label="Direct link to Why Integrate OpenAI with MCP?" title="Direct link to Why Integrate OpenAI with MCP?" translate="no">‚Äã</a></h2>
<p>OpenAI's powerful language models take tool calling to the next level when you leverage MCP. This integration enables dynamic interactions, letting you build applications that adapt to various scenarios and user needs. I explained <a class="" href="https://mcp.com.ai/oas-v4-is-out#how-does-mcp-work-for-mere-mortals">how MCP tool calling works</a> in a previous post. Now, I'll show you how OpenAI's implementation impressed me.</p>
<p>With a simple, clever setup, you create applications that understand user queries in natural language and fetch relevant tools from MCP servers. This is extremely powerful‚Äîit enables seamless, efficient interactions with AI models, making them more useful in real-world applications. Imagine an automated customer-support bot using MCP: it instantly retrieves necessary tools from MCP servers to resolve complex queries, such as billing discrepancies or technical troubleshooting, on the first call. This opens new possibilities for building intelligent applications that respond to user needs with greater precision and context-awareness.</p>
<p>Anthropic's Claude Desktop app (MCP Client) was groundbreaking almost a year ago. Early adopters were impressed, and now OpenAI seamlessly integrates these capabilities into their SDKs. As the Spanish saying goes, "Nadie sabe para quien trabaja" (Nobody knows for whom they work), but MCP is clearly shaping the future of AI applications. OpenAI is making significant strides by implementing Anthropic's legacy directly in the LLM.</p>
<p>You can build smarter, more adaptive applications by letting AI models fetch and use tools from MCP servers, reducing manual integration and boosting context-awareness.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The OpenAI's MCP integration is currently in beta, so expect some rough edges. However, the potential is immense, and I'm excited to see how this evolves.</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="three-approaches-to-tool-calling">Three Approaches to Tool Calling<a href="https://mcp.com.ai/openai-meets-mcp#three-approaches-to-tool-calling" class="hash-link" aria-label="Direct link to Three Approaches to Tool Calling" title="Direct link to Three Approaches to Tool Calling" translate="no">‚Äã</a></h2>
<p>You have three main ways to implement tool calling:</p>
<table><thead><tr><th>Approach</th><th>Description</th><th>Key Strength</th></tr></thead><tbody><tr><td><strong>MCP Clients</strong></td><td>Intermediary applications bridging models and external tool servers.</td><td>Dynamic retrieval and adaptation</td></tr><tr><td><strong>Direct Tool Calling</strong></td><td>LLMs with built-in function calling via structured JSON.</td><td>Precise programmatic control</td></tr><tr><td><strong>Native MCP Integration</strong></td><td>OpenAI‚Äôs latest approach combining both worlds.</td><td>Automatic discovery and zero-config operation</td></tr></tbody></table>
<p>When choosing, remember: Direct Tool Calling is easy to set up but requires manual tool management. MCP Clients offer dynamic adaptability, fetching tools as needed and calling them for the user. LLMs with Native MCP Support provide the most seamless experience, automatically integrating and using tools from MCP Servers, though you may need some upfront knowledge about OpenAI's system and SDKs.</p>
<p><strong>Summary:</strong><br>
<!-- -->Select the approach that best fits your workflow‚Äîmanual, dynamic, or fully automated tool integration.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The OpenAI's MCP integration may not be call by the model directly; my guess is that it uses an internal MCP Client to fetch and call the tools, similar to how <a href="https://docs.mcp.com.ai/components/qbot" target="_blank" rel="noopener noreferrer" class="">QBot</a> works.</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="end-to-end-example">End-to-End Example<a href="https://mcp.com.ai/openai-meets-mcp#end-to-end-example" class="hash-link" aria-label="Direct link to End-to-End Example" title="Direct link to End-to-End Example" translate="no">‚Äã</a></h2>
<p>Quick check:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST "https://api.openai.com/v1/responses" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> -H "Authorization: Bearer $OPENAI_API_KEY" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> -H "Content-Type: application/json" \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "model": "gpt-4.1",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "tools": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "type": "mcp",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "server_label": "tacosmcp",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "server_url": "https://tacostore.run.mcp.com.ai",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "require_approval": "never"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> "input": "What tacos do you have in the menu?"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> }'</span><br></span></code></pre></div></div>
<p>Let's walk through the process: set up an MCP server, integrate the OpenAI SDK, write the code, run it, and see the results. These steps help you use MCP to enhance your applications.</p>
<p><strong>Summary:</strong><br>
<!-- -->Follow these steps to quickly connect OpenAI models to MCP and unlock dynamic tool calling.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-set-up-an-mcp-server">1. Set Up an MCP Server<a href="https://mcp.com.ai/openai-meets-mcp#1-set-up-an-mcp-server" class="hash-link" aria-label="Direct link to 1. Set Up an MCP Server" title="Direct link to 1. Set Up an MCP Server" translate="no">‚Äã</a></h3>
<p>First, set up an MCP server hosting the tools you want to use. You can run your own MCP server or use an existing one. For this example, use the HAPI MCP Server‚Äîa simple way to get started. Find the <a href="https://docs.mcp.com.ai/components/hapi-server/" target="_blank" rel="noopener noreferrer" class="">HAPI MCP Server docs here</a>.</p>
<p>Open a terminal, ensure Bun is installed, and run:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Start a HAPI MCP Server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bun dev serve tacos --headless</span><br></span></code></pre></div></div>
<p>This starts a local MCP server hosting a tacos online store at <code>http://localhost:3000</code>. I asked <a href="https://www.postman.com/product/ai-agent-builder/" target="_blank" rel="noopener noreferrer" class="">Postman Agent Builder</a> to create a simple tacos store API, which I used for the MCP server.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-create-an-openai-account">2. Create an OpenAI Account<a href="https://mcp.com.ai/openai-meets-mcp#2-create-an-openai-account" class="hash-link" aria-label="Direct link to 2. Create an OpenAI Account" title="Direct link to 2. Create an OpenAI Account" translate="no">‚Äã</a></h3>
<p>If you don't have one, sign up for an OpenAI account and get your API key at the <a href="https://platform.openai.com/" target="_blank" rel="noopener noreferrer" class="">OpenAI platform</a>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-install-the-openai-sdk">3. Install the OpenAI SDK<a href="https://mcp.com.ai/openai-meets-mcp#3-install-the-openai-sdk" class="hash-link" aria-label="Direct link to 3. Install the OpenAI SDK" title="Direct link to 3. Install the OpenAI SDK" translate="no">‚Äã</a></h3>
<p>Use the OpenAI SDK in your preferred language. For this example, use JavaScript and TypeScript with Bun. In another terminal, run:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Initialize a new Bun project</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bun init -y -m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install the OpenAI SDK</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bun add openai</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-write-the-code">4. Write the Code<a href="https://mcp.com.ai/openai-meets-mcp#4-write-the-code" class="hash-link" aria-label="Direct link to 4. Write the Code" title="Direct link to 4. Write the Code" translate="no">‚Äã</a></h3>
<p>Create a new file, for example, <code>index.js</code>, and add:</p>
<div class="language-javascript codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-javascript codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword module" style="color:#00009f">import</span><span class="token plain"> </span><span class="token imports maybe-class-name">OpenAI</span><span class="token plain"> </span><span class="token keyword module" style="color:#00009f">from</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"openai"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> </span><span class="token class-name">OpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token literal-property property" style="color:#36acaa">apiKey</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> process</span><span class="token punctuation" style="color:#393A34">.</span><span class="token property-access">env</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">'OPENAI_API_KEY'</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic">// This is the default and can be omitted</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> resp </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword control-flow" style="color:#00009f">await</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token property-access">responses</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token literal-property property" style="color:#36acaa">model</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"gpt-5"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token literal-property property" style="color:#36acaa">tools</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token literal-property property" style="color:#36acaa">type</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"mcp"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token literal-property property" style="color:#36acaa">server_label</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"tacosmcp"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token literal-property property" style="color:#36acaa">server_description</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"The Tacos MCP Client"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token literal-property property" style="color:#36acaa">server_url</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"https://tacostore.run.mcp.com.ai"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token literal-property property" style="color:#36acaa">require_approval</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"never"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token literal-property property" style="color:#36acaa">input</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"What tacos do you have in the menu?"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token console class-name">console</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">resp</span><span class="token punctuation" style="color:#393A34">.</span><span class="token property-access">output_text</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-run-the-code">5. Run the Code<a href="https://mcp.com.ai/openai-meets-mcp#5-run-the-code" class="hash-link" aria-label="Direct link to 5. Run the Code" title="Direct link to 5. Run the Code" translate="no">‚Äã</a></h3>
<p>Set your OpenAI API key in the <code>OPENAI_API_KEY</code> environment variable, then run:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bun run index.js</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-see-the-magic">6. See the Magic<a href="https://mcp.com.ai/openai-meets-mcp#6-see-the-magic" class="hash-link" aria-label="Direct link to 6. See the Magic" title="Direct link to 6. See the Magic" translate="no">‚Äã</a></h3>
<p>The model fetches tools from the MCP server and uses them to answer your query. You should see a response listing the tacos available on the menu. To reinforce your learning, validate the returned taco list against the API response. This simple verification ensures tool execution works correctly and builds confidence in using MCP.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="7-explore-further">7. Explore Further<a href="https://mcp.com.ai/openai-meets-mcp#7-explore-further" class="hash-link" aria-label="Direct link to 7. Explore Further" title="Direct link to 7. Explore Further" translate="no">‚Äã</a></h3>
<p>Modify the input query to ask different questions or explore other tools on the MCP server. The possibilities are endless!</p>
<p><strong>Summary:</strong><br>
<!-- -->You can set up, connect, and validate MCP-powered tool calling in minutes, then experiment to discover more capabilities.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="demo-video">Demo Video<a href="https://mcp.com.ai/openai-meets-mcp#demo-video" class="hash-link" aria-label="Direct link to Demo Video" title="Direct link to Demo Video" translate="no">‚Äã</a></h2>
<!--$?--><template id="B:0"></template><!--/$-->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://mcp.com.ai/openai-meets-mcp#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">‚Äã</a></h2>
<p>Integrating OpenAI with MCP unlocks a world of possibilities for building intelligent applications that adapt to various scenarios and user needs. By leveraging MCP, you create dynamic, context-aware interactions with AI models, leading to more accurate and relevant outputs.</p>
<p><strong>Summary:</strong><br>
<!-- -->Use MCP to make your AI applications smarter, more flexible, and better suited to real-world challenges.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="references">References<a href="https://mcp.com.ai/openai-meets-mcp#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">‚Äã</a></h2>
<ul>
<li class=""><a href="https://platform.openai.com/docs/" target="_blank" rel="noopener noreferrer" class="">OpenAI API Documentation</a></li>
<li class=""><a href="https://platform.openai.com/docs/guides/tools-connectors-mcp?lang=javascript" target="_blank" rel="noopener noreferrer" class="">Connectors and MCP servers (Beta)</a></li>
<li class=""><a href="https://www.npmjs.com/package/openai" target="_blank" rel="noopener noreferrer" class="">OpenAI NPM Package</a></li>
<li class=""><a href="https://modelcontextprotocol.io/" target="_blank" rel="noopener noreferrer" class="">Model Context Protocol (MCP) Overview</a></li>
</ul>]]></content:encoded>
            <category>MCP</category>
            <category>OpenAI</category>
            <category>Tool Calling</category>
            <category>OAS</category>
            <category>Guide</category>
        </item>
        <item>
            <title><![CDATA[MCP Threats and Misleadings - Prompt Injection]]></title>
            <link>https://mcp.com.ai/mcp-threats-prompt-injection</link>
            <guid>https://mcp.com.ai/mcp-threats-prompt-injection</guid>
            <pubDate>Wed, 08 Oct 2025 11:36:31 GMT</pubDate>
            <description><![CDATA[An overview of threats and misleadings related to prompt injection in the context of MCP (Model Context Protocol).]]></description>
            <content:encoded><![CDATA[<p>Prompt injection is a critical security risk for any system using large language models (LLMs), including those built with Model Context Protocol (MCP). You must understand how prompt injection works, why MCP cannot prevent it, and what steps you should take to protect your users and applications (MCP Clients).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="https://mcp.com.ai/mcp-threats-prompt-injection#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">‚Äã</a></h2>
<p>MCP enables users and clients to discover and pull prompts from MCP Servers. This flexibility means you, as a client developer, are responsible for validating and sanitizing all user inputs before they reach the LLM. MCP Clients act as intermediaries between MCP Servers, end users, and LLMs. If you do not implement proper validation, malicious prompts can reach the LLM and cause harmful or unintended outputs.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Prompt injection is recognized as a top risk by OpenAI (<a href="https://platform.openai.com/docs/guides/prompt-injection" target="_blank" rel="noopener noreferrer" class="">OpenAI Prompt Injection Guide</a>), Anthropic (<a href="https://www.anthropic.com/index/prompt-injection" target="_blank" rel="noopener noreferrer" class="">Anthropic Prompt Injection FAQ</a>), and OWASP (<a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank" rel="noopener noreferrer" class="">OWASP AI Security Top 10</a>).</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-prompt-injection-works-in-mcp">How Prompt Injection Works in MCP<a href="https://mcp.com.ai/mcp-threats-prompt-injection#how-prompt-injection-works-in-mcp" class="hash-link" aria-label="Direct link to How Prompt Injection Works in MCP" title="Direct link to How Prompt Injection Works in MCP" translate="no">‚Äã</a></h2>
<!-- -->
<p><strong>Key Roles:</strong></p>
<ul>
<li class=""><strong>Client Developer:</strong> You build MCP Clients and must implement security and validation.</li>
<li class=""><strong>MCP Client:</strong> Your app acts as an intermediary, handling prompt delivery and user input forwarding.</li>
<li class=""><strong>End User:</strong> Users interact with LLMs via MCP Clients and may provide inputs that could be exploited.</li>
<li class=""><strong>LLM:</strong> Processes prompts and user inputs, vulnerable to prompt injection if upstream validation is insufficient.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="threats">Threats<a href="https://mcp.com.ai/mcp-threats-prompt-injection#threats" class="hash-link" aria-label="Direct link to Threats" title="Direct link to Threats" translate="no">‚Äã</a></h2>
<p>Prompt injection can lead to several serious risks:</p>
<ul>
<li class=""><strong>Malicious Prompts:</strong> Attackers craft prompts to manipulate the LLM into generating harmful or unintended outputs (<a href="https://platform.openai.com/docs/guides/prompt-injection" target="_blank" rel="noopener noreferrer" class="">OpenAI</a>).</li>
<li class=""><strong>User Input Manipulation:</strong> End users may input data designed to exploit vulnerabilities in the LLM's response generation (<a href="https://www.anthropic.com/index/prompt-injection" target="_blank" rel="noopener noreferrer" class="">Anthropic</a>).</li>
<li class=""><strong>Data Leakage:</strong> Sensitive information may be exposed through manipulated prompts or responses (<a href="https://airmf.nist.gov/" target="_blank" rel="noopener noreferrer" class="">NIST AI RMF</a>).</li>
<li class=""><strong>Reputation Damage:</strong> Misleading outputs generated by LLMs due to prompt injection can harm your application's reputation.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="common-misleadings">Common Misleadings<a href="https://mcp.com.ai/mcp-threats-prompt-injection#common-misleadings" class="hash-link" aria-label="Direct link to Common Misleadings" title="Direct link to Common Misleadings" translate="no">‚Äã</a></h2>
<p>Avoid these misconceptions:</p>
<ul>
<li class=""><strong>False Sense of Security:</strong> MCP does not provide inherent protection against prompt injection. You must implement your own safeguards.</li>
<li class=""><strong>Overreliance on LLMs:</strong> LLMs do not automatically handle all types of inputs safely. Validation is essential.</li>
<li class=""><strong>Misunderstanding Roles:</strong> Security measures must be implemented in the MCP Client, not just the server or LLM.</li>
<li class=""><strong>Assumption of Trustworthiness:</strong> Do not trust all prompts from third-party MCP Servers. Use official or self-hosted servers when possible (<a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank" rel="noopener noreferrer" class="">OWASP</a>).</li>
<li class=""><strong>Neglecting Client Responsibility:</strong> Input validation is your responsibility as the MCP Client developer.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="mitigation-strategies">Mitigation Strategies<a href="https://mcp.com.ai/mcp-threats-prompt-injection#mitigation-strategies" class="hash-link" aria-label="Direct link to Mitigation Strategies" title="Direct link to Mitigation Strategies" translate="no">‚Äã</a></h2>
<p>Follow these best practices to reduce prompt injection risks:</p>
<ol>
<li class=""><strong>Input Validation:</strong> Check all user inputs for malicious content before forwarding to the LLM (<a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank" rel="noopener noreferrer" class="">OWASP</a>).</li>
<li class=""><strong>Sanitization:</strong> Remove or neutralize potentially harmful elements in user inputs.</li>
<li class=""><strong>User Education:</strong> Inform users about prompt injection risks and safe input practices.</li>
<li class=""><strong>Regular Audits:</strong> Audit your MCP Client regularly to identify and fix vulnerabilities.</li>
<li class=""><strong>Monitoring and Logging:</strong> Track interactions and flag suspicious activities for review.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="references">References<a href="https://mcp.com.ai/mcp-threats-prompt-injection#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">‚Äã</a></h2>
<ul>
<li class=""><a href="https://platform.openai.com/docs/guides/prompt-injection" target="_blank" rel="noopener noreferrer" class="">OpenAI: Prompt Injection Guide</a></li>
<li class=""><a href="https://www.anthropic.com/index/prompt-injection" target="_blank" rel="noopener noreferrer" class="">Anthropic: Prompt Injection FAQ</a></li>
<li class=""><a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank" rel="noopener noreferrer" class="">OWASP: Top 10 for LLM Applications</a></li>
<li class=""><a href="https://airmf.nist.gov/" target="_blank" rel="noopener noreferrer" class="">NIST: AI Risk Management Framework</a></li>
</ul>
<p>By understanding and addressing these threats, you can secure your MCP Client against prompt injection vulnerabilities and protect your users and reputation.</p>]]></content:encoded>
            <category>MCP</category>
            <category>Security</category>
        </item>
        <item>
            <title><![CDATA[Swagger/OAS v4 Is out]]></title>
            <link>https://mcp.com.ai/oas-v4-is-out</link>
            <guid>https://mcp.com.ai/oas-v4-is-out</guid>
            <pubDate>Wed, 08 Oct 2025 11:36:31 GMT</pubDate>
            <description><![CDATA[Exploring the potential of OpenAPI Specification (OAS) v4 for AI tool integration and how it can complement Model Context Protocol (MCP).]]></description>
            <content:encoded><![CDATA[<p>üö® "OpenAPI Specification (OAS) v4 is out" - <em>That I wish</em>, this is the kind of headline I would expect to see soon, because OAS can easily be extended to enable RESTful APIs work seamlessly with AI.</p>
<p>By the end of this article, you'll know how to let any LLM call your REST tools automatically using OAS.</p>
<p><strong>What Does It Mean for AI Tool Integration?</strong> Let's explore how OAS v4 could fit into the AI landscape, complementing protocols like Model Context Protocol (MCP).</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>This is a speculative article about what I would like to see in OAS v4, based on my experience with Model Context Protocol (MCP) and AI tool integration. OAS v4 is not yet released, and this article is not endorsed by the OpenAPI Initiative or any other organization.</p></div></div>
<p>Over the past decade, OAS has become the standard for describing RESTful APIs and is widely adopted across various industries. Now, it's time to expand it to cover AI use cases, addressing the evolving needs of developers.</p>
<p>Model Context Protocol (MCP) has recently gained a lot of attention. It's great for local integrations, allows you to adjust the MCP server for backend connections, and with the latest updates, it can now handle remote calls, moving closer to RESTful APIs.</p>
<p>Since the beginning <a href="https://rebelion.la/model-context-protocol-mcp-is-it-a-protocol-or-a-contract#heading-the-lsp-connection-understanding-mcps-roots" target="_blank" rel="noopener noreferrer" class="">MCP was designed for local integrations mainly</a>. The breakthrough of MCP lies in its <strong>ability to let the LLM discover the tools available</strong>. This tool discovery feature marks MCP's unique value proposition, transforming the way we approach AI integrations. From there, everything falls into place similar to RESTful APIs: the client acts as a lightweight orchestration layer, the server handles the backend tasks, and the LLM plays the role of the brain, deciding which tools to use and how to use them.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-does-mcp-work-for-mere-mortals">How does MCP work? For mere mortals<a href="https://mcp.com.ai/oas-v4-is-out#how-does-mcp-work-for-mere-mortals" class="hash-link" aria-label="Direct link to How does MCP work? For mere mortals" title="Direct link to How does MCP work? For mere mortals" translate="no">‚Äã</a></h2>
<p>I have noticed that many people struggle to understand how MCP works, so let me try to explain it in a simple way.</p>
<p>Let's imagine a conversation between the client (you), the LLM (a friend), and the server (weather guy):</p>
<p>Setting the scene: you have a person (the MCP Server) who speaks a language you don't understand, such as French, and you have a friend who speaks both languages (The LLM), French and English. You'd like to know the weather in Paris, so you can ask your friend for help. Your friend asks the person in French, gets the answer, and translates it back to you in English. In this scenario, your friend represents the LLM supporting tool calling natively.</p>
<p>Now, imagine you can write in French but don't speak it fluently. You'd like to know the weather in Paris, but this time you need someone to guide you on what to ask in French. You write the message asking for the weather. Once you receive the answer, you can translate it without help. This scenario reflects the role of an LLM that doesn't support tool calling natively, and the client has to call the tool directly.</p>
<p>Complex, right? Let's see it in a sequence diagram:</p>
<!-- -->
<p>The LLM receives a prompt with a description of the <a href="https://modelcontextprotocol.io/specification/2025-06-18/server/tools#listing-tools" target="_blank" rel="noopener noreferrer" class="">available tools</a>. This tool list can be <a href="https://rebelion.la/you-dont-need-to-implement-mcp-servers-a-contract-first-approach-to-ai-tool-integration?showSharer=true#heading-example-conversion-openapi-mcp" target="_blank" rel="noopener noreferrer" class="">mapped from the OpenAPI spec</a>. The LLM then chooses which tool to use and how to use it. The client simply passes the user input to the LLM, which decides what to do next. Some LLMs, like GPT-4-turbo and Llama2, support tool calling natively. Others, like Claude, do not, so the client calls the tool directly, based on the LLM's instruction.</p>
<p>As you can see, either the LLM supports tool calling natively or not, the flow is similar. The only difference is that in the latter case, the client does the call to the server, and forwards the response to the LLM to get the final result for the end-user - based on the LLM's instruction.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="oas-v4---the-missing-piece">OAS v4 - The missing piece<a href="https://mcp.com.ai/oas-v4-is-out#oas-v4---the-missing-piece" class="hash-link" aria-label="Direct link to OAS v4 - The missing piece" title="Direct link to OAS v4 - The missing piece" translate="no">‚Äã</a></h2>
<p>The missing piece in OAS compared to MCP is that OAS does not have a discovery mechanism for the LLM to know which tools are available. This is where OAS v4 could shine, by adding a way for the LLM to discover the API spec and the available tools.</p>
<p>Imagine if OAS v4 had a way to describe the tools available in a way that the LLM could understand, and then the LLM could decide which tool to use, and how to use it. This would make it possible for any LLM to work seamlessly with RESTful APIs, without the need for a separate protocol like MCP, or even better, MCP could be used as a contract-first approach to AI tool integration, where the OAS v4 spec is the contract that defines the tools available, and the MCP server implements the backend logic. That's precisely what I have been advocating for a while now with my <a href="https://rebelion.la/you-dont-need-to-implement-mcp-servers-a-contract-first-approach-to-ai-tool-integration?showSharer=true" target="_blank" rel="noopener noreferrer" class="">contract-first approach to AI tool integration</a> and the <em>Headless API</em> (HAPI) initiative for MCP.</p>
<p>Now that I have explained how MCP works, and how OAS v4 could be the missing piece, I hope you can see the potential of OAS v4 for AI tool integration. But, don't stop here, next is what I would like to see in OAS v4.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-you-should-expect-in-oas-v4">What You Should Expect in OAS v4<a href="https://mcp.com.ai/oas-v4-is-out#what-you-should-expect-in-oas-v4" class="hash-link" aria-label="Direct link to What You Should Expect in OAS v4" title="Direct link to What You Should Expect in OAS v4" translate="no">‚Äã</a></h2>
<p>OAS v4 is not just an incremental update‚Äîit's an opportunity to rethink how APIs and AI tools work together. Here is what you should expect and advocate for in the next version, based on best practices and the needs of modern AI integrations.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="modular-multi-file-api-specifications">Modular, Multi-File API Specifications<a href="https://mcp.com.ai/oas-v4-is-out#modular-multi-file-api-specifications" class="hash-link" aria-label="Direct link to Modular, Multi-File API Specifications" title="Direct link to Modular, Multi-File API Specifications" translate="no">‚Äã</a></h2>
<p>You need modular specs for real-world APIs. OAS v4 should support multi-file specifications natively, allowing you to break down large APIs into smaller, reusable modules (for example, pets, users, orders). This approach enhances maintainability and collaboration across teams. Instead of a single massive file, you organize your API into logical domains:</p>
<ul>
<li class=""><strong>API Root:</strong> Main file with info, servers, and tags.</li>
<li class=""><strong>Security:</strong> Dedicated files for OAuth2 and other schemes.</li>
<li class=""><strong>Paths by Domain:</strong> Split endpoints into logical groups (e.g. <code>pet.api.yaml</code>, <code>user.api.yaml</code>).</li>
<li class=""><strong>Components/Models:</strong> Reusable schemas separated by domain.</li>
</ul>
<p>This modular structure keeps specs manageable (500‚Äì1000 lines each) and enables code generators and clients to see one unified spec. Tools like <a href="https://redocly.com/docs/cli/file-management#one-large-file-to-many-small-ones" target="_blank" rel="noopener noreferrer" class="">Redocly CLI</a> already offer splitting, but OAS v4 should standardize it. Modular specs also help AI tools (MCP servers) consume only the relevant modules, <strong>improving performance and reducing cognitive load for LLMs</strong> that may have context length limitations and make the LLMs' job easier when deciding which tools to use.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The current <code>$ref</code> approach only allows referencing individual components, not entire files. Modular specs let you load what you need, when you need it.</p></div></div>
<p><strong>Benefits:</strong></p>
<ul>
<li class="">Parallel development and reviews</li>
<li class="">Domain-specific clients (AI agents load only relevant modules)</li>
<li class="">Easier maintenance and updates</li>
<li class="">Improved collaboration</li>
<li class="">Better tooling support</li>
<li class="">Granular security schemes</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="well-known-tools-manifest-for-ai-discovery">Well-Known Tools Manifest for AI Discovery<a href="https://mcp.com.ai/oas-v4-is-out#well-known-tools-manifest-for-ai-discovery" class="hash-link" aria-label="Direct link to Well-Known Tools Manifest for AI Discovery" title="Direct link to Well-Known Tools Manifest for AI Discovery" translate="no">‚Äã</a></h2>
<p>AI clients must discover available tools easily. OAS v4 should adopt a well-known URI convention (such as <code>/.well-known/mcp/tools-manifest.json</code>) so MCP clients and AI agents can auto-discover your API's tools. This follows patterns from <a href="https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig" target="_blank" rel="noopener noreferrer" class="">OpenID Connect Discovery</a> and <a href="https://spec.openapis.org/oas/v3.2.0.html#security-scheme-object" target="_blank" rel="noopener noreferrer" class="">OAuth 2.0 Security Scheme</a>. Give agents a predictable URL to learn your API‚Äîthis small change pays off big in discoverability.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ai-first-annotations-and-metadata">AI-First Annotations and Metadata<a href="https://mcp.com.ai/oas-v4-is-out#ai-first-annotations-and-metadata" class="hash-link" aria-label="Direct link to AI-First Annotations and Metadata" title="Direct link to AI-First Annotations and Metadata" translate="no">‚Äã</a></h2>
<p>OAS v4 should introduce AI-first annotations to help clients and LLMs use APIs effectively. Add metadata extensions (such as <code>x-llm-hint</code>, <code>x-llm-example</code>) to endpoints, parameters, and responses. Use the <a href="https://spec.openapis.org/registry/tag-kind/" target="_blank" rel="noopener noreferrer" class=""><code>kind</code></a> property to categorize tags for AI relevance. For example:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">tags</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> contacts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">summary</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Manage contacts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">description</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Endpoints for creating</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> updating</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> and searching contacts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ai</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> internal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">summary</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Internal admin endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">description</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Endpoints not intended for AI or public use</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> internal</span><br></span></code></pre></div></div>
<p>With this approach, AI agents and MCP servers filter and discover only the endpoints relevant for tool calling, ignoring internal or non-AI endpoints. You can further extend this pattern with custom extensions:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">paths</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">/contacts/search</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">get</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">tags</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">contacts</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">x-llm-hint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Use this endpoint to search for contacts by name or email."</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">x-llm-example</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"Find all contacts named Alice."</span><br></span></code></pre></div></div>
<p>These annotations guide LLMs on how to use specific endpoints, making your API more AI-friendly and discoverable.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="references">References<a href="https://mcp.com.ai/oas-v4-is-out#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">‚Äã</a></h2>
<ul>
<li class=""><a href="https://spec.openapis.org/oas/latest.html" target="_blank" rel="noopener noreferrer" class="">OpenAPI Specification</a></li>
<li class=""><a href="https://redocly.com/docs/cli/file-management#one-large-file-to-many-small-ones" target="_blank" rel="noopener noreferrer" class="">Redocly CLI: File Management</a></li>
<li class=""><a href="https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig" target="_blank" rel="noopener noreferrer" class="">OpenID Connect Discovery</a></li>
<li class=""><a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/" target="_blank" rel="noopener noreferrer" class="">OWASP AI Security Top 10</a></li>
</ul>
<p>By advocating for these features, you help shape OAS v4 into a standard that supports scalable, AI-ready APIs for the next generation of applications.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-conversion-openapi--mcp">Example: Conversion OpenAPI ‚Üí MCP<a href="https://mcp.com.ai/oas-v4-is-out#example-conversion-openapi--mcp" class="hash-link" aria-label="Direct link to Example: Conversion OpenAPI ‚Üí MCP" title="Direct link to Example: Conversion OpenAPI ‚Üí MCP" translate="no">‚Äã</a></h2>
<p>Here is a simple example of how an OpenAPI spec can be converted to an MCP tools manifest.</p>
<p>Using the <a href="https://petstore3.swagger.io/api/v3/openapi.json" target="_blank" rel="noopener noreferrer" class="">Petstore example</a> from Swagger, we can extract the relevant information to create an MCP tools manifest. Deploying an MCP server with the <a href="https://docs.mcp.com.ai/components/hapi-server/" target="_blank" rel="noopener noreferrer" class=""><code>hapi</code> server</a>, we can extend the OpenAPI spec with AI-first annotations and modular structure.</p>
<p>In the demo below, the Petstore API is extended to integrate WorkOS for authentication, and the OpenAPI spec is modularized into separate files for better organization.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mcp.com.ai/v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Security</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> hapi</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">security</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">config</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> demo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> demo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">annotations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">description</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> HAPI server security configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">owner</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> team</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">hapi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">environment</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> development</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">version</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1.0.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">cors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">enabled</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">origin</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> http</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//localhost</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">8080</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Your MCP Client</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> http</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//localhost</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">6274</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># MCP Inspector</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">headers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Content</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Type</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Authorization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> X</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Requested</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">With</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">methods</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> GET</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> POST</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> PUT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> DELETE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> OPTIONS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">security</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">demo_auth</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">client_id</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> client_0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">well-known</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> https</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//</span><span class="token important">*****.app/.well-known/oauth-authorization-server</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">securitySchemes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">demo_auth</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> oauth2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">flows</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">authorizationCode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">authorizationUrl</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> https</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//api.workos.com/sso/authorize</span><span class="token punctuation" style="color:#393A34">?</span><span class="token plain">connection=conn_01</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">tokenUrl</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> https</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//</span><span class="token important">*****.app/oauth2/token</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">scopes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">read</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Read</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">write</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Modify</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">admin</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Access to admin operations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">read_all</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Read private resources</span><br></span></code></pre></div></div>
<!--$?--><template id="B:0"></template><!--/$-->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://mcp.com.ai/oas-v4-is-out#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">‚Äã</a></h2>
<p>OAS v4 has the potential to revolutionize how AI systems interact with RESTful APIs. By incorporating modular specs, AI-first annotations, and well-known discovery endpoints, OAS v4 can make it easier for LLMs to understand and utilize APIs effectively. This would not only benefit developers but also pave the way for more seamless AI integrations across various applications.</p>]]></content:encoded>
            <category>OAS</category>
            <category>MCP</category>
            <category>API</category>
            <category>AI</category>
        </item>
    </channel>
</rss>